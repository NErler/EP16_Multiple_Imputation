---
title: "Working with Multiply Imputed Data in Different Formats"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    number_sections: false
    theme: spacelab
    highlight: tango
    includes:
      after_body: style/footer.html
    css: style/style.css
---


```{r, include = F}
projdir <- gsub("/Practicals", "", getwd())

runimp <- FALSE

hint <- function(text) {
  id <- paste0('hint_', sample.int(1e10, size = 1))
    cat(
    paste0('\n',
      '<button type="button" class="btn btn-info btn-sm" data-toggle="collapse" ',
      'data-target="#', id, '">Hint</button>',
      '<div id = "', id, '" class="collapse" style="border:1px; ',
      'border-style:solid; padding: 1em; border-color:#1F78B4">',
      text, '</div>')
  )
}

options(width = 100, digits = 5)

set.seed(2020)


library(mice)
library(miceadds)
library(mitools)
library(plyr)


load(file.path(projdir, "Practicals/data/EP16dat1.RData"))
load(file.path(projdir, "Practicals/workspaces/imps.RData"))
```


## Preface
### R packages

In this practical, a number of R packages are used.
If any of them are not installed you may be able to follow the practical
but will not be able to run all of the code. The packages used (with versions
that were used to generate the solutions) are:

* `r R.version.string`
* `mice` (version: `r packageVersion("mice")`)
* `mitools` (version: `r packageVersion("mitools")`)
* `miceadds` (version: `r packageVersion("miceadds")`)
* `plyr` (version: `r packageVersion("plyr")`)


### Help files
You can find help files for any function by adding a `?` before the name of the 
function.

Alternatively, you can look up the help pages online at 
[https://www.rdocumentation.org/](https://www.rdocumentation.org/)
or find the whole manual for a package at
[https://cran.r-project.org/web/packages/available_packages_by_name.html](https://cran.r-project.org/web/packages/available_packages_by_name.html)


### Dataset 
For this practical, we will use the **EP16dat1** dataset, which is a 
subset of the [NHANES (National Health and Nutrition Examination Survey)](https://www.cdc.gov/nchs/nhanes/index.htm) data.

To get the **EP16dat1** dataset, load the file `EP16dat1.RData`.
You can download it [here](https://nerler.github.io/EP16_Multiple_Imputation/practical/data/index.html).

To load this dataset into R, you can use the command `file.choose()` which opens the
explorer and allows you to navigate to the location of the file on your computer.

If you know the path to the file, you can also use `load("<path>/EP16dat1.RData")`.


If you have not followed the first practical or if you re-loaded the **EP16dat1**
data, you need to re-code the variable `educ` again:

```{r}
EP16dat1$educ <- as.ordered(EP16dat1$educ)
```


### Imputed data
The imputed data are stored in a `mids` object called `imp` that we created in
the previous practical.

You can load it into your workspace by clicking the object `imps.RData` 
if you are using RStudio.
Alternatively, you can load this workspace using `load("<path>/imps.RData")`.


### Aim of this practical
Working with multiply imputed data can get a lot more complex, for example,
when the research question cannot be answered by just one regression model,
or when the data need some further processing after imputation.

In the lecture, we have seen that the *mice* package allows post-processing of
variables, but for more complex calculations it is often more convenient to
perform them after imputation.

When data have been imputed with a different R package, but you want to use the
convenient functions of the *mice* package, the imputed data needs to be 
converted to `mids` or `mira` objects first.

The focus of this practical is on functions to convert multiply imputed data between
different formats. An overview of possible workflows and the necessary functions
is given in this flow diagram:

<img src="./style/Flowdiagram2019.svg" style="width:100%">


## Adding a filter variable after imputation with **mice** {.tabset .tabset-fade .tabset-pills}
Assume that for a secondary research question we want to analyse a subset of the
imputed data: subjects without hypertension.

We define subjects as hypertensive if they have 

* systolic blood pressure above 140, or
* diastolic blood pressure above 90, or
* take medication for hypertension.

How can we select the correct cases for the analysis?

The standard functions for regression models (e.g. `lm`, `glm`, `lme`, ...)
have an argument `subset` that allows the specification of an expression that 
defines the subset, i.e. a "filter". The expression should return a `logical` value
(`TRUE` or `FALSE`), and only cases for which the value is `TRUE` are included
in the analysis.

When the criterion consists of multiple variables it can be useful to pre-calculate
it, so that we can easily check if our filter does what it is supposed to.

### Task 1

Since the imputed data is a `mids` object we first need to convert it to a
`data.frame`. This can be done with the function `complete()` from the **mice**
package.

:::{.task}
Convert `imp` to a long-format `data.frame` in which the original data and 
all imputed datasets are stacked onto each other.
:::

### Solution 1

```{r, midstodf-solution}
library("mice")
imp_long <- complete(imp, action = 'long', include = TRUE)
```

Some packages may not return the imputed data in long format but as a list of
data frames. In that case you can use the function `datalist2mids`
from the R package **miceadds** to create a `mids` object.

Alternatively, you can use `do.call(rbind, <list of data.frames>)` to convert 
the list of data frames into one long format data frame to then use `as.mids()`.
You need to make sure that
 
* the list contains the original data
* there are variables identifying the imputation number and subject id in each
  `data.frame`

### Task 2

:::{.task}

* Calculate a filter variable `hypten_filter` that separates cases with hypertension
   (`SBP > 140` or `DBP > 90` or `HyperMed == 'yes'`) from the other cases.
   Cases where `HyperMed` is missing should be classified based on `SBP` and `DBP` only.
* Check that the filter does what it is supposed to, for example with the help of a table.


```{r makefilter_hint, results = 'asis', echo = FALSE}
hint('Take care of the missing values in `HyperMed`.
`HyperMed == "yes"` will return `NA` if `HyperMed` is `NA`.')
```

:::
### Solution 2
```{r makefilter-solution}
imp_long$hypten_filter <- with(imp_long,
                               factor(
                                 ifelse(SBP <= 140 & DBP <= 90 & (HyperMed != "yes" | is.na(HyperMed)),
                                        "no", "yes")))
```

We can check that the filter variable does what it is supposed to by creating
a table:
```{r}
plyr::ddply(imp_long, c('HyperMed', "SBP > 140", "DBP > 90"), plyr::summarize,
            N = length(hypten_filter),
            'yes' = sum(hypten_filter == 'yes'),
            'no' = sum(hypten_filter == 'no'))
```

:::{.notebox}
[Note:]{.Note}

Subjects for whom `SBP` or `DBP` is imputed may be classified to have hypertension
in some sets but not in other, so that the number of subjects in the
analysis of the subset will differ between imputed datasets. This may complicate
subsequent analyses.
:::

```{r}
with(imp_long, table(hypten_filter, .imp, exclude = NULL))
```


### Task 3
:::{.task}

* Convert the data back to a `mids` object using the function `as.mids()` from
the **mice** package.
* Analyse and pool the data using the logistic regression with model formula
`DM ~ gender + race + age + chol + SBP + WC`, restricted to cases without
hypertension.

```{r subanalysis_hint, results = 'asis', echo = FALSE}
hint('Use `subset = hypten_filter == "no"` to select cases without hypertension.')
```
:::

### Solution 3

```{r subanalysis-solution}
imp_mids <- as.mids(imp_long)

subres <- with(imp_mids,
               glm(DM ~ gender + race + age + chol + SBP + WC,
                   family = binomial(),
                   subset = hypten_filter == 'no'))

summary(pool(subres), conf.int = TRUE)

```

If you want to check if the analysis was indeed performed on the subset only,
you can check the length of the fitted values from each analysis:

```{r}
sapply(subres$analyses, function(x) length(x$fitted.values))
```




## Another way of pooling {.tabset .tabset-fade .tabset-pills}
The function `pool()` from the **mice** package is not the only function that
performs pooling using Rubin's rules. The package **mitools** also provides this
functionality.

The diagram above shows how to obtain pooled results using **mitools**.

### Task 1
:::{.task}

* Split the data by imputation number using the function `split()`.
* Convert the resulting list to an object of class `imputationList`.
  The `imputationList` should only contain the imputed data, not the original data.

```{r splitlongdat_hint, results = 'asis', echo = FALSE}
hint('To exclude an element from a list, say the first element, use `<name of the list object>[-1]`.')
```
:::

### Solution 1
```{r splitlongdat-solution}
imp_list <- imputationList(split(imp_long, imp_long$.imp)[-1])
```


### Task 2
:::{.task}

* Analyse each of the imputed datasets in `imp_list` using `with()`.
* Pool the results using `MIcombine()` and obtain the `summary()` of the pooled
results.

:::


### Solution 2
```{r reslist-solution}
reslist <- with(imp_list, glm(DM ~ gender + race + age + chol + SBP + WC,
                   family = binomial(),
                   subset = hypten_filter == 'no'))

summary(MIcombine(reslist))
```


## Citing R Packages
When you use R for the analysis in a scientific publication, it is good practice
to properly reference the software and packages that you used, including the
version numbers.

Moreover, package developers spent a lot of time providing you with the software,
and they deserve getting some credit for their work.

The function `citation()` will tell you how you should cite R or specific packages.

**For example:**
```{r}
citation()
```

```{r}
citation("mice")
```

To obtain the version numbers you can use:
```{r}
R.version.string
```

```{r}
packageVersion("mice")
```

Because software changes over time it is important to know with which version
an analysis was performed in order to be able to reproduce the results.

