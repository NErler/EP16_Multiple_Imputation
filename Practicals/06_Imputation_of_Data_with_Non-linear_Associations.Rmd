---
title: "Imputation of Data with Non-linear Associations"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    number_sections: false
    theme: spacelab
    highlight: tango
    includes:
      after_body: style/footer.html
    css: style/style.css
---


```{r, include = FALSE}

projdir <- gsub("/Practicals", "", getwd())

runimps <- FALSE

hint <- function(text) {
  id <- paste0('hint_', sample.int(1e10, size = 1))
    cat(
    paste0('\n',
      '<button type="button" class="btn btn-info btn-sm" data-toggle="collapse" ',
      'data-target="#', id, '">Hint</button>',
      '<div id = "', id, '" class="collapse" style="border:1px; ',
      'border-style:solid; padding: 1em; border-color:#1F78B4">',
      text, '</div>')
  )
}


knitr::opts_chunk$set(out.width = "100%")

options(width = 100)

set.seed(2020)

library(kableExtra)
library(knitr)
library(mice)
library(ggplot2)
library(JointAI)

# library(ggpubr)
# library(ggplot2) # for propplot & JointAI
# library(RColorBrewer) # for propplot
# library(reshape2) # for propplot

load(file.path(projdir, "Practicals/data/EP16dat2.RData"))
load(file.path(projdir, "Practicals/workspaces/imps_nonlin.RData"))

source(file.path(projdir, "Slides/Rfcts/propplot.R"))
```


## Preface {data-progressive=FALSE}
### R packages

In this practical, a number of R packages are used.
If any of them are not installed you may be able to follow the practical
but will not be able to run all of the code. The packages used (with versions
that were used to generate the solutions) are:

* `r R.version.string`
* `mice` (version: `r packageVersion("mice")`)
* `JointAI` (version: `r packageVersion("JointAI")`)
* `ggplot2` (version: `r packageVersion("ggplot2")`)
* `reshape2` (version: `r packageVersion("reshape2")`)
* `ggpubr` (version: `r packageVersion("ggpubr")`)


### Help files
You can find help files for any function by adding a `?` before the name of the 
function.

Alternatively, you can look up the help pages online at 
[https://www.rdocumentation.org/](https://www.rdocumentation.org/)
or find the whole manual for a package at
[https://cran.r-project.org/web/packages/available_packages_by_name.html](https://cran.r-project.org/web/packages/available_packages_by_name.html)


### Dataset 

For this practical, we will use the **EP16dat2** dataset, which is a 
subset of the [NHANES (National Health and Nutrition Examination Survey)](https://www.cdc.gov/nchs/nhanes/index.htm) data.

To get the **EP16dat2** dataset, load the file `EP16dat2.RData`.
You can download it [here](https://nerler.github.io/EP16_Multiple_Imputation/practical/data/index.html).

To load this dataset into R, you can use the command `file.choose()` which opens the
explorer and allows you to navigate to the location of the file on your computer.

If you know the path to the file, you can also use `load("<path>/EP16dat2.RData")`.

To give you a head start, here some basic summary of this data:
```{r}
str(EP16dat2)
```

```{r, fig.width = 8, fig.height = 6}
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.6, 0))
JointAI::plot_all(EP16dat2, breaks = 50, nrow = 3)
```



### Aim
The focus of this practical is the imputation of data that has features
that require special attention.

In the interest of time, we will focus on these features and **abbreviate steps
that are the same as in any imputation setting** (e.g., getting to know 
the data or checking that imputed values are realistic).
**Nevertheless, these steps are of course required when analysing data in 
practice.**




Our aim is to impute data, so that we can later fit the following linear regression model for weight:
```{r NHANESmodel, eval = FALSE}
mod <- lm(wgt ~ gender + bili + age * (chol + HDL) + hgt)
```
(Note: this line of syntax will not run! This is just to give you the model
specification.)

We expect that the effects of cholesterol and HDL may differ with age, and, 
hence, include **interaction terms** between `age` and `chol` and `HDL`,
respectively.

Additionally, we want to include the other variables in the dataset as auxiliary variables.

## Imputation using **mice**
When the analysis model of interest involves interaction terms between
incomplete variables, **mice** has limited options to reduce the bias that may
be introduced by naive handling of the missing values.


Use of the "Just Another Variable" approach can in some settings reduce bias.
Alternatively, we can use passive imputation, i.e.,
calculate the interaction terms in each iteration of the MICE algorithm.
Furthermore, predictive mean matching tends to lead to less bias than 
normal imputation models.

### Just Another Variable approach {.tabset .tabset-fade .tabset-pills}
#### Task 1
:::{.task}
* Calculate the interaction terms in the incomplete data.
* Perform the setup-run of `mice()` without any iterations.
:::


#### Solution 1
```{r miceJAVsetup-solution}
# calculate the interaction terms
EP16dat2$agechol <- EP16dat2$age * EP16dat2$chol
EP16dat2$ageHDL <- EP16dat2$age * EP16dat2$HDL

# setup run
imp0 <- mice(EP16dat2, maxit = 0, 
             defaultMethod = c('norm', 'logreg', 'polyreg', 'polr'))
imp0
```

#### Task 2
:::{.task}
Apply the necessary changes to the imputation method and predictor matrix.


```{r, results = 'asis', echo = FALSE}
hint('Since the interaction terms are calculated from the orignal variables,
these interaction terms should not be used to impute the original variables.')
```
:::

#### Solution 2
```{r, miceJAVchanges-solution}
meth <- imp0$method 
pred <- imp0$predictorMatrix

# change imputation for "bili" to pmm (to prevent negative values)
meth["bili"] <- 'pmm'
 
# changes in predictor matrix to prevent feedback from the interactions to the
# original variables
pred["chol", "agechol"] <- 0
pred["HDL", "ageHDL"] <- 0

meth
pred
```

:::{.notebox}
[Note:]{.Note}

A look at the histogram of `bili` tells us that the variable is not too skewed,
but the distribution is relatively close to zero. And in a previous practical
we already saw that there were negative values for `bili` when this variable
was imputed with a linear regression model.


In practice, I would still try a normal distribution and only use predictive
mean matching if the distribution of the imputed values is off.
:::

#### Task 3
:::{.task}
Run the imputation using the JAV approach and check the traceplot.
:::


#### Solution 3

```{r miceJAV-solution, eval = runimps}
# run imputation with the JAV approach
impJAV <- mice(EP16dat2, method = meth, predictorMatrix = pred,
               maxit = 20, printFlag = FALSE, seed = 2020)
```

:::{.notebox}
[Note]{.Note}
The argument `printFlag` prevents the lengthy output and the argument `seed`
can be set to get reproducible results (this sets the seed value for the random
number generator).
:::

```{r, fig.width = 8, fig.height = 6}
plot(impJAV, layout = c(4, 6))
```


#### Task 4
We skip the more detailed evaluation of the imputed values.
With the settings given in the solution the chains have converged and distributions
of the imputed values match the distributions of the observed data closely enough.

:::{.task}
Analyse the imputed data and pool the results.
:::

#### Solution 4
```{r miceJAV-analysis-solution}
miraJAV <- with(impJAV, 
                lm(wgt  ~ gender + bili + age + chol + HDL + agechol + ageHDL + hgt))
summary(pool(miraJAV), conf.int = TRUE)
```


### Passive Imputation {.tabset .tabset-fade .tabset-pills}
For the passive imputation, we can re-use the adjusted versions of `meth` and 
`pred` we created for the JAV approach, but additional changes to `meth`
are necessary.

#### Task 1
:::{.task}
Specify the new imputation method, i.e., adapt `meth` and save it as `methPAS`.

```{r,  results = 'asis', echo = FALSE}
hint('For passive imputation, instead of an imputation method you need to specify
     the formula used to calculate the value that is imputed passively.')
```
:::

#### Solution 1

```{r micePASchanges-solution}
# changes in imputation method for passive imputation
methPAS <- meth
methPAS[c("agechol", "ageHDL")] <- c("~I(age*chol)", "~I(age*HDL)")
```

Note: the visit sequence does not have to be changed here, because the variables
that are being imputed passively are already last in the visit sequence:
```{r}
imp0$visitSequence
```


#### Task 2
:::{.task}
Run the imputation using passive imputation and check the traceplot.
:::

#### Solution 2
```{r micePAS-solution, eval = runimps}
# run imputation with passive imputation
impPAS <- mice(EP16dat2, method = methPAS, predictorMatrix = pred,
               maxit = 20, printFlag = FALSE, seed = 2020)
```

```{r fig.width = 8, fig.height = 6}
plot(impPAS, layout = c(4, 5))
```


#### Task 3
We will again skip the detailed evaluation of convergence and the imputed values.

:::{.task}
Analyse the imputed data and pool the results.
:::

#### Solution 3
```{r micePASanalysis-solution}
miraPAS <- with(impPAS, 
                lm(wgt ~ gender + bili + age + chol + HDL + agechol + ageHDL + hgt))

summary(pool(miraPAS), conf.int = TRUE)
```


## Imputation with **JointAI**
**JointAI** provides functions that allow us to fit Bayesian regression models
with incomplete covariates. The main functions are designed to resemble the 
standard functions to fit regression models with complete data.

For univariate outcomes the following functions are available:

* `lm_imp()`: for linear regression
* `lognorm_imp()`: for regression using a log-normal distribution
* `betareg_imp()`: for continuous outcomes in the interval $[0, 1]$
* `glm_imp()`: for generalized linear regression (e.g., logistic, gamma or Poisson)
* `clm_imp()`: for ordinal (cumulative logit) regression
* `mlogit_imp()`: for multinomial logit models

:::{.notebox}
[Note:]{.Note}

There will be a new version of **JointAI** (later this year) which will also 
provide functions to fit models using a log-normal or a beta distribution,
and a function to fit multinomial logit models (for
unordered categorical outcomes).
:::


### Specification of the analysis model {.tabset .tabset-fade .tabset-pills}
Similar to the complete data versions, the functions from **JointAI** take
the following arguments:
```{r JointAIargs, echo = FALSE}
JointAIargs <- rbind(
  c("`formula`", "model formula"),
  c("`data`", "original, incomplete dataset"),
  c("`family`", "for glm's: the distribution family of the outcome (e.g., `binomial()` for a logistic model)")
) %>% as.data.frame

names(JointAIargs) <- c("", "")

JointAIargs %>% kable(format = 'html') %>%
  kable_styling(full_width = FALSE)
```


#### Task 1
:::{.task}
Specify the linear regression model with the model formula given at the 
beginning of this practical, using `lm_imp()`.

You need to specify the arguments `formula`, `data` and `n.iter`.
Set `n.iter = 100` (we will learn more about this argument a little bit later).
:::


#### Solution 1
```{r JointAIsetup-solution, eval = runimps}
lm1 <- lm_imp(wgt ~ gender + bili + age * (chol + HDL) + hgt, data = EP16dat2,
              n.iter = 100)
```
```{r}
lm1
```


#### Task 2

`lm_imp()` returns an object of class `JointAI`, which contains

* the original data (`data`),
* information on the type of model (`call`, `analysis_type`, `models`,
`fixed`, `random`, `hyperpars`, `scale_pars`) and 
* information about the MCMC sampling (`mcmc_settings`),
* the JAGS model (`model`) and 
* the MCMC sample (`MCMC`; if a sample was generated),
* the computational time (`time`) of the MCMC sampling, and 
* some additional elements that are used by methods for objects of class `JointAI`
  but are typically not of interest for the user.

:::{.task}
Check which imputation models were used in `lm1`.

```{r lm1modelshint, results = 'asis', echo = FALSE}
hint('The imputation model types are returned in the JointAI object under "models".')
```
:::

#### Solution 2
```{r lm1models-solution}
lm1$models
```

### Specification of the imputation models {.tabset .tabset-fade .tabset-pills}
In **JointAI**, there are some arguments related to the imputation part of the model:
```{r JointAIargs2, echo = FALSE}
JointAIargs <- rbind(
  c("`models`", paste0("vector of imputation methods (for details see below and",
                       " the vignette on [Model Specification](https://nerler.github.io/JointAI/articles/ModelSpecification.html#meth))")),
  c("`auxvars`", paste0("a formula of variables that are not part of the analysis",
                        " model but should be used to predict missing values (optional;",
                        " for details see the vignette on [Model Specification](https://nerler.github.io/JointAI/articles/ModelSpecification.html#auxvars))")),
  c("`refcats`", paste0("allows specification of which category of categorical variables is used as reference (optional;",
                        " for details see the vignette on [Model Specification](https://nerler.github.io/JointAI/articles/ModelSpecification.html#reference-values-for-categorical-covariates))")),
  c("`trunc`", paste0("allow truncation of distributions of incomplete continuous",
   " covariates (for details see the vignette on [Model Specification](https://nerler.github.io/JointAI/articles/ModelSpecification.html#functions-with-restricted-support))"))
) %>% as.data.frame

names(JointAIargs) <- c("", "")

JointAIargs %>% kable(format = 'html') %>%
  kable_styling(full_width = FALSE)

```

Like in **mice** default imputation models are chosen based on the `class` of
each of the incomplete variables.
The default choices for baseline (not time-varying) covariates are
```{r, echo = FALSE}
tab <- rbind(lm = c("linear regression", "continuous variables"),
             glm_logit = c("logistic regression", "factors with two levels"),
             mlogit = c("multinomial logit model", "unordered factors with >2 levels"),
             clm = c("cumulative logit model", "ordered factors with >2 levels")
)

tab <- cbind(paste0("`", rownames(tab), "`"), tab)
colnames(tab) <- c('name', 'model', 'variable type')

knitr::kable(tab, row.names = FALSE, format = 'html') %>%
  kable_styling(full_width = FALSE)
```

Alternative imputation methods are available for continuous baseline covariates:
```{r, echo = FALSE}
tab = rbind(lognorm = c("normal regression of the log-transformed variable",
                        "right-skewed variables >0"),
            glm_gamma_inverse = c("Gamma regression (with inverse-link)",
                              "right-skewed variables >0"),
            glm_gamma_identity = c("Gamma regression (with identity-link)",
                              "right-skewed variables >0"),
            glm_gamma_log = c("Gamma regression (with log-link)",
                              "right-skewed variables >0"),
            beta = c("beta regression (with logit-link)",
                     "continuous variables with values in [0, 1]")
)
tab <- cbind(paste0("`", rownames(tab), "`"), tab)
colnames(tab) <- c('name', 'model', 'variable type')

knitr::kable(tab, row.names = FALSE, format = 'html') %>%
  kable_styling(full_width = FALSE)
```


#### Task
:::{.task}

Re-fit the linear regression model, but now

* specify a log-normal or a gamma distribution for `bili`
* set the reference category to the largest group
* use the other variables that are in the data as auxiliary variables

```{r lm2hints, results = 'asis', echo = FALSE}
hint('To specify a non-default imputation method use the argument `models = c(bili = ...)`.')
hint('To set the respective largest group as reference category for all 
     categorical variables use the argument `refcats = "largest"`.')
hint('Auxiliary variables need to be specified explicitely using the argument
     `auxvars`. It takes a formula of variable names.')
```
:::


#### Solution
```{r JointAIlm2-solution, eval = runimps}
lm2 <- lm_imp(wgt ~ gender + bili + age * (chol + HDL) + hgt, data = EP16dat2,
              auxvars = ~ educ + race + SBP + hypten + WC,
              models = c(bili = 'lognorm'), refcats = 'largest',
              n.iter = 100, seed = 2020)
```


:::{.notebox}
[Note:]{.Note}

By default, no output is printed during the adaptive phase. If you want to be
sure that the model is running and your computer did not just get stuck
you can set the argument `quiet = FALSE`.
:::

### Specification of the MCMC settings {.tabset .tabset-fade .tabset-pills}
Specification of the basic settings for the MCMC sampling can be done using
the following arguments:
```{r JointAIargs3, echo = FALSE}
JointAIargs <- rbind(
  c("`n.chains`", "number of MCMC chains"),
  c("`n.adapt`", "number of iterations used in the adaptive phase"),
  c("`n.iter`", "number of iterations per MCMC chain in the sampling phase")
) %>% as.data.frame

names(JointAIargs) <- c("", "")

JointAIargs %>% kable(format = 'html') %>%
  kable_styling(full_width = FALSE)
```

**JointAI** has more arguments than the ones given above, but in this practical
we focus only on the most important. 
You may find out more about all the arguments in the vignette on [MCMC Settings](https://nerler.github.io/JointAI/articles/MCMCsettings.html).

By default, `n.chains = 3`, `n.adapt = 100` and `n.iter = 0`.

It is useful to use more than one chain to be able
to evaluate convergence of the MCMC chains.

Samples in the adaptive phase are not used for the final MCMC sample. They are
needed to optimize the MCMC sampler. When the number provided via the argument
`n.adapt` is insufficient for this optimization a warning message will be printed.
In simple models (e.g., linear regression) usually the default value of `n.adapt = 100`
can be used.

The default value for `n.iter`, the number of iterations in the sampling phase
is `0` (no MCMC sample will be created). The number of iterations that is needed
depends on how complex the model and the data is and can range from somewhere
as low as 100 up to several million.

In the following, we will look at some criteria to determine if the number of 
MCMC samples that was used is sufficient.


### Evaluation of the MCMC sample {.tabset .tabset-fade .tabset-pills}
The first step after fitting a Bayesian model should be to confirm that
the MCMC chains have converged. This can be done visually, using a traceplot
(plotting the sampled values per parameter and chain across iterations)
or using the Gelman-Rubin criterion. 

#### Task 1
:::{.task}
Investigate convergence of `lm2` by creating a traceplot using the function `traceplot()`.
The plot should show a horizontal band without trends or patterns and the 
different chains should be mixed.
:::


#### Solution 1
```{r lm2trace-solution, fig.width = 8, fig.height = 6}
traceplot(lm2, use_ggplot = TRUE, ncol = 4) +
  theme(legend.position = 'none')
```

:::{.notebox}
[Note:]{.Note}

In the recent update of R to version 4.0.0, several things changed.
These changes also affect the function `traceplot()` of **JointAI** when
the (default) `matplot()` is use instead of the `use_ggplot = TRUE` option. 

Currently, the standard output (when `use_ggplot = TRUE` is not used) does not
work properly. This will be fixed in the next version of **JointAI**.
:::

#### Task 2
:::{.task}
Investigate convergence of `lm2` using the Gelman-Rubin criterion, implemented
in the function `GR_crit()`.

The upper limit of the confidence interval ("`Upper C.I.`") should not be much larger than 1.
:::

#### Solution 2
```{r lm2GR-solution, fig.width = 7, fig.height = 5}
GR_crit(lm2)
```


#### Continue

When we are satisfied with the convergence of the MCMC chains we can take a look
at the MCMC sample is precise enough. We can do this by comparing the Monte Carlo
error (which describes the error made since we have just a finite sample)
to the estimated standard deviation.
This is implemented in the function `MC_error()`.

#### Task 3
:::{.task}
Calculate the Monte Carlo error for `lm2`.
:::

#### Solution 3
```{r}
MC_error(lm2)
```

The output shows us the posterior mean (`est`), and standard deviaiton `SD`, 
as well as the Monte Carlo error (`MCSE`) and the ratio of the Monte Carlo error
to the posterior standard deviation (`MCSE/SD`).

This ratio should not bee too large. A rule of thumb is that it should be less 
than 5%.


To get a quick overview of this ratio we can also plot it:
```{r lm2MCE-solution, fig.width = 7, fig.height = 5, out.width = "80%"}
par(mar = c(3.2, 5, 1, 1), mgp = c(2, 0.6, 0))
plot(MC_error(lm2))
```

The Monte Carlo error is approximately 6% for all our model parameters.
We could reduce this proportion by increasing the number of iterations (`n.iter`),
but for the purpose of this practical the precision is acceptable.

### Results {.tabset .tabset-fade .tabset-pills}

#### Task
:::{.task}
Get the summary of the model using the function `summary()`.
:::


#### Solution

```{r lm2results-solution, fig.width = 8, fig.height = 6}
summary(lm2)
```


## Additional exercise JointAI
### Monitoring imputed values {.tabset .tabset-fade .tabset-pills}
**JointAI** also allows us to extract imputed values to generate multiple 
imputed datasets that can, for instance, be used for a secondary analysis.

To be able to extract the imputed values, it is necessary to specify in advance
that these values should be monitored ("recorded"). This can be done using
the argument `monitor_params`.

`monitor_params` uses a number of key words to specify which (groups of) parameters
or values should be monitored. Each key word works like a switch and can be set
to `TRUE` or `FALSE`. For more details see the vignette on [Parameter Selection](https://nerler.github.io/JointAI/articles/SelectingParameters.html).

For monitoring imputed values, `monitor_params = c(imps = TRUE)` needs to be 
specified.


#### Task
:::{.task}
Re-fit the linear regression model, but now additionally set the argument `monitor_params`
to keep the imputed values.
:::

#### Solution
```{r JointAIlm3-solution, eval = runimps}
lm3 <- lm_imp(wgt ~ gender + bili + age * (chol + HDL) + hgt, data = EP16dat2,
               auxvars = ~ educ + race + SBP + hypten + WC,
               models = c(bili = 'lognorm'), refcats = 'largest',
               n.iter = 250, monitor_params = c(imps = TRUE), seed = 2020)
```


### Extracting imputed data {.tabset .tabset-fade .tabset-pills}

The function `get_MIdat()` allows us to create multiple completed datasets
from an object of class `JointAI`. 

It takes the following arguments
```{r getMIdatargs, echo = FALSE}
getMIdatargs <- rbind(
  c("`object`", "an object of class `JointAI`"),
  c("`m`", "number of imputed datasets"),
  c("`include`", "should the original, incomplete data be included? (default is `TRUE`)"),
  c("`start`", "first iteration of interest; allows discarding burn-in iterations"),
  c("`minspace`", "minimum number of iterations between iterations chosen as imputed values (default is 50)"),
  c("`seed`", "optional seed value"),
  c("`export_to_SPSS`", "logical; should the completed data be exported to SPSS?"),
  c("`resdir`", "optional directory for results (for export to SPSS)"),
  c("`filename`", "optional file name (for export to SPSS)")
) %>% as.data.frame

names(getMIdatargs) <- c("", "")

getMIdatargs %>% kable(format = 'html') %>%
  kable_styling(full_width = FALSE)
```


#### Task 1
:::{.task}

* Extract 10 imputed datasets from `lm3`.
* Inspect the resulting object.

:::


#### Solution 1
```{r MIdatlm3-solution}
MIdat3 <- get_MIdat(lm3, m = 10)

head(MIdat3)
```

We see that some columns were added to the data:

* `Imputation_` identifies the imputation number
* `.id` is the subject ID
* `.rownr` refers to the row number of the original data

```{r}
summary(MIdat3)
```


#### Task 2
Similar to the functions `densplot()` from the **mice** package and `propplot()`,
the function `plot_imp_distr()` from **JointAI** allows us to plot the distribution
of the observed and imputed values for the incomplete variables.

It takes the following arguments

```{r, echo = FALSE}
tab <- rbind(
  c("`data`", "a data.frame in long format containing multiple imputations (and the original incomplete data)"),
  c("`imp`", "the name of the variable specifying the imputation indicator"),
  c("`id`", "the name of the variable specifying the subject indicator"),
  c("`rownr`", "the name of a variable identifying which rows correspond to the same observation in the original (unimputed) data"),
  c("`ncol`, `nrow`", "optional number of rows and columns in the plot layout; automatically chosen if unspecified")
) %>% as.data.frame

names(tab) <- c("", "")

tab %>% kable(format = 'html') %>%
  kable_styling(full_width = FALSE)
```


:::{.task}
Check the imputed values in  `MIdat3` using `plot_imp_distr()`.
:::

#### Solution 2
```{r plotimps-solution, fig.width = 8, fig.height = 7}
plot_imp_distr(MIdat3)
```


### Transforming imputed data to a mids object {.tabset .tabset-fade .tabset-pills}
To perform standard analyses on the imputed data it is usefull to convert them
to a `mids` object, so that they can be treated as if they had been imputed
with `mice()`.

The **mice** package proves the function `as.mids()` to convert a long-format
dataset (with original and multiple imputed datasets stacked onto each other)
to a `mids` object.


#### Task
:::{.task}
Transform `MIdat3` to a `mids` object and confirm that it has worked by checking
the `class` of the result.
:::

#### Solution
```{r lm3mids-solution}
mids3 <- mice::as.mids(MIdat3, .imp = "Imputation_", .id = '.id')

class(mids3)
```



```{r saveimp, include = FALSE, eval = runimps}
save(impJAV,
     impPAS,
     lm1,
     lm2,
     lm3,
     file = file.path(projdir, "Practicals/workspaces/imps_nonlin.RData"))
```
