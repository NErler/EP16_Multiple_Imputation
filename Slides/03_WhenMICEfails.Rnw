\begin{frame}[allowframebreaks=0.8]{Outline of Part III}
\tableofcontents[part=3]
\end{frame}

<<packages part3, echo = F>>=
library(knitr)
library(kableExtra)
library(plyr)
library(RColorBrewer)
library(magrittr)
library(kableExtra)
library(ggplot2)
library(splines)
library(dplyr)
library(mice)
library(miceadds)
library(lme4)
library(knitr)

source(file.path(projdir, "Slides", "Rfcts/make_exampledata.R"))
@

\section{Settings where MICE may have problems}
\subsection{Example: Quadratic effect}
<<example_quadratic_bias, echo = F>>=
# sim data quadratic -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
y <- -1 - 0.6 * x + 0.5 * x^2 + rnorm(N, 0, 0.2)

DFexqdr <- data.frame(y = y, x = x)
DFexqdr$xmis <- DFexqdr$x
DFexqdr$xmis[sample(1:length(x), size = N/2, prob = plogis(5 * DFexqdr$y))] <- NA

impmod <- lm(xmis ~ y, DFexqdr)
imps <- predict(impmod, newdata = DFexqdr[is.na(DFexqdr$xmis), ]) +
  rnorm(sum(is.na(DFexqdr$xmis)), 0, summary(impmod)$sigma)

DFexqdr$ximp <- DFexqdr$xmis
DFexqdr$ximp[is.na(DFexqdr$xmis)] <- imps

lm0 <- lm(y ~ x + I(x^2), DFexqdr)
lm_imp <- lm(y ~ ximp + I(ximp^2), DFexqdr)
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Consider the case where the analysis model (which we assume to be true)
is
$$y = \beta_0 + \beta_1 x + {\color{darkred}\bmath{\beta_2 x^2}} + \ldots,$$
i.e., $y$ has a \blue{quadratic relationship} with $x$, and $x$ is incomplete.

\begin{center}
<<plot_qdr1, echo = F, fig.width = 6, fig.height = 4, out.width = "65%">>=
pexqdr1 <- ggplot(DFexqdr, aes(x = x, y = y,
                               color = is.na(xmis),
                               shape = is.na(xmis))) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.1, 0.15),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 14))

pexqdr1 +
  scale_color_manual(name = "",
                     limits = c(F, T),
                     values = c("black", "black"),
                     labels = c("observed", "missing")) +
  scale_shape_manual(name = "",
                     limits = c(F, T),
                     values = c(19, 1),
                     labels = c("observed", "missing"))

@
\end{center}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to impute $x$ when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \ldots,$$
i.e., a linear relation between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr2, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 + geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
                     aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "black", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed"))
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The imputed values distort the curved pattern of the true data.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
% Analysis and imputation model contradict each other.
%
% No joint distribution exists that has the conditional distributions resulting
% from these models as its conditional distributions.
%
% \blue{\ding{225}} The imputation model for $x_1$ is \blue{uncongenial}.\\
% \blue{\ding{225}} Analysis of the imputed data leads to biased results.

The model fitted on the imputed data gives \blue{severely biased results}; the
non-linear shape of the curve has almost completely disappeared.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr3, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 +
  geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
             aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  geom_smooth(aes(group = "1", linetype = "ltycompl"), color = 'darkred',
              method = "lm", formula = y~x + I(x^2), se = F, lwd = 1.5) +
  geom_smooth(data = DFexqdr, aes(x = ximp, y = y, group = '1',
                                  linetype = "ltyimp"),
              color = 'darkred', se = F, lwd = 1.5,
              method = "lm", formula = y~x + I(x^2)) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "black", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed")) +
  scale_linetype_manual(name = "",
                        limits = c('ltycompl', 'ltyimp'),
                        values = c(1, 2),
                        labels = c("complete", "imputed")) +
  theme(legend.key.width = unit(1.5,"cm"),
        legend.title = element_blank(),
        legend.position = c(0.11, 0.18),
        legend.spacing.y = unit(-1, "lines"))
@
% \includegraphics[width = \linewidth]{figure/example_quadratic_bias-9.pdf}
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<restab_qdr, echo = F, size = 'scriptsize'>>=
tabexqdr <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'x2'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  3, "Imputed" = 3))# %>%

tabexqdr %>%
  gsub("x2", "$x^2$", .) %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Example: Interaction effect}
<<example_interact_bias, echo = F, include = F, fig.width = 6, fig.height = 4, fig.keep = "high">>=
# sim data interact -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
z <- rbinom(N, size = 1, prob = 0.5)
y <- -1 - 0.6 * x + 0.5 * z + x*z + rnorm(N, 0, 0.2)

DFexint <- data.frame(y = y, x = x, z = z)
DFexint$xmis <- DFexint$x
DFexint$xmis[sample(1:length(x), size = N/2, prob = plogis(2 * DFexint$y))] <- NA

impmod <- lm(xmis ~ y + z, DFexint)
impmod2 <- lm(xmis ~ y*z, DFexint)

impresid <- rnorm(sum(is.na(DFexint$xmis)), 0, summary(impmod)$sigma)

imps <- predict(impmod, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid
imps2 <- predict(impmod2, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid

DFexint$ximp <- DFexint$ximp2 <- DFexint$xmis
DFexint$ximp[is.na(DFexint$xmis)] <- imps
DFexint$ximp2[is.na(DFexint$xmis)] <- imps2

lm0 <- lm(y ~ x*z, DFexint)
lm_imp <- lm(y ~ ximp*z, DFexint)
lm_imp2 <- lm(y ~ ximp2*z, DFexint)

# xp <- seq(from = -1.5, to = 1.5, by = 0.1)
#
# yp0 <- predict(lm0, newdata = data.frame(x = xp, z = 0))
# yp1 <- predict(lm0, newdata = data.frame(x = xp, z = 1))
#
# yimp0 <- predict(lm_imp, newdata = data.frame(ximp = xp, z = 0))
# yimp1 <- predict(lm_imp, newdata = data.frame(ximp = xp, z = 1))
#
# yimp20 <- predict(lm_imp2, newdata = data.frame(ximp2 = xp, z = 0))
# yimp21 <- predict(lm_imp2, newdata = data.frame(ximp2 = xp, z = 1))
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another example occurs with an analysis model (which we assume to be true)
is
$$y = \beta_0 + \beta_x x + \beta_z z + {\color{darkred}\bmath{\beta_{xz} xz}} + \ldots,$$
i.e., $y$ has a \blue{non-linear relationship} with $x$ due to the
\blue{interaction term}.

\begin{center}
<<plot_int1, echo = F, fig.width = 6, fig.height = 4, out.width = "65%">>=
plotexint <- reshape2::melt(DFexint, id.vars = c("y", "z", "ximp2", "xmis"))
plotexint$combi <- paste0(plotexint$variable, "_",
                     ifelse(is.na(plotexint$xmis), "mis", "obs"), plotexint$z)

# plotexint$lty <- interaction(plotexint$variable, plotexint$z)

ggplot(plotexint[plotexint$variable == "x", ], aes(x = value, y = y,
                               color = combi,
                               shape = combi)) +
    geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.11, 0.16),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 14),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c(1, 1, 19, 19),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c("blue", "darkgreen", "blue", "darkgreen"),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)"))
@
\end{center}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to impute $x$ when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \theta_{12} z + \ldots,$$
i.e., a linear relation between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int2, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi)) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.11, 0.22),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 14),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 8, 8),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "darkgreen"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  expand_limits(y = -2)
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The ``$<$'' shaped pattern of the true data is distorted by the imputed values.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
And the analysis on these naively imputed values leads to severely biased estimates

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int3, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi)) +
  geom_point(size = 2, alpha = 0.3) +
  geom_smooth(data = plotexint[plotexint$z == "0", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'blue') +
  geom_smooth(data = plotexint[plotexint$z == "1", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'darkgreen') +
  theme_light() +
  theme(legend.position = c(0.21, 0.22),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 14),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal",
        legend.key.width = unit(1,"cm")) +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 8, 8),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "darkgreen"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_linetype_manual(name = "",
                        limits = c("x", "ximp"),
                        values = c(1, 2),
                        labels = c("true",  "imputed")) +
  expand_limits(y = -2, x = -1.5)
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<echo = F, size = 'scriptsize'>>=
restab_interact <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'z', 'x:z'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  4, "Imputed" = 4))

restab_interact %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}




\subsection{Example: longitudinal outcome}
<<simlong data, echo = F, fig.with = 6, fig.height = 4>>=
IDs <- c(5, 6, 7, 8, 18)
subIDs <- IDs[IDs != 7]
subDFexlong <- DFexlong[DFexlong$id %in% IDs, ]

DFexlongwide <- reshape(DFexlong, direction = 'wide', v.names = c("y", "time"), idvar = "id",
                  timevar = 'ti', drop = "tp")
subDFexlongwide <- DFexlongwide[DFexlongwide$id %in% subIDs, ]


coefDFexlong <- as.data.frame(t(sapply(lapply(split(subDFexlong, subDFexlong$id),
                                        lm, formula = y ~ time), coef)))
coefDFexlong$ID <- IDs


ltDFexlong <- subDFexlong[subDFexlong$id != 7,
                          c("id", "y", paste0("x", 1:4), "time")]
ltDFexlong$time <- sprintf(ltDFexlong$time, fmt = "%.2f")
ltDFexlong$y <- "\\checkmark"
ltDFexlong$x1 <- "\\checkmark"
ltDFexlong$x2 <- as.character(ltDFexlong$x2)
ltDFexlong$x2[!is.na(ltDFexlong$x2)] <- "\\checkmark"
ltDFexlong$x3 <- as.character(ltDFexlong$x3)
ltDFexlong$x3[!is.na(ltDFexlong$x3)] <- "\\checkmark"
ltDFexlong$x4[!is.na(ltDFexlong$x4)] <- "\\checkmark"

ltDFexlong <- rbind(ltDFexlong, rep("\\vdots", 7))


colvec <- brewer.pal(length(IDs), "Dark2")
@



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another setting where imputation with MICE is not straightforward is when
the outcome variable is longitudinal.
\begin{columns}
\begin{column}{0.55\linewidth}
<<trajectories, echo = F, fig.with = 6, fig.height = 4>>=
plong1_0 <- ggplot(subDFexlong, aes(x = time, y = y, color = factor(id))) +
  theme(legend.position = "none",
        axis.title = element_text(size = 14)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL,
                     minor_breaks = seq(from = 4, to = 6, by = 0.02))

plong1_1 <- plong1_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong1_1
@
\end{column}
\begin{column}{0.45\linewidth}
<<ex_datatable, echo = F, size = 'scriptsize', warning = F>>=
lsp <- rep("", nrow(ltDFexlong))
lsp[cumsum(table(subDFexlong$id[subDFexlong$id %in% ltDFexlong$id]))] <- "\\hdashline"

longdatatab <- ltDFexlong %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000"))),
         id = cell_spec(id, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  kable(format = 'latex', escape = F, booktabs = T,
        linesep = lsp,
        align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F)

longdatatab <- gsub("\\\\\n\\bottomrule", "", longdatatab, fixe = T)
longdatatab
@
\end{column}
\end{columns}
Here, $x_1, \ldots, x_4$ are baseline covariates, i.e., not measured repeatedly.
% You can think of them as "age at baseline", "gender", "education level", \ldots
\end{frame}


<<fake_imp, echo = F>>=
impexlong <- mice(DFexlong, seed = 123)
impDFexlong <- complete(impexlong, 3)
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Would we use MICE in the data in this format, each row would be regarded as
independent, which may cause bias and inconsistent imputations.
\begin{columns}
\begin{column}{0.55\linewidth}
Imputed values of baseline covariates are imputed with different values,
creating data that could not have been observed.
\end{column}
\begin{column}{0.45\linewidth}
<<echo = F, size = 'scriptsize'>>=
imptablong <- rbind(impDFexlong[impDFexlong$id %in% subIDs, names(ltDFexlong)],
                    rep(NA, ncol(ltDFexlong)))
imptablong[sapply(imptablong, is.numeric)] <-
  round(imptablong[sapply(imptablong, is.numeric)], 2)

ltDFexlong2 <- ltDFexlong
ltDFexlong2[is.na(ltDFexlong2)] <- imptablong[is.na(ltDFexlong2)]

ltDFexlong2 <- ltDFexlong2 %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  mutate(x2 = cell_spec(x2, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x2),
                                       brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                       '#FFFFFF'))) %>%
  mutate(x3 = cell_spec(x3, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x3),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  mutate(x4 = cell_spec(x4, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x4),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  kable(format = 'latex', escape = F, booktabs = T, linesep = lsp, align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F, digits = 2)

for (k in 1:8) {
  ltDFexlong2 <- gsub(paste0("\\cellcolor[HTML]{",
                             gsub("#", "", brewer.pal(8, "Dark2")[k])),
               paste0("\\cellcolor{Dark2", k, "!30"), ltDFexlong2, fixed = T)
}

gsub("\\\\\n\\bottomrule", "", ltDFexlong2, fixe = T)
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<res example LMM, echo = F, message = F, fig.height = 4, fig.width = 5>>=
lme0 <- lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
               (time|id), data = DFexlong_orig)

lme_imp <- with(impexlong, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
                                (time|id)))

res0 <- as.data.frame(cbind(fixef(lme0),
                            confint(lme0, parm = names(fixef(lme0)),
                                    method = "Wald")))
resimp <- as.data.frame(summary(pool(lme_imp))[, c("est", "lo 95", "hi 95")])

res0$mod <- "orig"
resimp$mod <- "imp"
names(res0) <- names(resimp) <- c("est", "lo", "hi", "mod")

res <- rbind(res0, resimp)
res$var <- rep(rownames(res0), 2)

ggplot(res[!res$var %in% grep("time", res$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2girl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3low" = "x3 (low)",
                                      "x3mid" = "x3 (mid)",
                                      "x4" = "x4"))) +
  # geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp"),
                   labels = c("original", "imputed")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.3\linewidth}
Estimates can be severely biased.
\end{column}
\end{columns}
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In some settings imputation in wide format may be possible.
\begin{columns}
\begin{column}{0.55\linewidth}
\only<1>{
<<echo = F, fig.with = 6, fig.height = 4>>=
plong1_1
@
}
\only<2>{
<<echo = F, fig.with = 6, fig.height = 4>>=
plong1_1 +
 geom_vline(xintercept = seq(1, 9, 2), lty = 2) +
  scale_x_continuous(breaks = seq(1, 9, 2))
@
}
\end{column}
\begin{column}{0.45\linewidth}
<<echo = F, size = 'scriptsize', warning = F>>=
longdatatab
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

<<size = 'scriptsize', echo = F>>=
subDFexlongwide[c("id",
            paste0("y.", c(1,3,5,7,9)),
            paste0("time.", c(1,3,5,7,9)))] %>%
  round(2) %>%
  rbind(., rep("\\vdots", 11)) %>%
  cbind(., '\\ldots' = rep("\\ldots", 5)) %>%
  kable(format = 'latex', row.names = F, booktabs = T, escape = F)
@
\bigskip

In this dataframe, missing outcome values and measurement times need to be
imputed, even though we would not need to impute them for the analysis
(remember: mixed model valid when outcome measurements are MCAR)

\bigskip

When the data is very unbalanced, i.e., there are no clear cut-offs in time or
transformation to wide format leads to variables with high proportions of missing
data, this is inefficient.

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, cache = T>>=
impwide <- mice(DFexlongwide, printFlag = F, maxit = 10)
@

<<fig.height = 4, fig.width = 5, echo = F, message = F, cache = T>>=
implist <- mice::complete(impwide, 'long') %>% split(., .$.imp)

longList <- lapply(implist, reshape, direction = 'long',
                   varying = list(y = paste0("y.", seq(1, 9, 2)),
                                  time = paste0("time.", seq(1, 9, 2))),
                   v.names = c("y", "time"),
                   timevar = 'tp', drop = ".imp")

midsobj <- miceadds::datalist2mids(longList)

lme_impwide <- with(midsobj, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) + (time|id)))
reswide <- as.data.frame(summary(pool(lme_impwide)))[, c("est", "lo 95", "hi 95")]
reswide$mod <- "impwide"
names(reswide) <- names(resimp)
reswide$var <- rownames(res0)

# library(JointAI)
# resJointAI <- lme_imp(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3), random = ~ time|id,
#         n.iter = 5000, data = DFexlong, quiet = T)
# coefJointAI <- as.data.frame(summary(resJointAI, start = 1000)$stat[, c(1,3,4)])
# coefJointAI$mod <- "JointAI"
# names(coefJointAI) <- names(resimp)
# coefJointAI$var <- rownames(res0)

res2 <- rbind(res, reswide)#, coefJointAI)

ggplot(res2[!res2$var %in% grep("time", res2$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2_origgirl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3_origlow" = "x3 (low)",
                                      "x3_origmid" = "x3 (mid)",
                                      "x4_orig" = "x4"))) +
  geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp", "impwide"),#, "JointAI"),
                   labels = c("orig.", "imp.\nlong", "imp.\nwide")) +#, "JointAI")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.3\linewidth}
Better, but very large confidence intervals.
\end{column}
\end{columns}
\end{frame}


<<simlong2 data, echo = F, fig.with = 6, fig.height = 4>>=
# sim data2 longitudinal --------------------------------------------------------
# set.seed(2241)
# N <- 5
# id <- 1:N
# t1 <- runif(N, 0, 10)
# nj <- sample(5:10, N, replace = T)
# age <- lapply(1:N, function(x) sort(runif(nj[x], min = t1[x], max = t1[x] + nj[x])))
#
# DFexlong2 <- data.frame(id = rep(1:N, sapply(age, length)),
#                  age = unlist(age),
#                  ti = unlist(lapply(nj, seq, from = 1, by = 1))
# )
#
# D <- matrix(nrow = 2, ncol = 2, data = c(0.2, -0.005, -0.005, 0.001))
# b <- MASS::mvrnorm(N, c(0,0), D)
# Z <- model.matrix(~1 + age, DFexlong2)
#
# betas <- c(Intercept = 15,
#            age1 = -0.4, age2 = 0.3, age3 = 0.4
#            )
#
# fmla <- ~ ns(age, df = 3)
# X <- model.matrix(fmla, model.frame(fmla, DFexlong2, na.action = "na.pass"))
#
# DFexlong2$y <- as.numeric(X %*% betas +
#                      rowSums(Z * b[match(DFexlong2$id, unique(DFexlong2$id)), , drop = F]) +
#                      rnorm(nrow(DFexlong2), 0, 0.02))

coefDFexlong2 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ age), coef)))

coefDFexlong22 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ age + I(age^2)), coef)))
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, fig.width = 6, fig.height = 4>>=
plong2_0 <- ggplot(DFexlong2_sub, aes(x = age, y = y, color = factor(id))) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size = 14)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL) +
                     # minor_breaks = seq(from = 4, to = 6, by = 0.02)) +
  scale_x_continuous(breaks = NULL)

plong2_1 <- plong2_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong2_1
@
\end{column}
\begin{column}{0.3\linewidth}
When the measurement time-points do not follow a regular pattern, transformation
to wide format is not possible.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, label = naivelong]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.6\linewidth}
<<trajectories_ignore, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_1 +
  geom_line(data = data.frame(x = c(min(DFexlong2_sub$age), max(DFexlong2_sub$age),
                                    min(DFexlong2_sub$age), max(DFexlong2_sub$age)),
                              y = c(min(DFexlong2_sub$y), max(DFexlong2_sub$y),
                                    max(DFexlong2_sub$y), min(DFexlong2_sub$y)),
                              id = c(1, 1, 2, 2)),
            aes(x = x, y = y, group = factor(id)), color = "red", lwd = 2)
@
\onslide<2->{
<<trajectories_first, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_0 +
  geom_point(data = DFexlong2_sub[DFexlong2_sub$ti == 1, ],
             aes(x = age, y = y, fill = factor(id)),
             size = 8, shape = 21, alpha = 0.5) +
  geom_line(lwd = 1) +
  geom_point(lwd = 2) +
  scale_fill_brewer(palette = "Dark2")
@
}
\end{column}
\begin{column}{0.4\linewidth}
Naive approaches that are sometimes used are to
\begin{itemize}
\item ignore the outcome in the imputation\onslide<2->{, or to}
\item<2-> use only the \blue{first/baseline outcome}
\end{itemize}
\onslide<3>{However, important information may be lost, resulting in invalid
imputations and biased results.}

\end{column}
\end{columns}
\end{frame}



\subsection{Example: Survival data}
<<simSurv, echo = F>>=
library(MASS)
library(splines)
n <- 500 # number of subjects

# parameters for the survival model
phi <- 1.6458 # shape for the Weibull baseline hazard
mean.Cens <- 12 # mean of the exponential distribution for the censoring mechanism

################################################
gammas <- c("(Intercept)" = -5.7296, "Group" = 2.4092, x = 1) # coefficients for baseline covariates

group <- rep(0:1, each = n/2) # group indicator, i.e., '0' placebo, '1' active treatment
x <- rnorm(n)

# design matrix for the survival model
W <- cbind("(Intercept)" = 1,
           "Group" = group,
           x = x)

################################################

# simulate event times
eta.t <- as.vector(W %*% gammas)
invS <- function(t, u, i) {
    h <- function(s) {
        group0 <- 1 - group[i]
        group1 <- group[i]
        exp(log(phi) + (phi - 1) * log(s) + eta.t[i])
    }
    integrate(h, lower = 0, upper = t)$value + log(u)
}
u <- runif(n)
trueTimes <- numeric(n)
for (i in 1:n) {
    Up <- 50
    tries <- 5
    Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    while (inherits(Root, "try-error") && tries > 0) {
        tries <- tries - 1
        Up <- Up + 200
        Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    }
    trueTimes[i] <- if (!inherits(Root, "try-error")) Root else NA
}
na.ind <- !is.na(trueTimes)
trueTimes <- trueTimes[na.ind]
W <- W[na.ind, , drop = FALSE]

n <- length(trueTimes)

# simulate censoring times from an exponential distribution,
# and calculate the observed event times, i.e., min(true event times, censoring times)
Ctimes <- runif(n, 0, 2 * mean.Cens)
Time <- pmin(trueTimes, Ctimes)
event <- as.numeric(trueTimes <= Ctimes) # event indicator

survdat_orig <- data.frame(Time = Time,
                           event = event,
                           group = group[na.ind],
                           x = x[na.ind])

@

<<echo = F>>=
library(survival)
library(mice)

survdat <- survdat_orig
N = n
survdat$x[sample(1:N, N*0.3)] <- NA
survdat$group[sample(1:N, N*0.3)] <- NA

survdat$na <- nelsonaalen(survdat, "Time", "event")
# survdat$event <- factor(survdat$event)

imp00 <- mice(survdat, maxit = 0)
pred0 <- pred1 <- pred2 <- imp00$predictorMatrix

pred0[, c('Time', 'event', 'na')] <- 0
pred1[, c('na')] <- 0
# pred2[, c('Time')] <- 0


imp0 <- mice(survdat, maxit = 10, predictorMatrix = pred0)
imp1 <- mice(survdat, maxit = 10, predictorMatrix = pred1)
# smc <- smcfcs(survdat, smtype = 'coxph',
              # smformula = "Surv(Time, event) ~ group + x",
              # method = c(Time = "", event = "", group = "logreg",
                         # x = 'norm', na = ''), numit = 10
            # )

# impsmc <- miceadds::datalist2mids(smc$impDatasets)


# imp2 <- mice(survdat, maxit = 10, predictorMatrix = pred2)
# imp3 <- mice(survdat, maxit = 10)

cox <- with(survdat_orig, coxph(Surv(Time, as.numeric(event)) ~ x + group))
cox0 <- with(imp0, coxph(Surv(Time, as.numeric(event)) ~ x + group))
cox1 <- with(imp1, coxph(Surv(Time, as.numeric(event)) ~ x + group))
# coxsmc <- with(impsmc, coxph(Surv(Time, as.numeric(event)) ~ x + group))

# cox2 <- with(imp2, coxph(Surv(Time, as.numeric(event)) ~ x + group))
# cox3 <- with(imp3, coxph(Surv(Time, as.numeric(event)) ~ x + group))

rescox0 <- as.data.frame(summary(pool(cox0))[, c("est", "lo 95", "hi 95")])
rescox1 <- as.data.frame(summary(pool(cox1))[, c("est", "lo 95", "hi 95")])
# rescox2 <- as.data.frame(summary(pool(cox2))[, c("est", "lo 95", "hi 95")])
# rescox3 <- as.data.frame(summary(pool(cox3))[, c("est", "lo 95", "hi 95")])
rescox <- as.data.frame(cbind(cox$coef, confint(cox)))
# ressmc <- as.data.frame(summary(pool(coxsmc))[, c("est", "lo 95", "hi 95")])

rescox0$meth <- 0
rescox1$meth <- 1
# rescox2$meth <- 2
# rescox3$meth <- 3
rescox$meth <- "orig"
# ressmc$meth <- 'smc'

rescox$var = rownames(rescox)
rescox0$var = rownames(rescox)
rescox1$var = rownames(rescox)
# ressmc$var = rownames(rescox)
# rescox2$var = rownames(rescox)
# rescox3$var = rownames(rescox)

names(rescox) <- names(rescox0)
plotcox <- rbind(rescox, rescox0, rescox1)#, ressmc)#, rescox2, rescox3)


@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\textcolor{red}{[In survival analysis, the outcome is usually represented by the event (or censoring)
time $T$ and the event indicator $D$.]}

$$h(t\mid x,z) = h_0(t)\exp(\beta_x x + \beta_z z)$$

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<plot surv example, echo = F, fig.width = 6, fig.height = 4>>=
library(ggplot2)
ggplot(plotcox, aes(x = meth, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = `lo 95`, max = `hi 95`)) +
  facet_wrap("var", scales = 'free')

@
\end{frame}



\section{Requirements for MICE to work (well)}
\subsection{Joint and conditional distributions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Recall:} The MICE algorithm is based on the idea of Gibbs sampling.

\bigskip

Gibbs sampling exploits that a joint distribution is fully determined
by its full conditional distributions.

\begin{center}
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white} joint\\distribution}
}
\quad
\parbox[c]{3cm}{
\tikzfancyarrow[3cm]{\scriptsize \textbf{Gibbs}}\\
\onslide<2>{\tikzfancyarrow[3cm, shape border rotate = 180]{\scriptsize \textbf{MICE}}}
}
\quad
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white}full\\conditionals}
}
\end{center}

\onslide<2>{In MICE, the full conditionals are not derived from the joint distribution
but we directly specify the full conditionals and hope a joint distribution exists.}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The uncertainty about whether a joint distribution exists for the specified
set of imputation models is often considered to be mainly a theoretical problem,
since in practice, violations often only have little impact on results derived
from the imputed data.\textcolor{red}{[references]}

\bigskip

However, as we have seen in the examples on the previous slides,
there are settings where the direct specification of the full
conditionals/imputation models may lead to problems, causing biased results.

\end{frame}


\subsection{Some conditions and definitions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two important definitions:

\bigskip


\blue{Compatibility:}
\begin{quote}
A joint distribution exists, that has the full conditionals (imputation models)
as its conditional distributions.
\end{quote}

\blue{Congeniality:}
\begin{quote}
The imputation model is compatible with the analysis model.
\end{quote}

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Important requirements include:}
\begin{itemize}
\item Compatibility
\item Congeniality
\item MAR or MCAR (in the standard implementations)
\item all relevant variables need to be included (that includes the outcome!!!)\\
      (omission might result in MNAR)
\item the imputation models (and analysis model) need to be correctly specified
      (which is a requirement in any standard analysis)
\end{itemize}
\end{frame}


\subsection{Why imputation with MICE can go wrong}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
When incomplete variables have non-linear associations with the outcome,
or with each other, the requirement(s) of \textit{compatibility} and/or
\textit{congeniality} are violated.

\bigskip

Omission, or inadequate inclusion, of the outcome may result in MNAR missing
mechanisms. The same is the case when other relevant predictor variables
are not used as predictor variables in the imputation.
\bigskip

Furthermore, omission of variables may lead to mis-specified models, however,
models may also be mis-specified when all relevant covariates are included,
but distributional assumptions or the specified form of associations are incorrect.
\end{frame}



\section{Alternative imputation approaches}
\subsection{Joint model (multiple) imputation}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To avoid incompatible and uncongenial imputation models, we need to
\begin{itemize}
\item specify the joint distribution
\item and derive full conditionals / imputation models from this joint distribution
\end{itemize}
instead of specifying the directly.

\bigskip

\blue{Problem:}\\
Especially in settings with several variables of mixed type, the joint
distribution is usually not of any known form:

\begin{eqnarray*}
\begin{array}{c}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim N(\mu_2, \sigma_2^2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim N\left(
                \left[
                  \begin{array}{c}
                  \mu_1\\ \mu2
                  \end{array}
                \right], \left[
                            \begin{array}{cc}
                            \sigma_1^2 & \sigma_{12}\\
                            \sigma_{12} & \sigma_2^2
                            \end{array}
                          \right]
              \right)\\[2ex]
\text{\blue{but}\quad}
\begin{array}{l}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim Bin(\mu_2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim ???
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Approach 1: Multivariate Normal Model}\\
Approximate the joint distribution by a known multivariate distribution
\mode<presentation>{
(usually the normal distribution; this is the approach mentioned in Part I
on slide~\ref{jointmodelimp})
}
\mode<article>{
(usually the normal distribution; this is the approach mentioned in Part I
in Section~\ref{subsec:multivarmissing})
}

\bigskip

\blue{Approach 2: Sequential Factorization}\\
Factorize the joint distribution into a (sequence of) conditional and a marginal
distribution(s)
\end{frame}

\subsection{Multivariate Normal Model}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Assumption:}\\
The outcome and incomplete variables follow a joint multivariate normal
distribution, conditional on the completely observed covariates $\mathbf X_c$,
parameters $\bmath\theta$ and possibly random effects, $\bmath b$:
$$ p(\bmath y, \bmath x_1,\ldots, \bmath x_p \mid \mathbf X_c, \bmath\theta,
     \bmath b) \sim N(\bmath \mu, \bmath \Sigma)$$

\bigskip

\onslide<2>{
\textbf{How do we get that multivariate normal distribution?}
\begin{enumerate}
\item Assume \blue{all} incomplete variables and the outcome are \blue{(latent) normal}.
\item specify linear (mixed) \blue{models based on observed covariates}.
\item \blue{Connect} using multivariate normal for \blue{random effects \& error terms}.
\end{enumerate}
}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{1. Latent normal assumption:}\vspace*{-3ex}
$$\text{e.g.: } \bmath x_k \text{ binary }
  \rightarrow \text{ latent } \bmath{\hat x}_k \text{ is standard normal: }
  \left\{\begin{array}{c} \bmath x_k = 1\\ \bmath x_k = 0\end{array}\right.
  \text{ if } \begin{array}{c} \bmath{\hat x_k}\geq 0\\ \bmath{\hat x_k} < 0\end{array}
$$

<<echo = F, fig.width = 6, fig.height = 3, out.width = "70%">>=
par(mar = c(3.5, 3.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
plot(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)), type = "l",
     xlab = expression(hat(x)[k]), ylab = expression(density~of~hat(x)[k]))
polygon(x = c(seq(-4, 0, 0.1), 0),
        y = c(dnorm(seq(-4, 0, 0.1)), 0), col = grey(0.9), border = 'transparent')
polygon(x = c(seq(4, 0, -0.1), 0),
        y = c(dnorm(seq(4, 0, -0.1)), 0), col = grey(0.7), border = 'transparent')
abline(v = 0, lty = 2)
lines(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)))
text(x = -1, y = 0.05, label = bquote(x[k] == 0))
text(x = 1, y = 0.05, label = bquote(x[k] == 1))
@
\textcolor{red}{[examples for categorical data???]}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<1>{\textbf{2. Specify models:}\\}
\only<2>{\textbf{2. Specify models / 3. Connect random effects \& error terms:}\\}
\begin{picture}(200, 100)
\onslide<1->{
\put(0, 60){
    $\addtolength\arraycolsep{-.8ex}
    \begin{array}{rclclcl}
    \bmath y   &=& \bmath X_c \bmath{\tilde\beta}_y     &+& \bmath{\tilde Z_y} \;\bmath{\tilde b_y} &+& \bmath{\tilde \varepsilon_y}\\
    \textcolor{black!50}{\bmath w} &=& \textcolor{black!50}{\bmath X_c \bmath{\tilde\beta}_w}
                                   &+& \textcolor{black!50}{\bmath{\tilde Z_w} \,\bmath{\tilde b_w}}
                                   &+& \textcolor{black!50}{\bmath{\tilde \varepsilon_w}}\\
    \bmath{\hat x}_1 &=& \bmath X_c \bmath{\tilde\beta}_{x_1} &+& \phantom{\bmath Z_w\,} \bmath{\tilde \varepsilon_{x_1}}      &&\\[-1ex]
               & \vdots&                                & & \phantom{\bmath Z_w\;} \vdots                                &&\\[-1ex]
    \bmath{\hat x}_p &=& \bmath X_c \bmath{\tilde\beta}_{x_p} &+& \phantom{\bmath Z_w\,} \bmath{\tilde \varepsilon_{x_p}}      &&
    \end{array}
    $
    }
}
\thicklines
\onslide<2>{
\put(124, 80){\color{red} \oval(15, 32.5)}
\put(96, 62.5){\color{red} \oval(18, 72.5)}
\put(97, 25){\line(0,-1){15}}
\put(97, 10){\vector(1, 0){10}}
\put(110, 7.5){multivariate normal}
%
\put(125, 62.5){\line(0,-1){15}}
\put(125, 47.5){\vector(1, 0){10}}
\put(137.5, 45){multivariate normal (optional, but suggested)}
}
\end{picture}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.5\linewidth}
\blue{Advantages:}
\begin{itemize}
\item Easy to specify
\item Relatively easy to implement
\item Relatively easy to sample from
\item works for longitudinal outcomes
\end{itemize}
\end{column}
\begin{column}{0.5\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item Assumes linear associations
\item ??? survival models
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\subsection{Sequential Factorization}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\onslide<1->{
The joint distribution of two variables $y$ and $x$ can be factorized into
a conditional and a marginal distribution:
$$p(y,x) = p(y\mid x)\;p(x)$$
(or alternatively $p(y,x) = p(x\mid y)\;p(y)$)
}

\bigskip

\onslide<2->{
This can easily be extended for more variables:
$$p(y,x_1,\ldots,x_p, X_c) = \only<2>{p(y\mid x_1,\ldots,x_p, X_c)}
                             \only<3->{\underset{\text{analysis model}}{
                             \underbrace{p(y\mid x_1,\ldots,x_p, X_c)}}}\;
p(x_1\mid x_2,\ldots,x_p, X_c)\;
\ldots\; p(x_p\mid X_c)$$
}
where $x_1, \ldots, x_p$ denote incomplete covariates and $X_c$ contains all
completely observed covariates.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Since the analysis model is one of the building blocks of the joint distribution,
the outcome is automatically included in the imputation procedure.

\bigskip

Because the outcome only appears in the first factor of the sequence (which
is the analysis model), but is not part of the linear predictor of the other
factors, there is no need for summarizing longitudinal or survival outcomes.

\bigskip

When some incomplete covariates have non-linear associations with the outcome
or are involved in interactions, this is automatically included, when it it
specified in the analysis model.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Even though there usually is no closed form for the joint distribution, the
sequence of conditional distribution fully describes it.

\bigskip

However, we can not sample from it directly, but need to use, for instance,
Gibbs sampling to sample from the full conditional distributions that are
derived from the joint distribution.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.5\linewidth}
\blue{Advantages:}
\begin{itemize}
\item Flexible with regards to outcome type
\item univariate conditional distributions of incomplete covariates can be chosen
according to type of variable
\item non-linear associations and interactions can be taken into account
\item assures congeniality and compatible imputation models
\end{itemize}
\end{column}
\begin{column}{0.5\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item separate models need to be specified per incomplete variable: takes more time
and consideration
\item the joint distribution is of unknown form and sampling may be more computationally intensive
\end{itemize}
\end{column}
\end{columns}
\end{frame}



\section{Imputation with non-linear functional forms}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
There is no strategy for MICE that can guarantee valid imputations when
non-linear functional forms and/or interactions are involved,
but some settings in \textbf{mice} may help to reduce bias in the resulting estimates.

\bigskip

For imputation of variables that have non-linear associations
\begin{itemize}
\item \Rstring{pmm} often works better than \Rstring{norm},
\item Just Another Variable approach can reduce bias in interactions,
\item \Rfct{impute.mice.quadratic} can help to impute variables with quadratic association.
% \item inclusion of interaction terms in the imputation model may help.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In the \blue{Just Another Variable (JAV)} approach the non-linear form (or interaction term)
is calculated in the incomplete data, added as a column to the dataset and
imputed as if it was just another variable.

\bigskip

\Rfct{impute.mice.quadratic} provides imputation of covariates that have a
quadratic association with the outcome, using the ``polynomial combination''
method.\cite[pp. 139--141]{Buuren2012}, \cite{Vink2013}.

\bigskip

This is to ensures the imputed values for $x$ and $x^2$ are consistent,
and to reduce bias in the subsequent analysis that uses $x$ and $x^2$.

\bigskip

In my own experience, using \Rstring{quadratic} often has numerical problems.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<>>=
# simulate data
set.seed(2018)
N <- 200
x <- rnorm(N)
z <- rbinom(N, size = 1, prob = plogis(x))
y <- x + x^2 + z + x*z + rnorm(N, 0, 0.5)

DF_nonlin <- data.frame(y = y, x = x, z = z)

# model on complete data
mod_nonlin <- lm(y ~ x + I(x^2) + z + x:z, data = DF_nonlin)

# create missing values
DF_nonlin$x[sample(1:length(x), size = N/2)] <- NA

# naive imputation, using only y, x, z
impnaive <- mice(DF_nonlin, printFlag = F)

@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<>>=
# add quadratic term and interaction to data
DF2 <- DF_nonlin
DF2$xx <- DF2$x^2
DF2$xz <- DF2$x * DF2$z

# JAV imputation
impJAV <- mice(DF2, printFlag = F, maxit = 20)

# add interaction between y and z to data
DF3 <- DF2
DF3$yz <- DF3$y * DF3$z

# JAV imputation with additional interaction
impJAV2 <- mice(DF3, printFlag = F, maxit = 20)

@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<warning = F>>=
# adapt the imputation method for quadratic imputation
methqdr <- impJAV$meth
methqdr[c("x", "xx", "xz")] <- c("quadratic", "~I(x^2)", "~I(x*z)")

# adapt the predictor matrix
predqdr <- impJAV$pred
predqdr[, "xx"] <- 0

impqdr <- mice(DF2, meth = methqdr, pred = predqdr,
               printFlag = F, maxit = 10)
warnings()[1]
@

\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 6, fig.height = 4>>=
res_impnaive <- with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary
res_JAV <- with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_JAV2 <- with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_qdr <- with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

resqdr <- rbind(
  with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary,
  with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

)[, c("est", 'lo 95', 'hi 95')] %>%
  `row.names<-`(1:(4*5)) %>%
  as.data.frame() %>%
  mutate(meth = rep(c("naive", "JAV", "JAV2", "qdr"), each = 5),
         var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), 4),
         beta = rep(coef(mod_nonlin), 4)
  )

polyDF_nonlin <- data.frame(x = rep(c(0, 5, 5, 0), 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"),
                               each = 4)
)

ggplot(resqdr, aes(x = meth, y = est)) +
  geom_polygon(data = polyDF_nonlin,
               aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_point() +
  geom_errorbar(aes(ymin = `lo 95`, ymax = `hi 95`)) +
  facet_wrap("var", scales = 'free') +
  geom_hline(aes(yintercept = beta), lty = 2) +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr")) +
  xlab("imputation method")
@
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
For this example, none of the approaches provided satisfying results.
(To make a more general statement, a simulation study would be needed.)

Note that we used a relatively large proportion of missing values and that not
a lot of additional covariate information was used.

\bigskip

The message is:\\
When incomplete variables are involved in interactions or have non-linear association
with the outcome, you can not be sure that MICE will provide valid imputations.
Since usually we do not know the true values, it is impossible to judge if this
is a problem in a real dataset or how big the resulting bias is.
\end{frame}



\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The package \href{https://cran.r-project.org/web/packages/JointAI/index.html}%
{\textbf{JointAI}} uses the sequential factorization approach to perform
simultaneous analysis and imputation.\cite{Erler2016, Erler2017}

\bigskip

\textbf{JointAI} (version 0.1.0) can handle linear, generalized linear and
linear mixed models, with incomplete covariates, non-linear effects and
interaction terms.

\bigskip

The necessary Gibbs sampling is performed using \textsf{JAGS}, which needs to be
installed from \url{https://sourceforge.net/projects/mcmc-jags/files/}.

\bigskip

The latest development version of \textbf{JointAI} is available from GitHub and
can be installed using
<<eval = F>>=
install.packages("devtools")
devtools::install_github(repo = "JointAI", username = "NErler")
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To analyze \& impute the current example:
<<JointAI_nonlin, eval = F>>=
library(JointAI)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF, n.iter = 2500)

# to check convergence:
traceplot(JointAI_nonlin)
@

<<runJointAI_nonlin, eval = F, echo = F>>=
library(JointAI)
set.seed(1234)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF_nonlin, n.iter = 2500)
save(JointAI_nonlin, file =  "workspaces/JointAI_nonlin.RData")
@

<<getJointAI_nonlin, echo = F>>=
load("workspaces/JointAI_nonlin.RData")
@
To obtain the results (no separate analysis \& pooling is necessary):
<<>>=
res_JointAI_nonlin <- summary(JointAI_nonlin)
@

\end{frame}


\subsection{R package smcfcs}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The \textsf{R} package
\href{https://cran.r-project.org/web/packages/smcfcs/index.html}{\textbf{smcfcs}}
performs imputation using
``substantive model compatible fully conditional specification'', a hybrid
approach between FCS and sequential factorization.\cite{Bartlett2015}

\bigskip
\textbf{smcfcs} (version 1.3.0) can handle linear, logistic,
poisson regression as well as Cox proportional hazard and competing risk
survival models.

\bigskip

For more information see the
\href{https://cran.r-project.org/web/packages/smcfcs/vignettes/smcfcs-vignette.html}%
{\dotuline{vignette}}.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To impute data in the current example:
<<smcfcs_nonlin, eval = F>>=
library(smcfcs)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)

# to check convergence:
par(mfrow = c(2,3), mar = c(2, 2, 0.5, 0.5), mgp = c(2, 0.6, 0))
for(i in 1:dim(smcfcs_nonlin$smCoefIter)[2]) {
  matplot(t(smcfcs_nonlin$smCoefIter[, i, ]), type = 'l', ylab = '')
}
@

<<smcfcs_nonlin_run, eval = F, echo = F>>=
library(smcfcs)
set.seed(2018)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)
save(smcfcs_nonlin, file = 'workspaces/smcfcs_nonlin.RData')
@

<<smcfcs_nonlin_get, echo = F, include = F>>=
library(smcfcs)
load("workspaces/smcfcs_nonlin.RData")
impobj_smcfcs_nonlin <- mitools::imputationList(smcfcs_nonlin$impDatasets)
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- invisible(summary(mitools::MIcombine(models_smcfcs_nonlin)))
@

To analyze \& pool the imputed data:
<<smcfcs_nonlin_pool, eval = F>>=
impobj_smcfcs_nonlin <- mitools::imputationList(smcfcs_nonlin$impDatasets)
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- summary(mitools::MIcombine(models_smcfcs_nonlin))
@
\end{frame}



\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The \textsf{R} package
\href{https://cran.r-project.org/web/packages/jomo/index.html}{\textbf{jomo}}
performs \blue{joint model imputation} using the multivariate normal approach,
with extensions to assure compatibility of the imputations with the analysis model.

\bigskip

\textbf{jomo} (version 2.5-2) can handle linear, generalized linear,
linear mixed, generalized linear mixed and Cox proportional hazards models.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To impute the data in the current example:
<<jomo_nonlin, eval = F>>=
library(jomo)
jomo_nonlin <- jomo.lm(y ~ x*z + I(x^2), data = DF_nonlin)

# to check convergence
jomo_nonlinMCMC <- jomo.lm.MCMCchain(y ~ x*z + I(x^2), data = DF_nonlin)
par(mfrow = c(2, 2), mar = c(3, 2.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
apply(jomo_nonlinMCMC$collectbeta[1, ,], 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
apply(jomo_nonlinMCMC$collectomega, 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
@

<<jomo_nonlin_run, echo = F, eval = F>>=
library(jomo)
set.seed(2018)
jomo_nonlinMCMC <- jomo.lm.MCMCchain(y ~ x*z + I(x^2), data = DF_nonlin)
jomo_nonlin <- jomo.lm(y ~ x*z + I(x^2), data = DF_nonlin)
save(jomo_nonlin, jomo_nonlinMCMC, file = "workspaces/jomo_nonlin.RData")
@

<<jomo_nonlin_get, echo = F, include = F>>=
library(jomo)
load("workspaces/jomo_nonlin.RData")
impobj_jomo_nonlin <- mitools::imputationList(split(jomo_nonlin,
                                                    jomo_nonlin$Imputation)[-1])
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(mitools::MIcombine(models_jomo_nonlin))
@

To analyze \& pool the imputed data:
<<eval = F>>=
impobj_jomo_nonlin <- mitools::imputationList(split(jomo_nonlin,
                                                    jomo_nonlin$Imputation)[-1])
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(mitools::MIcombine(models_jomo_nonlin))
@

\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, figwidth = 6, fig.height = 4.5>>=
res_nonlin <- list(naive = as.data.frame(res_impnaive[, c("est", "lo 95", "hi 95")]),
                   JAV = as.data.frame(res_JAV[, c("est", "lo 95", "hi 95")]),
                   JAV2 = as.data.frame(res_JAV2[, c("est", "lo 95", "hi 95")]),
                   qdr = as.data.frame(res_qdr[, c("est", "lo 95", "hi 95")]),
                   JointAI = as.data.frame(res_JointAI_nonlin$stat[, c(1,3,4)]),
                   smcfcs = res_smcfcs_nonlin[, c(1, 3, 4)],
                   jomo = res_jomo_nonlin[, c(1, 3, 4)])

res_nonlin <- lapply(res_nonlin, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- gsub("xx", "I(x^2)", rownames(x)) %>%
    gsub("xz", "x:z", .)
  x
})

plot_nonlin <- reshape2::melt(res_nonlin, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_nonlin) + .5)[c(1,2,2,1)], 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), each = 4)
)

ggplot(plot_nonlin, aes(x = L1, y = coef)) +
  geom_point() +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = coef(mod_nonlin),
                               var = names(coef(mod_nonlin))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr",
                              "JointAI", "smcfcs", "jomo")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
\end{frame}


\section{Longitudinal data}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{mice} has functions to allow imputation of longitudinal (2-level) data.
\begin{itemize}
\item \blue{Level 1:}\\
repeated measurements (within subjects) or subjecs (within classes)
\item \blue{Level 2:}\\
subjects (that have repeated measurements) or classes/groups (containin several
subjects)
\end{itemize}

\bigskip

Functions for impuation of \blue{level-1} variables:
\begin{itemize}
\item \Rfct{mice.impute.2l.pan}
\item \Rfct{mice.impute.2l.norm}
\item \Rfct{mice.impute.2l.lmer}
\end{itemize}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rfct{mice.impute.2l.pan} implements a linear two-level model with \blue{homogeneous
within group variances} using Gibbs sampling \cite{Schafer2002}.
It needs the package \textbf{pan} to be installed.

\bigskip

\Rfct{mice.impute.2l.pan} allows different roles of predictor variables, that
can be specified as different values in the \Rarg{predictorMatrix}:
\begin{itemize}
\item grouping variable: -2
\item random effects (also included as fixed effects): 2
\item fixed effets of group means: 3
\item fixed effects of group means \& random effects: 4
\end{itemize}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rfct{mice.impute.2l.norm} implements a (Bayesian) linear two-level model with
\blue{heterogenous} group variances

In the current implementation all predictors should be specified as random
effects (set to 2 in the \Rarg{predictorMatrix}, because the algorithm does not
handle predictors that are specified as fixed effects.)

\bigskip

\Rfct{mice.impute.2l.lmer} imputes univariate systematically and sporadically
missing data using a two-level normal model using \Rfct{lmer} from package
\textbf{lme4} (developed in the context of individual patient meta analysis.
\cite{Jolani2015, Jolani2018})
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Functions for impuation of \blue{level-2} variables:
\begin{itemize}
\item \Rfct{mice.impute.2lonly.norm}
\item \Rfct{mice.impute.2lonly.pmm}
\item \Rfct{mice.impute.2lonly.mean}
\end{itemize}

\bigskip

\Rfct{mice.impute.2lonly.norm} and \Rfct{mice.impute.2lonly.pmm} implement
Bayesian linear regression analysis and predictive mean matching, respectively,
to impute level-2 variables (in combination with \Rfct{mice.impute.2l.pan} for
level-1 variables\cite{Yucel2008}).

\bigskip

The group identifier ("id" variable") needs to be set to -2 in the \Rarg{predictorMatrix}.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rfct{mice.impute.2lonly} imputes values with the mean of the observed values per
class. This function should only be used to fill in values that are known to be
constant per class and have some values observed in each class.

\bigskip

\textbf{Example:}
In a multi-center trial the type of some medical equipment is known to be
the same for all patients treated in the same hospital, but not filled in for
some patients.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<micelong_ex1, eval = F>>=
##################################################
# simulate some data: two-level regression model with fixed slope
# x,y ... level 1 variables
# v,w ... level 2 variables
G <- 250 # number of groups
n <- 20 # number of persons
beta <- .3 # regression coefficient
rho <- .30 # residual intraclass correlation
rho.miss <- .10 # correlation with missing response
missrate <- .50 # missing proportion

# random intercept + residual
y1 <- rep(rnorm(G, sd = sqrt(rho)), each = n) + rnorm(G*n, sd = sqrt(1 - rho))

# covariates
w <- rep(round(rnorm(G), 2), each = n)
v <- rep(round(runif(G, 0, 3)), each = n)
x <- rnorm(G*n)

# calculate the outcome
y <- y1 + beta * x + .2 * w + .1 * v
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<micelong_ex1cont, eval = F>>=
# combine to data set
dfr0 <- dfr <- data.frame("group" = rep(1:G, each = n), # id variable
                          "x" = x,
                          "y" = y,
                          "w" = w,
                          "v" = factor(v, levels = 1:4, labels = LETTERS[1:4])
)

# create missing values in y, w and v
dfr[rho.miss * x + rnorm(G*n, sd = sqrt(1 - rho.miss)) < qnorm(missrate), "y"] <- NA
dfr[rep(rnorm(G), each = n) < qnorm(missrate), "w"] <- NA
dfr[rep(rnorm(G), each = n) < qnorm(missrate), "v"] <- NA

# empty mice imputation
imp0 <- mice(as.matrix(dfr), maxit = 0)
predM <- imp0$predictorMatrix
impM <- imp0$method
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<micelong_ex1_cont2, eval = F>>=
# settings for multilevel imputation
# y ... imputation using pan
# w ... imputation at level 2 using norm
# v ... imputation at level 2 using pmm
predM1 <- predM
predM1[c("w","y","v"), "group"] <- -2
predM1["y", "x"] <- 1 # fixed x effects imputation
impM1 <- impM
impM1[c("y","w","v")] <- c("2l.pan", "2lonly.norm", "2lonly.pmm")

imp <- mice(dfr, m = 5, predictorMatrix = predM1 ,
            imputationMethod = impM1, maxit = 10, paniter = 500)


# multilevel analysis
library(lme4)
mod <- with(imp, lmer(y ~ x + v + w + (1 + x | group)))
summary(pool(mod))
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<micelong_ex1_cont3, eval = F>>=
# Examples of predictorMatrix specification
# random x effects
predM1["y","x"] <- 2
# fixed x effects and group mean of x
predM1["y","x"] <- 3
# random x effects and group mean of x
predM1["y","x"] <- 4
@
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Currently, there is only limited documentation on how to use these functions
in \textbf{mice} and technical details can only be obtained from the methodologic
references.


The
\href{https://gerkovink.github.io/miceVignettes/Multi_level/Multi_level_data.html}{\dotuline{vignette}} on multi-level imputation shows a more elaborate example of how
to analyze such data.
%\textcolor{red}{[which did not run when I tried on march 29, 2018]}
\end{frame}

<<eval = F, echo = F, cache = T>>=
DFexlong_orig$x5 <- DFexlong$x5 <- rnorm(nrow(DFexlong), 35, 6)
DFexlong$x5[sample.int(nrow(DFexlong), 0.3 * nrow(DFexlong))] <- NA
imp0 <- mice(DFexlong, maxit = 0)

pred <- imp0$predictorMatrix
meth <- imp0$method

# multilevel imputation
pred[ ,"id"] <- -2
pred[ , c("ti", "tp")] <- 0
pred[pred == 1] <- 2 # curently, the advice is to specify everything as random
                     # effect because 2l.norm can't handle fixed effects

meth[c("x2", "x3", "x4")] <- "2lonly.pmm"
meth1 <- meth2 <- meth3 <- meth
meth1["x5"] <- "2l.norm"
meth2["x5"] <- "2l.pan"
meth3["x5"] <- "2l.pmm"

implong1 <- mice(DFexlong, method = meth1, predictorMatrix = pred, m = 10, maxit = 10)
implong2 <- mice(DFexlong, method = meth2, predictorMatrix = pred, m = 10, maxit = 10)
implong3 <- mice(DFexlong, method = meth3, predictorMatrix = pred, m = 10, maxit = 10)

mod_mice1 <- with(implong1, lmer(y ~ x1 + x2 + x3 + x4 + x5 +
                                   ns(time, df = 3) + (time|id)))
mod_mice2 <- with(implong2, lmer(y ~ x1 + x2 + x3 + x4 + x5 +
                                   ns(time, df = 3) + (time|id)))
mod_mice3 <- with(implong3, lmer(y ~ x1 + x2 + x3 + x4 + x5 +
                                   ns(time, df = 3) + (time|id)))

mod_long <- with(DFexlong_orig, lmer(y ~ x1 + x2 + x3 + x4 + x5 +
                                   ns(time, df = 3) + (time|id)))
@
<<eval = F, echo = F, fig.width = 6, fig.height = 4>>=
reslong <- list(obs = as.data.frame(cbind(fixef(mod_long),
                            confint(mod_long, parm = names(fixef(mod_long)),
                                    method = "Wald"))),
                mice1 = as.data.frame(summary(pool(mod_mice1)
                                             )[, c("est", "lo 95", "hi 95")]),
                mice2 = as.data.frame(summary(pool(mod_mice2)
                )[, c("est", "lo 95", "hi 95")]),
                mice3 = as.data.frame(summary(pool(mod_mice3)
                )[, c("est", "lo 95", "hi 95")]))


reslong <- lapply(reslong, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  # x$var <- gsub("xx", "I(x^2)", rownames(x)) %>%
  #   gsub("xz", "x:z", .)
  x
})

plot_long <- reshape2::melt(reslong, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(reslong) + .5)[c(1,2,2,1)], 10),
                     y = c(apply(confint(mod_long, method = "Wald",
                                         parm = names(fixef(mod_long))),
                                 1, rep, each = 2)),
                     var = rep(reslong[[1]]$var, each = 4)
)

ggplot(plot_long, aes(x = L1, y = coef)) +
  geom_point() +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = fixef(mod_long),
                               var = names(fixef(mod_long))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  # scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr",
  #                             "JointAI", "smcfcs", "jomo")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}


\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In settings where the available multi-level functions do not work satisfactorily,
e.g., when level-1 variables do not fit the assumptions of a normal model,
an alternative is needed.
A possible work-around for settings with unbalanced longitudinal data
builds on the naive approaches to impute multi-level data in wide format.

\bigskip

The problem with the naive methods mentioned above on slide~\ref{naivelong}
\textcolor{red}{[link for article version]})
is that important information is lost (e.g., when excluding the outcome from
imputation) and that the chosen value may not have the same meaning for all
subjects (e.g. when the first value is used but does not represent a
common baseline time).

\bigskip

A better summary of the longitudinal outcome (and other longitudinal
variables) needs to have the \blue{same number of parameters/components} for all subjects,
such that all of those components have the \blue{same interpretation} for all subjects,
and captures the relevant features of the longitudinal variables.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\begin{columns}
\begin{column}{0.3\linewidth}
One idea is to get an estimate of the underlying trajectories of the
longitudinal measurements, e.g. with a mixed model.
\end{column}
\begin{column}{0.7\linewidth}
<<trajectories_fit_, echo = F, fig.with = 6, fig.height = 4>>=
coefDFexlong2 <- as.data.frame(t(sapply(lapply(split(DFexlong2_sub,
                                                     DFexlong2_sub$id),
                                               lm, formula = y ~ age), coef)))
coefDFexlong2$id <- as.numeric(unique(DFexlong2_sub$id))

coefDFexlong22 <- as.data.frame(t(sapply(lapply(split(DFexlong2_sub,
                                                      DFexlong2_sub$id),
                                                lm, formula = y ~ age + I(age^2)), coef)))
coefDFexlong22$id <- as.numeric(rownames(coefDFexlong22))

plong2_1 +
  geom_abline(data = coefDFexlong2,
              aes(intercept = `(Intercept)`, slope = age,
                  color = factor(id)),
              lty = 2, lwd = 1)
@
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Individual trajectories can then be summarized by their random effects, e.g.:
\begin{columns}
\begin{column}{0.3\linewidth}
\begin{itemize}
\item<1-> their random intercept
\item<2> their random intercept and slope
\end{itemize}
\end{column}
\begin{column}{0.7\linewidth}
\only<1>{
<<trajectories_ri, echo = F, fig.with = 6, fig.height = 4.5>>=
plong2_2 <- plong2_1 +
  geom_point(data = coefDFexlong2, aes(x = 0, y = `(Intercept)`,
                                       fill = factor(id)),
             size = 8,
             shape = 21, alpha = 0.5) +
  geom_abline(data = coefDFexlong2,
              aes(intercept = `(Intercept)`, slope = age,
                                 color = factor(id)), lty = 2, lwd = 1) +
  scale_fill_brewer(palette = "Dark2")

plong2_2
@
}
\only<2>{
<<trajectories_ris, echo = F, fig.width = 6, fig.height = 4>>=
starttri <- c(1, 1, 2, 1, 1, 1)
endtri <- starttri + 4

polyDFexlong2 <- data.frame(x = c(starttri, endtri, endtri),
                            y = c(rep(coefDFexlong2$`(Intercept)` +
                                        starttri*coefDFexlong2$age, 2),
                                  coefDFexlong2$`(Intercept)` +
                                    coefDFexlong2$age * endtri
                            ),
                            id = rep(unique(DFexlong2_sub$id), 3)
)

plong2_2 + geom_polygon(data = polyDFexlong2,
                        aes(x = x, y = y, group = factor(id),
                            fill = factor(id)),
                        alpha = 0.5)
@
}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
However, in this examples a random intercept \& slope model does not capture the
curvature of the individual trajectories.

\begin{columns}
\begin{column}{0.25\linewidth}
In the current example, random intercepts and random effects for $age$ and $age^2$
give a better representation of the trajectories.
\end{column}
\begin{column}{0.7\linewidth}
<<trajectories_fit_2, echo = F, fig.with = 6, fig.height = 4.5>>=
plong2_1 +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = F, lty = 2,
              fullrange = TRUE, alpha = 0.2)
@
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The models used to obtain the summary of the trajectories may also contain
completely observed covariates, e.g.:
<<eval = F>>=
# fit mixed model on long-format data
out <- lmer(y ~ sex + gestbir + age + I(age^2) + (age + I(age^2)|id),
            data = longDF)

# extract the random effects
out_summary <- ranef(out)$id
names(out_summary) <- c("b0", "b1", "b2")

# add the random effects to the wide-format data for imputation
# data can be transformed with function reshape()
impDF <- cbind(wideDF, out_summary)

# for analysis, data needs to be transformed back to long format
@
\end{frame}


\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Approximately normally distributed longitudinal data can also be imputed and
analyzed using the package \textbf{JointAI}.

\bigskip

The syntax is analogous the syntax used in \Rfct{lme} of the package \textbf{nlme}.

\bigskip

Currently, imputation is only possible for cross-sectional covariates, but
longitudinal covariates that are completely observed can be included.
The random effects structure is restricted to 2-levels, but may contain various
functional forms.

\bigskip

Contrary to the two-level imputation of \textbf{mice}, non-linear associations
are appropriately handled to avoid bias (as discussed above).\textcolor{red}{[reference]}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<JointAI_long, eval = F>>=
# create a time-varying covariate
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2*x4 + ns(age, df = 3),
                        random = ~ns(age, df = 3)|id, data = DFexlong2,
                        n.iter = 2500)

res_JointAI_long <- summary(JointAI_long)
@

<<JointAI_long_run, eval = F, echo = F>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2*x4 + ns(age, df = 3),
                        random = ~ns(age, df = 3)|id, data = DFexlong2,
                        n.iter = 2500, meth = c(x3 = "cumlogit", x2 = "logit"))

save(JointAI_long, file = "workspaces/JointAI_long.RData")
@

<<JointAI_long_get, echo = F>>=
load("workspaces/JointAI_long.RData")
res_JointAI_long <- summary(JointAI_long)
@
\end{frame}


\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using the functions \Rfct{jomo.lmer} or \Rfct{jomo.glmer} longitudinal data
with normal or non-normal variables can be imputed.
As in the examples for non-linear functional forms, congeniality of imputation
models is maintained.

<<jomo_long, eval = F>>=
library(jomo)
lvl <- c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2, x4 = 1, age = 1)
jomo_long <- jomo.lmer(formula = y ~ x1 + as.numeric(x3) +
                         as.numeric(x2)*x4 +
                         ns(age, df = 3) + (ns(age, df = 3)|id),
                       data = DFexlong2[, names(lvl)], level = lvl)
@

<<jomo_long_run, eval = F, echo = F>>=
library(jomo)
jomo_long <- jomo.lmer(formula = y ~ x1 + as.numeric(x3) + as.numeric(x2)*x4 +
                         ns(age, df = 3) + (ns(age, df = 3)|id),
                       data = DFexlong2[, c("id", "y", paste0("x", 1:4),
                                            "age")],
                       level = c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2,
                                 x4 = 1, age = 1)
)

jomo_longMCMC <- jomo.lmer.MCMCchain(formula = y ~ x1 + as.numeric(x2)*x4 +
                                       as.numeric(x3) +
                                       ns(age, df = 3) + (ns(age, df = 3)|id),
                                     data = DFexlong2[, c("id", "y", paste0("x", 1:4),
                                                          "age")],
                                     level = c("id" = 1, y = 1, x1 = 2, x2 = 2,
                                               x3 = 2, x4 = 1,
                                               age = 1)
)

save(jomo_long, jomo_longMCMC, file = 'workspaces/jomo_long.RData')
@

<<jomo_long_get, echo = F>>=
load('workspaces/jomo_long.RData')
@

<<>>=
library(miceadds)
impobj_jomo_long <- datalist2mids(split(jomo_long,
                                        jomo_long$Imputation)[-1])
models_jomo_long <- with(impobj_jomo_long,
                         lmer(y ~ x1 + x3 + x2*x4 + ns(age, df = 3) +
                                (ns(age, df = 2)|clus)))

res_jomo_long <- summary(pool(models_jomo_long))
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, figwidth = 6, fig.height = 4.5>>=
mod_long2 <- with(DFexlong2_orig, lmer(y ~ x1 + x3 + x2*x4 + ns(age, df = 3) +
                                         (ns(age, df = 3)|id)
                                       ))
# res_long2 <- cbind(fixef(mod_long2),
#                    confint(mod_long2, method = "Wald",
#                            parm = names(fixef(mod_long2))))

res_long2 <- list(JointAI = as.data.frame(res_JointAI_long$stat[, c(1,3,4)]),
                   # smcfcs = res_smcfcs_long[, c(1, 3, 4)],
                   jomo = as.data.frame(res_jomo_long)[, c("est", "lo 95", "hi 95")])

res_long2 <- lapply(res_long2, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  # x$var <- gsub("xx", "I(x^2)", rownames(x)) %>%
  #   gsub("xz", "x:z", .)
  x
})

plot_long <- reshape2::melt(res_long2, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_long2) + .5)[c(1,2,2,1)], 5),
                     y = c(apply(confint(mod_long2, method = "Wald",
                           parm = names(fixef(mod_long2))), 1, rep, each = 2)),
                     var = rep(names(fixef(mod_long2)), each = 4)
)

ggplot(plot_long, aes(x = L1, y = coef)) +
  geom_point() +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  # geom_hline(data = data.frame(betas = coef(mod_long),
                               # var = names(coef(mod_long))),
             # aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  # scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr",
  #                             "JointAI", "smcfcs", "jomo")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
\end{frame}

\section{Survival data}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
White et al. \cite{White2009} have investigated imputation of survival data.
They considered a range of combinations and transformation of survival time
and event indicator, to include in the imputation.

\bigskip

Their advice is to use the event indicator together with the Nelson-Aalen estimate.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In \textbf{mice}, the function \Rfct{nelsonaalen} can be used to calculate the
Nelson-Aalen estimator. This variable can then be added as a column to the
dataset and used as predictor in the imputation models.
\end{frame}




\section{Some general notes}
\begin{frame}
The packags are young and research is ongoing. There may be problems, errors, etc.

\end{frame}

