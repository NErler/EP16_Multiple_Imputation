\begin{frame}[allowframebreaks=0.75]{Outline of Part III}
\tableofcontents[part=3, sections={12-14}]
\framebreak
\tableofcontents[part=3, sections={15-16}]
\framebreak
\tableofcontents[part=3, sections={17-18}]
\end{frame}

<<packages part3, echo = F>>=
library(knitr)
library(kableExtra)
library(plyr)
library(RColorBrewer)
library(magrittr)
library(kableExtra)
library(ggplot2)
library(splines)
library(dplyr)
library(mice)
library(miceadds)
library(lme4)
library(knitr)

source(file.path(projdir, "Slides", "Rfcts/make_exampledata.R"))
@

\section{Settings where MICE may have problems}
\subsection{Example: Quadratic effect}
<<example_quadratic_bias, echo = F>>=
# sim data quadratic -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
y <- -1 - 0.6 * x + 0.5 * x^2 + rnorm(N, 0, 0.2)

DFexqdr <- data.frame(y = y, x = x)
DFexqdr$xmis <- DFexqdr$x
DFexqdr$xmis[sample(1:length(x), size = N/2, prob = plogis(5 * DFexqdr$y))] <- NA

impmod <- lm(xmis ~ y, DFexqdr)
imps <- predict(impmod, newdata = DFexqdr[is.na(DFexqdr$xmis), ]) +
  rnorm(sum(is.na(DFexqdr$xmis)), 0, summary(impmod)$sigma)

DFexqdr$ximp <- DFexqdr$xmis
DFexqdr$ximp[is.na(DFexqdr$xmis)] <- imps

lm0 <- lm(y ~ x + I(x^2), DFexqdr)
lm_imp <- lm(y ~ ximp + I(ximp^2), DFexqdr)
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Consider the case where the \blue{analysis model} (which we assume to be true)
is
$$y = \beta_0 + \beta_1 x + {\color{darkred}\bmath{\beta_2 x^2}} + \ldots,$$
i.e., $y$ has a \blue{quadratic relationship} with $x$, and $x$ is incomplete.

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr1, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 <- ggplot(DFexqdr, aes(x = x, y = y,
                               color = is.na(xmis),
                               shape = is.na(xmis))) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.1, 0.15),
        legend.background = element_rect(fill = 'transparent'),
        legend.text = element_text(size = 12),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        axis.ticks = element_blank())

pexqdr1 +
  scale_color_manual(name = "",
                     limits = c(F, T),
                     values = c("black", "black"),
                     labels = c("observed", "missing")) +
  scale_shape_manual(name = "",
                     limits = c(F, T),
                     values = c(19, 1),
                     labels = c("observed", "missing"))

@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The original data show a curved pattern.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to \blue{impute $x$} when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \ldots,$$
i.e., a \blue{linear relation} between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr2, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 + geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
                     aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "black", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed"))
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The imputed values \blue{distort the curved pattern} of the original data.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
% Analysis and imputation model contradict each other.
%
% No joint distribution exists that has the conditional distributions resulting
% from these models as its conditional distributions.
%
% \blue{\ding{225}} The imputation model for $x_1$ is \blue{uncongenial}.\\
% \blue{\ding{225}} Analysis of the imputed data leads to biased results.

The model fitted on the imputed data gives \blue{severely biased results}; the
non-linear shape of the curve has almost completely disappeared.

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr3, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 +
  geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
             aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  geom_smooth(aes(group = "1", linetype = "ltycompl"), color = 'darkred',
              method = "lm", formula = y~x + I(x^2), se = F, lwd = 1.5) +
  geom_smooth(data = DFexqdr, aes(x = ximp, y = y, group = '1',
                                  linetype = "ltyimp"),
              color = 'darkred', se = F, lwd = 1.5,
              method = "lm", formula = y~x + I(x^2)) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "black", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed")) +
  scale_linetype_manual(name = "",
                        limits = c('ltycompl', 'ltyimp'),
                        values = c(1, 2),
                        labels = c("fit on complete", "fit on imputed")) +
  theme(legend.key.width = unit(1.5,"cm"),
        legend.title = element_blank(),
        legend.position = c(0.17, 0.17),
        legend.spacing.y = unit(-0.3, "lines")
  ) +
  expand_limits(y = -2)
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<restab_qdr, echo = F, size = 'scriptsize'>>=
tabexqdr <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'x2'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  3, "Imputed" = 3))# %>%

tabexqdr %>%
  gsub("x2", "$x^2$", .) %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Example: Interaction effect}
<<example_interact_bias, echo = F, include = F, fig.width = 6, fig.height = 4, fig.keep = "high">>=
# sim data interact -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
z <- rbinom(N, size = 1, prob = 0.5)
y <- -1 - 0.6 * x + 0.5 * z + x*z + rnorm(N, 0, 0.2)

DFexint <- data.frame(y = y, x = x, z = z)
DFexint$xmis <- DFexint$x
DFexint$xmis[sample(1:length(x), size = N/2, prob = plogis(2 * DFexint$y))] <- NA

impmod <- lm(xmis ~ y + z, DFexint)
impmod2 <- lm(xmis ~ y*z, DFexint)

impresid <- rnorm(sum(is.na(DFexint$xmis)), 0, summary(impmod)$sigma)

imps <- predict(impmod, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid
imps2 <- predict(impmod2, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid

DFexint$ximp <- DFexint$ximp2 <- DFexint$xmis
DFexint$ximp[is.na(DFexint$xmis)] <- imps
DFexint$ximp2[is.na(DFexint$xmis)] <- imps2

lm0 <- lm(y ~ x*z, DFexint)
lm_imp <- lm(y ~ ximp*z, DFexint)
lm_imp2 <- lm(y ~ ximp2*z, DFexint)

# xp <- seq(from = -1.5, to = 1.5, by = 0.1)
#
# yp0 <- predict(lm0, newdata = data.frame(x = xp, z = 0))
# yp1 <- predict(lm0, newdata = data.frame(x = xp, z = 1))
#
# yimp0 <- predict(lm_imp, newdata = data.frame(ximp = xp, z = 0))
# yimp1 <- predict(lm_imp, newdata = data.frame(ximp = xp, z = 1))
#
# yimp20 <- predict(lm_imp2, newdata = data.frame(ximp2 = xp, z = 0))
# yimp21 <- predict(lm_imp2, newdata = data.frame(ximp2 = xp, z = 1))
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another example occurs with an analysis model (again, assumed to be true)
is
$$y = \beta_0 + \beta_x x + \beta_z z + {\color{darkred}\bmath{\beta_{xz} xz}} + \ldots,$$
i.e., $y$ has a \blue{non-linear relationship} with $x$ due to the
\blue{interaction term}.


\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int1, echo = F, fig.width = 6, fig.height = 4>>=
plotexint <- reshape2::melt(DFexint, id.vars = c("y", "z", "ximp2", "xmis"))
plotexint$combi <- paste0(plotexint$variable, "_",
                          ifelse(is.na(plotexint$xmis), "mis", "obs"), plotexint$z)

ggplot(plotexint[plotexint$variable == "x", ], aes(x = value, y = y,
                                                   color = combi,
                                                   shape = combi)) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.13, 0.15),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 12),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  xlab("x") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c(1, 1, 19, 19),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c("blue", "darkgreen", "blue", "darkgreen"),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)"))
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The orignal data shows a ``$<$'' shaped pattern.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to impute $x$ when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \theta_{12} z + \ldots,$$
i.e., a linear relation between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}

<<plot_int2, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi)) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.13, 0.18),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 12),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 8, 8),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "darkgreen"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  expand_limits(y = -2) +
  xlab("x")
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The ``$<$'' shaped pattern of the true data is \blue{distorted by the imputed values}.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
And the analysis on these naively imputed values leads to \blue{severely biased estimates}.

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int3, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi)) +
  geom_point(size = 2, alpha = 0.3) +
  geom_smooth(data = plotexint[plotexint$z == "0", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'blue') +
  geom_smooth(data = plotexint[plotexint$z == "1", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'darkgreen') +
  theme_light() +
  theme(legend.position = c(0.23, 0.18),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 12),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal",
        legend.key.width = unit(1,"cm")
        ) +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 8, 8),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "darkgreen"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_linetype_manual(name = "",
                        limits = c("x", "ximp"),
                        values = c(1, 2),
                        labels = c("true",  "imputed")) +
  expand_limits(y = -2, x = -1.8) +
  xlab("x")
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<echo = F, size = 'scriptsize'>>=
restab_interact <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'z', 'x:z'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  4, "Imputed" = 4))

restab_interact %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}




\subsection{Example: longitudinal outcome}
<<simlong data, echo = F, fig.with = 6, fig.height = 4>>=
IDs <- c(5, 6, 7, 8, 18)
subIDs <- IDs[IDs != 7]
subDFexlong <- DFexlong[DFexlong$id %in% IDs, ]

DFexlongwide <- reshape(DFexlong, direction = 'wide', v.names = c("y", "time"), idvar = "id",
                  timevar = 'ti', drop = "tp")
subDFexlongwide <- DFexlongwide[DFexlongwide$id %in% subIDs, ]


coefDFexlong <- as.data.frame(t(sapply(lapply(split(subDFexlong, subDFexlong$id),
                                        lm, formula = y ~ time), coef)))
coefDFexlong$ID <- IDs


ltDFexlong <- subDFexlong[subDFexlong$id != 7,
                          c("id", "y", paste0("x", 1:4), "time")]
ltDFexlong$time <- sprintf(ltDFexlong$time, fmt = "%.2f")
ltDFexlong$y <- "\\checkmark"
ltDFexlong$x1 <- "\\checkmark"
ltDFexlong$x2 <- as.character(ltDFexlong$x2)
ltDFexlong$x2[!is.na(ltDFexlong$x2)] <- "\\checkmark"
ltDFexlong$x3 <- as.character(ltDFexlong$x3)
ltDFexlong$x3[!is.na(ltDFexlong$x3)] <- "\\checkmark"
ltDFexlong$x4[!is.na(ltDFexlong$x4)] <- "\\checkmark"

ltDFexlong <- rbind(ltDFexlong, rep("\\vdots", 7))


colvec <- brewer.pal(length(IDs), "Dark2")
@



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another setting where imputation with MICE is not straightforward is when
the \blue{outcome variable is longitudinal}.
\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
<<trajectories, echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_0 <- ggplot(subDFexlong, aes(x = time, y = y, color = factor(id))) +
  theme(legend.position = "none",
        axis.title = element_text(size = 15),
        axis.text = element_text(size = 12)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL,
                     minor_breaks = seq(from = 4, to = 6, by = 0.02))

plong1_1 <- plong1_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong1_1
@
\end{column}
\begin{column}{0.45\linewidth}
<<ex_datatable, echo = F, size = 'scriptsize', warning = F>>=
lsp <- rep("", nrow(ltDFexlong))
lsp[cumsum(table(subDFexlong$id[subDFexlong$id %in% ltDFexlong$id]))] <- "\\hdashline"

longdatatab <- ltDFexlong %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000"))),
         id = cell_spec(id, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  kable(format = 'latex', escape = F, booktabs = T,
        linesep = lsp,
        align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F)

longdatatab <- gsub("\\\\\n\\bottomrule", "", longdatatab, fixe = T)
longdatatab
@
\end{column}
\end{columns}
Here, $x_1, \ldots, x_4$ are baseline covariates, i.e., not measured repeatedly.
% You can think of them as "age at baseline", "gender", "education level", \ldots
\end{frame}


<<fake_imp, echo = F>>=
impexlong <- mice(DFexlong, seed = 123)
impDFexlong <- complete(impexlong, 3)
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Would we use MICE in the data in this (long) format,
each row would be regarded as independent,
which may cause bias and \blue{inconsistent imputations}.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\linewidth}
Imputed values of baseline covariates are imputed with different values,
creating data that could not have been observed.
\end{column}
\begin{column}{0.45\linewidth}
<<echo = F, size = 'scriptsize'>>=
imptablong <- rbind(impDFexlong[impDFexlong$id %in% subIDs, names(ltDFexlong)],
                    rep(NA, ncol(ltDFexlong)))
imptablong[sapply(imptablong, is.numeric)] <-
  round(imptablong[sapply(imptablong, is.numeric)], 2)

ltDFexlong2 <- ltDFexlong
ltDFexlong2[is.na(ltDFexlong2)] <- imptablong[is.na(ltDFexlong2)]

ltDFexlong2 <- ltDFexlong2 %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  mutate(x2 = cell_spec(x2, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x2),
                                       brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                       '#FFFFFF'))) %>%
  mutate(x3 = cell_spec(x3, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x3),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  mutate(x4 = cell_spec(x4, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x4),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  mutate(id = cell_spec(id, 'latex', escape = F,
                        color = factor(id, c(IDs, "\\vdots"),
                                       c(brewer.pal(length(IDs),
                                                    name = "Dark2"),
                                         "#000000")))) %>%
  kable(format = 'latex', escape = F, booktabs = T, linesep = lsp, align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F, digits = 2)

for (k in 1:8) {
  ltDFexlong2 <- gsub(paste0("\\cellcolor[HTML]{",
                             gsub("#", "", brewer.pal(8, "Dark2")[k])),
               paste0("\\cellcolor{Dark2", k, "!30"), ltDFexlong2, fixed = T)
}

gsub("\\\\\n\\bottomrule", "", ltDFexlong2, fixe = T)
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}[onlytextwidth]
\begin{column}{0.7\linewidth}
<<res example LMM, echo = F, message = F, fig.height = 4, fig.width = 5>>=
lme0 <- lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
               (time|id), data = DFexlong_orig)

lme_imp <- with(impexlong, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
                                (time|id)))

res0 <- as.data.frame(cbind(fixef(lme0),
                            confint(lme0, parm = names(fixef(lme0)),
                                    method = "Wald")))
resimp <- as.data.frame(summary(pool(lme_imp))[, c("est", "lo 95", "hi 95")])

res0$mod <- "orig"
resimp$mod <- "imp"
names(res0) <- names(resimp) <- c("est", "lo", "hi", "mod")

res <- rbind(res0, resimp)
res$var <- rep(rownames(res0), 2)

ggplot(res[!res$var %in% grep("time", res$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2girl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3low" = "x3 (low)",
                                      "x3mid" = "x3 (mid)",
                                      "x4" = "x4"))) +
  # geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp"),
                   labels = c("original", "imputed")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.25\linewidth}
Estimates can be severely biased.
\end{column}
\end{columns}
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In some settings \blue{imputation in wide format} may be possible.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
\only<1>{
<<echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_1
@
}
\only<2>{
<<echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_1 +
 geom_vline(xintercept = seq(1, 9, 2), lty = 2) +
  scale_x_continuous(breaks = seq(1, 9, 2))
@
}
\end{column}
\begin{column}{0.45\linewidth}
<<echo = F, size = 'scriptsize', warning = F>>=
longdatatab
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

<<size = 'scriptsize', echo = F>>=
subDFexlongwide[c("id",
            paste0("y.", c(1,3,5,7,9)),
            paste0("time.", c(1,3,5,7,9)))] %>%
  round(2) %>%
  rbind(., rep("\\vdots", 11)) %>%
  cbind(., '\\ldots' = rep("\\ldots", 5)) %>%
  kable(format = 'latex', row.names = F, booktabs = T, escape = F)
@
\bigskip

In this wide format data frame, missing values in outcome and measurement times
need to be imputed (to be able to use them as predictors to impute covariates),
even though we would not need to impute them for the analysis
(mixed model valid when outcome measurements are M(C)AR).

\bigskip

When the data is very \blue{unbalanced}, i.e., there are no clear cut-offs in time or
transformation to wide format leads to variables with high proportions of missing
data, this is inefficient.

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, cache = T>>=
impwide <- mice(DFexlongwide, printFlag = F, maxit = 10)
@

<<fig.height = 4, fig.width = 5, echo = F, message = F>>=
implist <- mice::complete(impwide, 'long') %>% split(., .$.imp)

longList <- lapply(implist, reshape, direction = 'long',
                   varying = list(y = paste0("y.", seq(1, 9, 2)),
                                  time = paste0("time.", seq(1, 9, 2))),
                   v.names = c("y", "time"),
                   timevar = 'tp', drop = ".imp")

midsobj <- miceadds::datalist2mids(longList)

lme_impwide <- with(midsobj, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) + (time|id)))
reswide <- as.data.frame(summary(pool(lme_impwide)))[, c("est", "lo 95", "hi 95")]
reswide$mod <- "impwide"
names(reswide) <- names(resimp)
reswide$var <- rownames(res0)

res2 <- rbind(res, reswide)#, coefJointAI)

ggplot(res2[!res2$var %in% grep("time", res2$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2girl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3low" = "x3 (low)",
                                      "x3mid" = "x3 (mid)",
                                      "x4" = "x4"))) +
  geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp", "impwide"),#, "JointAI"),
                   labels = c("orig.", "imp.\nlong", "imp.\nwide")) +#, "JointAI")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.3\linewidth}
Better, but very large confidence intervals.
\end{column}
\end{columns}
\end{frame}


<<simlong2 data, echo = F, fig.with = 6, fig.height = 4>>=
coefDFexlong2 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ time), coef)))

coefDFexlong22 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ time + I(time^2)), coef)))
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, fig.width = 6, fig.height = 4>>=
plong2_0 <- ggplot(DFexlong2_sub, aes(x = time, y = y, color = factor(id))) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size = 14)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL) +
                     # minor_breaks = seq(from = 4, to = 6, by = 0.02)) +
  scale_x_continuous(breaks = NULL) +
  xlab("time")

plong2_1 <- plong2_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong2_1
@
\end{column}
\begin{column}{0.3\linewidth}
When the measurement time-points do not follow a regular pattern, transformation
to wide format is not possible.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, label = naivelong]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.6\linewidth}
<<trajectories_ignore, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_1 +
  geom_line(data = data.frame(x = c(min(DFexlong2_sub$time), max(DFexlong2_sub$time),
                                    min(DFexlong2_sub$time), max(DFexlong2_sub$time)),
                              y = c(min(DFexlong2_sub$y), max(DFexlong2_sub$y),
                                    max(DFexlong2_sub$y), min(DFexlong2_sub$y)),
                              id = c(1, 1, 2, 2)),
            aes(x = x, y = y, group = factor(id)), color = "red", lwd = 2) +
  theme(axis.title = element_text(size = 16))
@
\onslide<2->{
<<trajectories_first, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_0 +
  geom_point(data = DFexlong2_sub[DFexlong2_sub$ti == 1, ],
             aes(x = time, y = y, fill = factor(id)),
             size = 8, shape = 21, alpha = 0.5) +
  geom_line(lwd = 1) +
  geom_point(lwd = 2) +
  scale_fill_brewer(palette = "Dark2") +
  theme(axis.title = element_text(size = 16))
@
}
\end{column}
\begin{column}{0.4\linewidth}
Naive approaches that are sometimes used are to
\begin{itemize}
\item \blue{ignore the outcome} in the imputation\onslide<2->{, or to}
\item<2-> use only the \blue{first/baseline outcome}
\end{itemize}
\onslide<3>{However, \blue{important information may be lost},
resulting in invalid imputations and biased results.}

\end{column}
\end{columns}
\end{frame}



\subsection{Example: Survival data}
<<simSurv, echo = F>>=
library(MASS)
library(splines)
n <- 500 # number of subjects

# parameters for the survival model
phi <- 1.6458 # shape for the Weibull baseline hazard
mean.Cens <- 12 # mean of the exponential distribution for the censoring mechanism

################################################
gammas <- c("(Intercept)" = -5.7296, "x2" = 2.4092, "x1" = -2, x3 = 0.2) # coefficients for baseline covariates

x2 <- rep(0:1, each = n/2) # group indicator, i.e., '0' placebo, '1' active treatment
x1 <- rnorm(n)
x3 <- rnorm(n)

# design matrix for the survival model
W <- cbind("(Intercept)" = 1,
           "x2" = x2,
           "x1" = x1,
           "x3" = x3)

################################################

# simulate event times
eta.t <- as.vector(W %*% gammas)
invS <- function(t, u, i) {
    h <- function(s) {
        x20 <- 1 - x2[i]
        x21 <- x2[i]
        exp(log(phi) + (phi - 1) * log(s) + eta.t[i])
    }
    integrate(h, lower = 0, upper = t)$value + log(u)
}
u <- runif(n)
trueTimes <- numeric(n)
for (i in 1:n) {
    Up <- 50
    tries <- 5
    Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    while (inherits(Root, "try-error") && tries > 0) {
        tries <- tries - 1
        Up <- Up + 200
        Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    }
    trueTimes[i] <- if (!inherits(Root, "try-error")) Root else NA
}
na.ind <- !is.na(trueTimes)
trueTimes <- trueTimes[na.ind]
W <- W[na.ind, , drop = FALSE]

n <- length(trueTimes)

# simulate censoring times from an exponential distribution,
# and calculate the observed event times, i.e., min(true event times, censoring times)
Ctimes <- runif(n, 0, 2 * mean.Cens)
Time <- pmin(trueTimes, Ctimes)
event <- as.numeric(trueTimes <= Ctimes) # event indicator

survdat_orig <- data.frame(Time = Time,
                           event = event,
                           x2 = x2[na.ind],
                           x1 = x1[na.ind],
                           x3 = x3[na.ind])

@


<<echo = F>>=
library(survival)
library(mice)

survdat <- survdat_orig
N = n
survdat$x1[sample(1:N, N*0.3)] <- NA
survdat$x3[sample(1:N, N*0.3)] <- NA
survdat$x2[sample(1:N, N*0.3)] <- NA
survdat$x2 <- factor(survdat$x2)
survdat_orig$x2 <- factor(survdat_orig$x2 + 1)


imp00 <- mice(survdat, maxit = 0)

meth01 <- imp00$method
meth01[c("x1")] <- "norm"
meth01[c("x3")] <- "norm"

impsurv_01 <- mice(survdat, maxit = 10, method = meth01)

cox <- with(survdat_orig, coxph(Surv(Time, as.numeric(event)) ~ x1 + x2 + x3))
cox01 <- with(impsurv_01, coxph(Surv(Time, as.numeric(event)) ~ x1 + x2 + x3))

rescox01 <- as.data.frame(summary(pool(cox01))[, c("est", "lo 95", "hi 95")])
rescox <- as.data.frame(cbind(cox$coef, confint(cox)))

rescox01$meth <- "norm"
rescox$meth <- "orig"

rescox$var = rownames(rescox)
rescox01$var = rownames(rescox)

names(rescox) <- names(rescox01)
plotcox <- rbind(rescox, rescox01)
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In survival analysis, the aim is to estimate the effect of covariates on
the \blue{time until an event} of interest happens.

\bigskip

In the commonly used \blue{Cox proportional hazards model}, the hazard $h(t)$
(i.e., the instantaneous risk of an event at time $t$, given that the event has not
occurred until time $t$) is modeled as
$$h(t) = h_0(t)\exp(\beta_x X + \beta_z Z),$$
where $h_0(t)$ is denotes the \textcolor{red}{[usually]} unknown baseline hazard,
and here we use \blue{$X$}
and \blue{$Z$} to distinguish between \blue{incomplete} and \blue{complete}
covariates, respectively.

\bigskip

\blue{Survival outcomes} are usually represented by the \blue{observed event
time $T$} and the \blue{event indicator $D$} ($D = 1$: event, $D = 0$: censored).
\end{frame}

\begin{frame}[fragile, label=survivalmice]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Naive use of MICE} treats the columns in the data set containing $T$ and $D$
just like any other variable, and the resulting imputation model for $X$ would have the form
$$p(X \mid T, D, Z) = \theta_0 + \theta_1 T + \theta_2 D + \theta_3 z + \ldots.$$

\bigskip

\pause
The correct conditional distribution of $X$ given the other variables is, however,
\begin{multline}
\log p(X\mid T, D, Z) = \log p(X\mid Z) + D(\beta_x X + \beta_z Z) - \\
H_0(T)\exp(\beta_x X+\beta_z Z) + const.,\nonumber
\end{multline}
where $H_0(T)$ is the cumulative baseline hazard.\cite{White2009}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using the naively assumed imputation model can lead to \blue{severe bias}:

<<plot surv example, echo = F, fig.width = 6, fig.height = 3, out.width = "80%">>=
library(ggplot2)
ggplot(plotcox, aes(x = meth, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = `lo 95`, max = `hi 95`), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = labeller(var = c("x22" = "x2 (binary)",
                                         "x1" = "x1 (continuous)",
                                         "x3" = "x3 (continuous)"))) +
  scale_x_discrete(limits = c("orig", "norm"),
                   labels = c("original", "naive\nimputation")) +
  xlab("") +
  ylab("estimate & 95% confidence interval")
@
(Results from MICE imputation with an incomplete normal and an incomplete binary covariate.)
\end{frame}



\section{Requirements for MICE to work (well)}
\subsection{Joint and conditional distributions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Recall:} The MICE algorithm is based on the idea of Gibbs sampling.

\bigskip

Gibbs sampling exploits that a joint distribution is fully determined
by its full conditional distributions.

\begin{center}
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white} joint\\distribution}
}
\quad
\parbox[c]{3cm}{
\tikzfancyarrow[3cm]{\scriptsize \textbf{Gibbs}}\\
\onslide<2>{\tikzfancyarrow[3cm, shape border rotate = 180]{\scriptsize \textbf{MICE}}}
}
\quad
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white}full\\conditionals}
}
\end{center}

\onslide<2>{In MICE, the full conditionals are not derived from the joint distribution
but we directly specify the full conditionals and hope a joint distribution exists.}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The \blue{uncertainty about whether a joint distribution exists} for the specified
set of imputation models is often considered to be mainly a theoretical problem.

\bigskip

In practice, violations only have little impact on results in many applications.

\bigskip

However, as we have seen in the examples on the previous slides,
there are \blue{settings where the direct specification} of the full
conditionals/imputation models \blue{may lead to problems}, causing biased results.

\end{frame}


\subsection{Some conditions and definitions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two important definitions:

\bigskip


\blue{Compatibility:}
\begin{quote}
A joint distribution exists, that has the full conditionals (imputation models)
as its conditional distributions.
\end{quote}

\blue{Congeniality:}
\begin{quote}
The imputation model is compatible with the analysis model.
\end{quote}

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Important requirements} for MICE to work well include:
\begin{itemize}
\item Compatibility
\item Congeniality
\item MAR or MCAR (in the standard implementations)
\item \blue{all relevant variables} need to be included (that includes the outcome!!!)\\
      (omission might result in MNAR)
\item the imputation models (and analysis model) need to be \blue{correctly specified}
      (which is a requirement in any standard analysis)
\end{itemize}
\end{frame}


\subsection{Why imputation with MICE can go wrong}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\blue{What went wrong in our above examples?}

\bigskip

When incomplete variables have \blue{non-linear associations} with the outcome,
or with each other, the requirement(s) of \blue{\textit{compatibility} and/or
\textit{congeniality} are violated}.

\bigskip

\blue{Omission, or inadequate inclusion, of the outcome} may result in \blue{MNAR} missing
mechanisms. The same is the case when other relevant predictor variables
are not used as predictor variables in the imputation.
\bigskip

Furthermore, \blue{omission of variables} may lead to \blue{mis-specified models},
however, models may also be mis-specified when all relevant covariates are included,
but \blue{distributional assumptions} or the specified \blue{form of associations}
are incorrect.
\end{frame}



\section{Alternatives to MICE}
\subsection{Joint model imputation}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To \blue{avoid incompatible and uncongenial imputation models}, we need to
\begin{itemize}
\item specify the joint distribution
\item and derive full conditionals / imputation models from this joint distribution
\end{itemize}
instead of specifying the directly.

\bigskip

\pause
\blue{Problem:}\\
Especially in settings with several \blue{variables of mixed type}, the joint
distribution is usually not of any known form:

\begin{eqnarray*}
\begin{array}{c}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim N(\mu_2, \sigma_2^2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim N\left(
                \left[
                  \begin{array}{c}
                  \mu_1\\ \mu_2
                  \end{array}
                \right], \left[
                            \begin{array}{cc}
                            \sigma_1^2 & \sigma_{12}\\
                            \sigma_{12} & \sigma_2^2
                            \end{array}
                          \right]
              \right)\\[2ex]
\text{\blue{but}\quad}
\begin{array}{l}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim Bin(\mu_2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim ???
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Approach 1: Multivariate Normal Model}\\
Approximate the joint distribution by a known multivariate distribution
\mode<presentation>{
(usually the normal distribution; this is the approach mentioned in Part I
on slide~\ref{jointmodelimp})
}
\mode<article>{
(usually the normal distribution; this is the approach mentioned in Part I
in Section~\ref{subsec:multivarmissing})
}

\bigskip

\blue{Approach 2: Sequential Factorization}\\
Factorize the joint distribution into a (sequence of) conditional and a marginal
distributions
\end{frame}

\subsection{Multivariate Normal Model}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Assumption:}\\
The outcome and incomplete variables follow a \blue{joint multivariate normal
distribution}, conditional on the completely observed covariates $\mathbf X_c$,
parameters $\bmath\theta$ and, possibly, random effects, $\bmath b$:
$$ p(\bmath y, \bmath x_1,\ldots, \bmath x_p \mid \mathbf X_c, \bmath\theta,
     \bmath b) \sim N(\bmath \mu, \bmath \Sigma)$$

\bigskip

\onslide<2>{
\textbf{How do we get that multivariate normal distribution?}
\begin{enumerate}
\item Assume \blue{all} incomplete variables and the outcome are \blue{(latent) normal}.
\item specify linear (mixed) \blue{models based on observed covariates}.
\item \blue{Connect} using multivariate normal for \blue{random effects \& error terms}.
\end{enumerate}
}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{1. Latent normal assumption:}\vspace*{-3ex}
$$\text{e.g.: } \bmath x_k \text{ binary }
  \rightarrow \text{ latent } \bmath{\hat x}_k \text{ is standard normal: }
  \left\{\begin{array}{c} \bmath x_k = 1\\ \bmath x_k = 0\end{array}\right.
  \text{ if } \begin{array}{c} \bmath{\hat x_k}\geq 0\\ \bmath{\hat x_k} < 0\end{array}
$$

<<echo = F, fig.width = 6, fig.height = 3, out.width = "70%">>=
par(mar = c(3.5, 3.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
plot(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)), type = "l",
     xlab = expression(hat(x)[k]), ylab = expression(density~of~hat(x)[k]))
polygon(x = c(seq(-4, 0, 0.1), 0),
        y = c(dnorm(seq(-4, 0, 0.1)), 0), col = grey(0.9), border = 'transparent')
polygon(x = c(seq(4, 0, -0.1), 0),
        y = c(dnorm(seq(4, 0, -0.1)), 0), col = grey(0.7), border = 'transparent')
abline(v = 0, lty = 2)
lines(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)))
text(x = -1, y = 0.05, label = bquote(x[k] == 0))
text(x = 1, y = 0.05, label = bquote(x[k] == 1))
@
\textcolor{red}{[examples for categorical data???]}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<1>{\textbf{2. Specify models:}\\}
\only<2>{\textbf{2. Specify models / 3. Connect random effects \& error terms:}\\}
\begin{picture}(200, 100)
\onslide<1->{
\put(0, 60){
    $\addtolength\arraycolsep{-.8ex}
    \begin{array}{rclclcl}
    \bmath y   &=& \bmath X_c \bmath{\tilde\beta}_y     &+& \bmath{\tilde Z_y} \;\bmath{\tilde b_y} &+& \bmath{\tilde \varepsilon_y}\\
    \textcolor{black!50}{\bmath w} &=& \textcolor{black!50}{\bmath X_c \bmath{\tilde\beta}_w}
                                   &+& \textcolor{black!50}{\bmath{\tilde Z_w} \,\bmath{\tilde b_w}}
                                   &+& \textcolor{black!50}{\bmath{\tilde \varepsilon_w}}\\
    \bmath{\hat x}_1 &=& \bmath X_c \bmath{\tilde\beta}_{x_1} &+& \phantom{\bmath Z_w\,} \bmath{\tilde \varepsilon_{x_1}}      &&\\[-1ex]
               & \vdots&                                & & \phantom{\bmath Z_w\;} \vdots                                &&\\[-1ex]
    \bmath{\hat x}_p &=& \bmath X_c \bmath{\tilde\beta}_{x_p} &+& \phantom{\bmath Z_w\,} \bmath{\tilde \varepsilon_{x_p}}      &&
    \end{array}
    $
    }
}
\thicklines
\onslide<2>{
\put(124, 80){\color{red} \oval(15, 32.5)}
\put(96, 62.5){\color{red} \oval(18, 72.5)}
\put(97, 25){\line(0,-1){15}}
\put(97, 10){\vector(1, 0){10}}
\put(110, 7.5){multivariate normal}
%
\put(125, 62.5){\line(0,-1){15}}
\put(125, 47.5){\vector(1, 0){10}}
\put(137.5, 45){multivariate normal (optional, but suggested)}
}
\end{picture}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}[T,onlytextwidth]
\begin{column}{0.5\linewidth}
\blue{Advantages:}
\begin{itemize}
\item Easy to specify
\item Relatively easy to implement
\item Relatively easy to sample from
\item works for longitudinal outcomes
\end{itemize}
\end{column}
\begin{column}{0.5\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item Assumes linear associations
\end{itemize}
\end{column}
\end{columns}

\bigskip

Imputation with \blue{non-linear associations} or \blue{survival data} is
possible with \blue{extensions} of the multivariate normal approach.
\end{frame}

\subsection{Sequential Factorization}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\onslide<1->{
The \blue{joint distribution} of two variables $y$ and $x$ can be \blue{factorized} into
a conditional and a marginal distribution:
$$p(y,x) = p(y\mid x)\;p(x)$$
(or alternatively $p(y,x) = p(x\mid y)\;p(y)$)
}

\vfill

\onslide<2->{
This can easily be \blue{extended for more variables}:
$$p(y,x_1,\ldots,x_p, X_c) = \only<2>{p(y\mid x_1,\ldots,x_p, X_c)}
                             \only<3->{\underset{\text{analysis model}}{
                             \underbrace{p(y\mid x_1,\ldots,x_p, X_c)}}}\;
p(x_1\mid x_2,\ldots,x_p, X_c)\;
\ldots\; p(x_p\mid X_c)$$%

where $x_1, \ldots, x_p$ denote incomplete covariates and $X_c$ contains all
completely observed covariates.
}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
That the analysis model is part of the specification of the joint distribution has
several advantages:
\begin{itemize}
\item The outcome is \blue{automatically included in the imputation} procedure.
\item The outcome does not appear in any of the predictors of the imputation
      models:
      \begin{itemize}
      \item no need to approximate complex outcomes,
      \item no need to summarize complex outcomes.
      \end{itemize}
\item The parameters of interest are obtained directly\\
      \blue{\ding{225}}
      imputation and analysis in one step
\item Non-linear associations or interactions involving incomplete covariates
      are specified in the analysis model and thereby
      \blue{automatically taken into account}
\end{itemize}


\bigskip

Since the joint distribution usually does not have a known form, Gibbs sampling
is used to estimate parameters and sample imputed values.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.55\linewidth}
\blue{Advantages:}
\begin{itemize}
\item Flexible with regards to outcome type
\item univariate conditional distributions of incomplete covariates can be chosen
according to type of variable
\item non-linear associations and interactions can be taken into account
\item assures congeniality and compatible imputation models
\end{itemize}
\end{column}
\begin{column}{0.45\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item separate models need to be specified per incomplete variable: takes more time
and consideration
\item the joint distribution is of unknown form and sampling may be more computationally intensive
\end{itemize}
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

In the following we will not only consider the \textsf{R} package \blue{mice},
but also three additional packages, \blue{JointAI}, \blue{smcfcs} and \blue{jomo},
that are some of the available packages that provide alternatives to \textbf{mice}.

\vfill

These three packages use Bayesian methodology to impute values, but once imputed
datasets are obtained, standard complete data methods can be used.

\bigskip

\blue{jomo} and \blue{smcfcs} perform multiple imputation and create imputed
datasets that can then be analyzed the same way data imputed by \textbf{mice}
would be analyzed.

\bigskip

\blue{JointAI} works fully Bayesian and performs the analysis and imputation
simultaneously, so that the results from the analysis model of interest are
obtained directly.
\end{frame}


\section[Imputation with non-linear//functional forms]{Imputation with non-linear functional forms}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
There is no strategy for MICE that can guarantee valid imputations when
non-linear functional forms and/or interactions are involved,
but some settings in \textbf{mice} may help to reduce bias in the resulting estimates.

\bigskip

For imputation of variables that have non-linear associations
\begin{itemize}
\item \Rstring{pmm} often works better than \Rstring{norm},
\item Just Another Variable approach can reduce bias in interactions,
\item \Rstring{quadratic} can help to impute variables with quadratic association.
% \item inclusion of interaction terms in the imputation model may help.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In the \blue{Just Another Variable (JAV)} approach the non-linear form (or interaction term)
is calculated in the incomplete data, added as a column to the dataset and
imputed as if it was just another variable.

\bigskip

\Rstring{quadratic} provides imputation of covariates that have a
quadratic association with the outcome, using the ``polynomial combination''
method.\cite[pp. 139--141]{Buuren2012}, \cite{Vink2013}.

\bigskip

This is to ensures the imputed values for $x$ and $x^2$ are consistent,
and to reduce bias in the subsequent analysis that uses $x$ and $x^2$.

\bigskip

In my own experience, using \Rstring{quadratic} often has numerical problems.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To demonstrate the approaches, we use a simulated example dataset \Robj{DFnonlin}, with
\begin{itemize}
\item continuous outcome $y$
\item continuous (normal) covariate $x$ (50\% missing values MCAR)
\item quadratic effect of $x$ on $y$
\item binary covariate $z$ (complete)
\item interaction between $x$ and $z$
\end{itemize}

<<echo = F>>=
# simulate data
set.seed(2018)
N <- 200
x <- rnorm(N)
z <- rbinom(N, size = 1, prob = plogis(x))
y <- x + x^2 + z + x*z + rnorm(N, 0, 0.5)

DF_nonlin <- data.frame(y = y, x = x, z = z)

# model on complete data
mod_nonlin <- lm(y ~ x + I(x^2) + z + x:z, data = DF_nonlin)

# create missing values
DF_nonlin$x[sample(1:length(x), size = N/2)] <- NA
@

\bigskip

\pause
In the naive approach, we leave all settings to the defaults.
<<>>=
# naive imputation, using only y, x, z
impnaive <- mice(DF_nonlin, printFlag = F)
@

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We use two different JAV approaches:\\[2ex]
\blue{JAV:} calculating the quadratic and interaction term before imputation
<<>>=
# add quadratic term and interaction to data
DF2 <- DF_nonlin
DF2$xx <- DF2$x^2
DF2$xz <- DF2$x * DF2$z

# JAV imputation
impJAV <- mice(DF2, printFlag = F, maxit = 20)
@
\blue{JAV2:} additionally using an interaction between $z$ and $y$
<<>>=
# add interaction between y and z to data
DF3 <- DF2
DF3$yz <- DF3$y * DF3$z

# JAV imputation with additional interaction
impJAV2 <- mice(DF3, printFlag = F, maxit = 20)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We also try using imputation method \Rarg{quadratic}.
<<warning = F>>=
# adapt the imputation method for quadratic imputation
methqdr <- impJAV$meth
methqdr[c("x", "xx", "xz")] <- c("quadratic", "~I(x^2)", "~I(x*z)")

# adapt the predictor matrix
predqdr <- impJAV$pred
predqdr[, "xx"] <- 0

impqdr <- mice(DF2, meth = methqdr, pred = predqdr,
               printFlag = F, maxit = 1)
@
Note: there were warning messages about numerical issues for this approach.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 6, fig.height = 3.5>>=
res_impnaive <- with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary
res_JAV <- with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_JAV2 <- with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_qdr <- with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

resqdr <- rbind(
  with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary,
  with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

)[, c("est", 'lo 95', 'hi 95')] %>%
  `row.names<-`(1:(4*5)) %>%
  as.data.frame() %>%
  mutate(meth = rep(c("naive", "JAV", "JAV2", "qdr"), each = 5),
         var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), 4),
         beta = rep(coef(mod_nonlin), 4)
  )

polyDF_nonlin <- data.frame(x = rep(c(0, 5, 5, 0), 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"),
                               each = 4)
)

ggplot(resqdr, aes(x = meth, y = est)) +
  geom_polygon(data = polyDF_nonlin,
               aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_point() +
  geom_errorbar(aes(ymin = `lo 95`, ymax = `hi 95`)) +
  facet_wrap("var", scales = 'free') +
  geom_hline(aes(yintercept = beta), lty = 2) +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr")) +
  xlab("imputation method") +
  ylab("estimate & 95% confidence interval")
@
For this example, \blue{none of the approaches provided satisfying results}.
\end{frame}



% \begin{frame}[fragile]{\thesection. \insertsection}
% \framesubtitle{\thesection.\thesubsection. \insertsubsection}
% For this example, \blue{none of the approaches provided satisfying results}.\\
% (To make a more general statement, a simulation study would be needed.)
%
% \bigskip
%
% Note that we used a relatively large proportion of missing values and that not
% a lot of additional covariate information was used \ding{225} in practice
% bias may be less
%
% \bigskip
%
% The message is:\\
% When incomplete variables are involved in interactions or have non-linear association
% with the outcome, you can not be sure that MICE will provide valid imputations.
% Since usually we do not know the true values, it is impossible to judge if this
% is a problem in a real dataset or how big the resulting bias is.
% \end{frame}


\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

The package \href{https://cran.r-project.org/web/packages/JointAI/index.html}%
{\blue{JointAI}} uses the \blue{sequential factorization approach} to perform
simultaneous analysis and imputation.\cite{Erler2016, Erler2017}

\bigskip

\textbf{JointAI} (version 0.1.0) can handle

\begin{itemize}
\item linear regression
\item generalized linear regression
\item linear mixed models
\end{itemize}

while assuring compatibility between analysis model and imputation models
when non-linear functions or interactions are included.

\bigskip

The necessary Gibbs sampling is performed using \textsf{JAGS} (an external program),
which is free, but needs to be
installed from \url{https://sourceforge.net/projects/mcmc-jags/files/}.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{JointAI} can be installed from CRAN
<<eval = F>>=
install.packages("JointAI")
@

The development version (containing bug fixes and other improvements)
can be installed from \href{https://github.com/nerler/JointAI}{GitHub}
<<eval = F>>=
install.packages("devtools")
devtools::install_github(repo = "JointAI", username = "NErler")
@

A detailed explanation of the functionality is given in the help files of the
package, and a vignette with an in-depth example analysis will be available soon.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The syntax analyze and impute the current example using \blue{JointAI} is
similar to the specification of a standard linear model using \Rfct{lm}.

<<JointAI_nonlin, eval = F>>=
library(JointAI)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF, n.iter = 2500)
@

Convergence of the Gibbs sampler can be checked using a traceplot.
<<JointAI_nonlin02, eval = F>>=
traceplot(JointAI_nonlin)
@

<<runJointAI_nonlin, eval = F, echo = F>>=
library(JointAI)
set.seed(1234)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF_nonlin, n.iter = 2500)
save(JointAI_nonlin, file =  "workspaces/JointAI_nonlin.RData")
@

<<getJointAI_nonlin, echo = F>>=
load("workspaces/JointAI_nonlin.RData")
@

Results (no separate analysis \& pooling is necessary) can be obtained with
the \Rfct{summary} function:
<<>>=
res_JointAI_nonlin <- summary(JointAI_nonlin)
@
\end{frame}



\subsection{R package smcfcs}
\begin{frame}{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The package
\href{https://cran.r-project.org/web/packages/smcfcs/index.html}{\blue{smcfcs}}
performs multiple imputation using
\textit{substantive model compatible fully conditional specification}, a \blue{hybrid
approach between FCS and sequential factorization}.\cite{Bartlett2015}

\bigskip
\textbf{smcfcs} (version 1.3.0) can handle
\begin{itemize}
\item linear regression,
\item logistic regression,
\item poisson regression,
\item Cox proportional hazard models, and
\item competing risk survival models,
\end{itemize}
while ensuring compatibility between analysis model and imputation models.

\bigskip

For more information see the help files and the
\href{https://cran.r-project.org/web/packages/smcfcs/vignettes/smcfcs-vignette.html}%
{\dotuline{vignette}}.
\end{frame}


\begin{frame}[fragile, label=smcfcsnonlin]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The syntax to impute the data in the current example using the package \blue{smcfcs}
is:
<<smcfcs_nonlin01, eval = F>>=
library(smcfcs)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)
@

The convergence of the procedure should be checked, for example with the
following syntax:
<<smcfcs_nonlin02, eval = F>>=
par(mfrow = c(2,3), mar = c(2, 2, 0.5, 0.5), mgp = c(2, 0.6, 0))
for(i in 1:dim(smcfcs_nonlin$smCoefIter)[2]) {
  matplot(t(smcfcs_nonlin$smCoefIter[, i, ]), type = 'l', ylab = '')
}
@

<<smcfcs_nonlin_run, eval = F, echo = F>>=
library(smcfcs)
set.seed(2018)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)
save(smcfcs_nonlin, file = 'workspaces/smcfcs_nonlin.RData')
@

<<smcfcs_nonlin_get, echo = F, include = F>>=
library(smcfcs)
library(miceadds)
load("workspaces/smcfcs_nonlin.RData")
impobj_smcfcs_nonlin <- datalist2mids(smcfcs_nonlin$impDatasets)
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- summary(pool(models_smcfcs_nonlin))
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To be able to use the convenient pooling function from the \textbf{mice} package
we first need to convert the imputed data (which is a list)
to a \Robj{mids} object.

\bigskip

This can be done with the function \Rfct{datalist2mids} from the \textbf{miceadds}
package.
<<smcfcs_nonlin_pool1, eval = F>>=
library(miceadds)
impobj_smcfcs_nonlin <- datalist2mids(smcfcs_nonlin$impDatasets)
@

The \Robj{mids} object can then be pooled and summarized as we have seen before
with \texttt{mids} objects created by \Rfct{mice}.
<<smcfcs_nonlin_pool2, eval = F>>=
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- summary(pool(models_smcfcs_nonlin))
@
\end{frame}




\subsection{R package jomo}
\begin{frame}{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The package
\href{https://cran.r-project.org/web/packages/jomo/index.html}{\blue{jomo}}
performs \blue{joint model imputation} using the multivariate normal approach,
with \blue{extensions to assure compatibility} between analysis and imputation models.\cite{Carpenter2012}

\bigskip

\textbf{jomo} (version 2.6-1) can handle
\begin{itemize}
\item linear regression,
\item generalized linear regression,
\item linear mixed models,
\item generalized linear mixed models, and
\item Cox proportional hazards models.
\end{itemize}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using \blue{jomo} we can impute the data in the current example as follows:
<<jomo_nonlin, eval = F>>=
library(jomo)
jomo_nonlin <- jomo.lm(y ~ x*z + I(x^2), data = DF_nonlin)
@

<<jomo_nonlin_run, echo = F, eval = F>>=
library(jomo)
set.seed(2018)
jomo_nonlinMCMC <- jomo.lm.MCMCchain(y ~ x*z + I(x^2), data = DF_nonlin)
jomo_nonlin <- jomo.lm(y ~ x*z + I(x^2), data = DF_nonlin)
save(jomo_nonlin, jomo_nonlinMCMC, file = "workspaces/jomo_nonlin.RData")
@

<<jomo_nonlin_get, echo = F, include = F>>=
library(jomo)
library(miceadds)
load("workspaces/jomo_nonlin.RData")
impobj_jomo_nonlin <- datalist2mids(split(jomo_nonlin,
                                          jomo_nonlin$Imputation)[-1])
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(pool(models_jomo_nonlin))
@

To check the convergence of the model, the corresponding function with
ending \Rfct{.MCMCchain} as to be used.
<<jomo_nonlin2, eval = F>>=
jomo_nonlinMCMC <- jomo.lm.MCMCchain(y ~ x*z + I(x^2), data = DF_nonlin)

par(mfcol = c(2, 3), mar = c(3, 2.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
apply(jomo_nonlinMCMC$collectbeta[1, ,], 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
for (k in 1:dim(jomo_nonlinMCMC$collectomega)[1]) {
  apply(jomo_nonlinMCMC$collectomega[k, , ], 1, plot, type = "l",
        xlab = 'iteration', ylab = '')
}

apply(jomo_nonlinMCMC$collectbetaY[1, ,], 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
plot(jomo_nonlinMCMC$collectvarY, type = 'l')
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

Again, we need to convert the output to a \Robj{mids} object using
\Rfct{datalist2mids}. However, \Rfct{jomo.lm} returns a data frame, in which
the original data and all imputed datasets are stacked onto each other.

\bigskip

\Rfct{split} splits the dataset by imputation number into a list of datasets,
from which we need to exclude the first element (the original/incomplete data).

<<eval = F>>=
impobj_jomo_nonlin <- datalist2mids(split(jomo_nonlin,
                                          jomo_nonlin$Imputation)[-1])
@

With the resulting \Robj{mids} object, analysis of the imputed data and
pooling the results works as in the above examples.
<<eval = F>>=
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(pool(models_jomo_nonlin))
@
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, figwidth = 6, fig.height = 4.5>>=
res_nonlin <- list(naive = as.data.frame(res_impnaive[, c("est", "lo 95", "hi 95")]),
                   JAV = as.data.frame(res_JAV[, c("est", "lo 95", "hi 95")]),
                   JAV2 = as.data.frame(res_JAV2[, c("est", "lo 95", "hi 95")]),
                   qdr = as.data.frame(res_qdr[, c("est", "lo 95", "hi 95")]),
                   JointAI = as.data.frame(res_JointAI_nonlin$stat[, c(1,3,4)]),
                   smcfcs = as.data.frame(res_smcfcs_nonlin[, c("est", "lo 95", "hi 95")]),
                   jomo = as.data.frame(res_jomo_nonlin[, c("est", "lo 95", "hi 95")])
)

res_nonlin <- lapply(res_nonlin, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- gsub("xx", "I(x^2)", rownames(x)) %>%
    gsub("xz", "x:z", .)
  x
})

plot_nonlin <- reshape2::melt(res_nonlin, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_nonlin) + .5)[c(1,2,2,1)], 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), each = 4)
)

ggplot(plot_nonlin, aes(x = L1, y = coef)) +
  geom_point() +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = coef(mod_nonlin),
                               var = names(coef(mod_nonlin))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr",
                              "JointAI", "smcfcs", "jomo")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

For the current example data, the \blue{mice} package was clearly outperformed
by the three alternative packages \blue{JointAI}, \blue{smcfcs} and \blue{jomo}.

\bigskip

To make a more general statement, a simulation study would be needed.

\bigskip

Note also that we used a large proportion of missing values (50\%) and that not
a lot of additional covariate information was used\\
\blue{\ding{225}} In practice, \blue{mice} may perform better than what we saw here.

\bigskip

\begin{block}{The message:}
When \blue{incomplete variables} are involved in \blue{interactions} or
have \blue{non-linear association} with the outcome, standard MICE approaches
may not provide valid imputations.

\bigskip

Alternative methods are available and should be considered.
\end{block}
\end{frame}


\section{Imputation of longitudinal data}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{mice} has functions to allow imputation of longitudinal (2-level) data.
\begin{itemize}
\item \blue{Level 1:}\\
repeated measurements (within subjects) or subjecs (within classes)
\item \blue{Level 2:}\\
subjects (that have repeated measurements) or classes/groups (containing several
subjects)
\end{itemize}

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\textwidth}
Impuation methods for \blue{level-1} variables:
\begin{itemize}
\item \Rstring{2l.pan}
\item \Rstring{2l.norm}
\item \Rstring{2l.lmer}
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
Impuation methods for \blue{level-2} variables:
\begin{itemize}
\item \Rstring{2lonly.norm}
\item \Rstring{2lonly.pmm}
\item \Rstring{2lonly.mean}
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.pan} uses a linear two-level model with \blue{homogeneous
within group variances} using Gibbs sampling \cite{Schafer2002}.
It needs the package \textbf{pan} to be installed.

\bigskip

\Rstring{2l.pan} allows different roles of predictor variables, that
can be specified as different values in the \Rarg{predictorMatrix}:
\begin{itemize}
\item grouping/ID variable: -2
\item random effects (also included as fixed effects): 2
\item fixed effets of group means: 3
\item fixed effects of group means \& random effects: 4
\end{itemize}

<<micelong_ex1_cont3_, eval = F>>=
# random effects of x in model for y
pred["y","x"] <- 2
# fixed effects of x and group mean of x
pred["y","x"] <- 3
# random effects of x and group mean of x
pred["y","x"] <- 4
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.norm} implements a (Bayesian) linear two-level model with
\blue{heterogenous} group variances.

In the current implementation all predictors should be specified as random
effects (set to 2 in the \Rarg{predictorMatrix}, because the algorithm does not
handle predictors that are specified as fixed effects.)

\bigskip

\pause
\Rstring{2l.lmer} imputes univariate systematically and sporadically
missing data using a two-level normal model using \Rfct{lmer} from package
\textbf{lme4} (developed in the context of individual patient meta analysis.
\cite{Jolani2015, Jolani2018})

\bigskip

\pause
\Rstring{2lonly.norm} and \Rstring{2lonly.pmm} can be used
to impute level-2 variables (in combination with \Rstring{2l.pan} for
level-1 variables).

\bigskip

In any case, the group identifier ("id" variable") needs to be set to -2 in.
the \Rarg{predictorMatrix}.
\end{frame}

% \begin{frame}[fragile]{\thesection. \insertsection}
% \framesubtitle{\thesection.\thesubsection. \insertsubsection}
% Functions for impuation of \blue{level-2} variables:
% \begin{itemize}
% \item \Rfct{mice.impute.2lonly.norm} (Bayesian lin. regression)
% \item \Rfct{mice.impute.2lonly.pmm} (predictive mean matching)
% \item \Rfct{mice.impute.2lonly.mean}
% \end{itemize}
%
% \bigskip
%
% \Rstring{2lonly.norm} and \Rstring{2lonly.pmm} can be used
% to impute level-2 variables (in combination with \Rstring{2l.pan} for
% level-1 variables\cite{Yucel2008}).
%
% \bigskip
%
% In any case, the group identifier ("id" variable") needs to be set to -2 in
% the \Rarg{predictorMatrix}.
% \end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2lonly.mean} imputes values with the mean of the observed values per
class. This method should only be used to fill in values that are known to be
constant per class and have some values observed in each class.

\bigskip

\textbf{Example:}
In a multi-center trial the type of some medical equipment is known to be
the same for all patients treated in the same hospital, but not filled in for
some patients.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As an example, we will impute the second (unbalanced) longitudinal
data example from above. The data contain
\begin{itemize}
\item $x1$ (complete)
\item $x2$ (binary, 30\% missing values)
\item $x3$ (3 categories, 30\% missing values)
\item $x4$ (continuous/normal, 30\% missing values)
\item $y$ (longitudinal outcome)
\item $time$ (time variable with quadratic effect)
\item $id$ (id variable)
\end{itemize}

\bigskip

Since there is no 2-level method for categorical data, we use \Rstring{2lonly.pmm}
to impute $x2$ and $x3$.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As usual, we start with the setup run of \Rfct{mice}
<<miceimp_DFexlong2>>=
imp0 <- mice(DFexlong2, maxit = 0)
meth <- imp0$method
pred <- imp0$predictorMatrix
@

and adjust the imputation \Rarg{method} and \Rarg{predictorMatrix}
<<miceimp_DFexlong2_02>>=
meth[c("x2", "x3")] <- "2lonly.pmm"
meth[c("x4")] <- "2lonly.norm"

pred[, "id"] <- -2  # identify id variable
pred[, "ti"] <- 0 # don't use time-point indicator
@

We can then proceed to perform the imputation.
<<miceimp_DFexlong2_03>>=
imp <- mice(DFexlong2, maxit = 10, meth = meth, pred = pred, printFlag = F)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The imputed data can be analysed using either \Rfct{lmer} from the package
\textbf{lme4}, or \Rfct{lme} from \textbf{nlme}. Here we use the former.
<<miceimp_DFexlong2_04>>=
library(lme4)
models <- with(imp, lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) +
                           (time|id)))
mice_longimp <- summary(pool(models))
@
\end{frame}


<<miceimp_DFexlong2_naive, echo = F>>=
pred[, c("id", "ti")] <- 0
impnaive <- mice(DFexlong2, predictorMatrix = pred, maxit = 10)
models2 <- with(impnaive,
                lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id)))

mice_longimp_naive <- summary(pool(models2))
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Currently, there is only limited documentation and examples available that show how to
use these functions in \textbf{mice}.

Technical details can be obtained from the methodologic references given in the
help files of the R functions.

\bigskip

A
\href{https://gerkovink.github.io/miceVignettes/Multi_level/Multi_level_data.html}{\dotuline{vignette}}
on multi-level imputation with \textbf{mice} is available.
It gives a more elaborate example of how to analyze such data.
%\textcolor{red}{[which did not run when I tried on march 29, 2018]}
\end{frame}



\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Linear mixed models with incomplete covariates can also be
analyzed using the package \textbf{JointAI}.

\bigskip

The syntax is analogous the syntax used in \Rfct{lme} of the package \textbf{nlme}.

<<JointAI_long, eval = F>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2 + x4 + time + I(time^2),
                        random = ~time|id, data = DFexlong2,
                        n.iter = 5000)
traceplot(JointAI_long)
res_JointAI_long <- summary(JointAI_long, start = 2000)
@

Again, convergence of the Gibbs sampler should be checked using a traceplot,
<<JointAI_long_02, eval = F>>=
traceplot(JointAI_long)
@
before obtaining the results:
<<JointAI_long_03, eval = F>>=
res_JointAI_long <- summary(JointAI_long, start = 2000)
@



<<JointAI_long_run, eval = F, echo = F>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2 + x4 + time + I(time^2),
                        random = ~time|id, data = DFexlong2,
                        n.iter = 5000)

save(JointAI_long, file = "Slides/workspaces/JointAI_long.RData")
@

<<JointAI_long_get, echo = F, fig.width = 8, fig.height = 4, message = F>>=
load("workspaces/JointAI_long.RData")
res_JointAI_long <- summary(JointAI_long, start = 2000)
@
%
% Currently, imputation is only possible for cross-sectional covariates, but
% longitudinal covariates that are completely observed can be included.
% The random effects structure is restricted to 2-levels, but may contain various
% functional forms.
%
% \bigskip

Contrary to the two-level imputation of \textbf{mice}, non-linear associations
are appropriately handled.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 8, fig.height = 5, message = F>>=
library(JointAI)
traceplot(JointAI_long)
@
\end{frame}


\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In \blue{jomo}, the functions \Rfct{jomo.lmer} and \Rfct{jomo.glmer}
can be used to impute longitudinal data with normal or non-normal outcomes.

\bigskip

In the multi-level setting, the level of each variable needs to be specified
(1: repeated measurements, 2: baseline covariates)
<<jomo_long, eval = F>>=
library(jomo)
# specify the level of each variable
lvl <- c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2, x4 = 2, time = 1)

jomo_long <- jomo.lmer(formula = y ~ x1 + x2 + x3 + x4 +
                         time + I(time^2) + (time|id),
                       data = DFexlong2[, names(lvl)], level = lvl)
@


<<jomo_long_run, eval = F, echo = F>>=
library(jomo)
source(file.path(projdir, "Slides", "Rfcts/myjomo.R"))

lvl <- c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2, x4 = 2, time = 1)

jomo_long <- myjomo.lmer(formula = y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id),
                       data = DFexlong2[, names(lvl)],
                       level = lvl)

subDF <- DFexlong2[, c("id", "y", paste0("x", 1:4), "time")]

jomo_longMCMC <- myjomo.lmer.MCMCchain(formula = y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id),
                                       data = DFexlong2[, names(lvl)],
                                       level = lvl)

# plot(jomo_longMCMC$collectbeta[1, 1, ], type = 'l')
# plot(jomo_longMCMC$collectomega[1, 1, ], type = 'l')
# matplot(t(jomo_longMCMC$collectu[3, , ]), type = 'l')

save(jomo_long, jomo_longMCMC, file = 'Slides/workspaces/jomo_long.RData')
@

<<jomo_long_get, echo = F>>=
load('workspaces/jomo_long.RData')
@

Analogously to the example with non-linear effects, convergence of the imputation
needs to be checked.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Again, the stacked dataframe returned by \Rfct{jomo.lmer} needs to be split
by imputation number and the original data excluded, before fitting the model
and pooling the results.
<<>>=
library(miceadds)
impobj_jomo_long <- datalist2mids(split(jomo_long,
                                        jomo_long$Imputation)[-1])
models_jomo_long <- with(impobj_jomo_long,
                         lmer(y ~ x1 + x3 + x2 + x4 + time + I(time^2) +
                                (time|clus)))

res_jomo_long <- summary(pool(models_jomo_long))
@

As in the examples for non-linear functional forms, congeniality of imputation
models is maintained.
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<1>{
<<echo = F, figwidth = 6, fig.height = 4.5>>=
mod_long2 <- with(DFexlong2_orig,
                  lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id)))

res_long2 <- list(JointAI = as.data.frame(res_JointAI_long$stat[, c(1,3,4)]),
                  jomo = as.data.frame(res_jomo_long)[, c("est", "lo 95", "hi 95")],
                  mice_long = as.data.frame(mice_longimp)[, c("est", "lo 95", "hi 95")],
                  mice_naive = as.data.frame(mice_longimp_naive)[, c("est", "lo 95", "hi 95")]
                  # mice_wide = as.data.frame(mice_wideimp)[, c("est", "lo 95", "hi 95")]
)

res_long2 <- lapply(res_long2, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  x$var <- gsub("x22", "x21", rownames(x))
  x
})

plot_long <- reshape2::melt(res_long2, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_long2) + .5)[c(1,2,2,1)], 8),
                     y = c(apply(confint(mod_long2,
                                         method = "Wald",
                           parm = names(fixef(mod_long2))), 1, rep,
                           each = 2)),
                     var = rep(names(fixef(mod_long2)), each = 4)
)

ggplot(plot_long[plot_long$L1 != "mice_naive", ], aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free', ncol = 4) +
  geom_polygon(data = polyDF, aes(x = pmin(x, 3.5), y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = fixef(mod_long2),
                               var = names(fixef(mod_long2))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_long", "JointAI", "jomo"),
                   labels = c("mice", "JointAI", "jomo"))
@
}
\only<2>{
<<echo = F, figwidth = 6, fig.height = 4.5>>=
ggplot(plot_long, aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free', ncol = 4) +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = fixef(mod_long2),
                               var = names(fixef(mod_long2))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_long", "JointAI", "jomo", "mice_naive"),
                   labels = c("mice", "JointAI", "jomo", "mice\nnaive"))
@
}
\end{frame}

\section{Imputation of survival data}
\subsection{Results from literature}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
On slide~\ref{survivalmice} we have seen the rather complex formula for imputation of
an incomplete covariate in survival data.

\bigskip

White et al. \cite{White2009} derived versions of this model for different
settings (binary or continuous incomplete covariate $X$, and no,
binary, or categorical complete covariate $Z$) and investigated how to best
approximate it.

\bigskip

They found that when \blue{covariate effects and cumulative incidences are rather small},
using \blue{$Z$, $D$ and $H_0(T)$}, and possibly an interaction term, as
predictor variables in the imputation for $X$ in MICE may work satisfactorily.

\bigskip

However, in practice $H_0(T)$ is \textcolor{red}{[usually]} not known.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two main ideas:
\begin{itemize}
\item If covariate effects $\beta_x$ and $\beta_z$ are small, \blue{$H_0(t)\approx H(t)$},
      which can be approximated by the \blue{Nelson-Aalen estimator}.
\item \blue{Estimate $H_0(T)$ in an additional step} inside the MICE procedure
      by fitting a Cox model on the imputed data.
\end{itemize}
Neither of these approaches takes into account uncertainty about $H_0(t)$
(but the impact is likely to be small).

\bigskip

\pause
Based on results from their simulation study, White et al. conclude that
\blue{using $Z$, $D$ and the Nelson-Aalen estimator $\hat H(T)$} as predictors
for the imputation of $X$ worked best.

\bigskip

However, some \blue{bias towards the null} should be expected when covariates have large
effects.
\end{frame}


\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

In \textbf{mice}, \Rfct{nelsonaalen} can be used to
\blue{calculate the Nelson-Aalen estimator}, to use it as covariate in the
imputation.

<<mice_surv01>>=
survdat$H0 <- nelsonaalen(survdat, timevar = Time, statusvar = event)
@

Then, we can prepare the imputation the same steps as in previous examples:
<<mice_surv02>>=
# setup run
imp0 <- mice(survdat, maxit = 0)
meth <- imp0$method
pred <- imp0$predictorMatrix

# specify normal imputation for continuous covariates
meth[c("x1", "x3")] <- "norm"

# remove event time from predictor (high correlation with H0)
pred[, "Time"] <- 0
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
With the modified arguments \Rarg{method} and \Rarg{predictorMatrix} we run
the imputation:
<<mice_surv03>>=
survimp <- mice(survdat, maxit = 10, method = meth, predictorMatrix = pred,
                printFlag = F)
@


To obtain the pooled results, we first fit the model of interest
<<mice_surv2>>=
cox_mice <- with(survimp, coxph(Surv(Time, event) ~ x1 + x2 + x3))
@

and pool and summarize the results.
<<>>=
res_mice_surv <- summary(pool(cox_mice))
@
The warning message refers to the way the degrees of freedom for the formulas
we saw in part I (slide \ref{poolingdf}) are calculated and can be ignored.
\end{frame}


\subsection{R package smcfcs}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Jusing the package \blue{smcfcs}, the same data can be imputed with the following
syntax:

<<smcfcs_surv, eval = F>>=
library(smcfcs)
smcfcs_surv <- smcfcs(originaldata = survdat, smtype = "coxph",
                      smformula = "Surv(Time, event) ~ x1 + x2 + x3",
                      method = c("", "", "logreg", "norm", "norm", ""),
                      numit = 20, rjlimit = 1500)
@
Convergence of the procedure should be checked, analogous to the previous
example (see slide~\ref{smcfcsnonlin}).

\bigskip

After the resulting object is converted to a \Robj{mids} object, fitting the
model and pooling the results is analogous to what was done with the data imputed
by \textbf{mice}.

<<smcfcs_surv02, eval = F>>=
impobj_smcfcs_surv <- datalist2mids(smcfcs_surv$impDatasets)
models_smcfcs_surv <- with(impobj_smcfcs_surv,
                           coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_smcfcs_surv <- summary(pool(models_smcfcs_surv))
@

<<smcfcs_surv_run, echo = F, eval = F>>=
library(smcfcs)
smcfcs_surv <- smcfcs(originaldata = survdat, smtype = "coxph",
                      smformula = "Surv(Time, event) ~ x1 + x2 + x3",
                      method = c("", "", "logreg", "norm", "norm", ""),
                      numit = 20, rjlimit = 1500)

save(smcfcs_surv, file = "Slides/workspaces/smcfcs_surv.Rdata")
@

<<smcfcs_surv_load, echo = F, warning = F>>=
load("workspaces/smcfcs_surv.Rdata")
impobj_smcfcs_surv <- datalist2mids(smcfcs_surv$impDatasets)
models_smcfcs_surv <- with(impobj_smcfcs_surv,
                           coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_smcfcs_surv <- summary(pool(models_smcfcs_surv))
@
\end{frame}


\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In the package \blue{jomo}, the function \Rfct{jomo.coxph} can be used to
impute our example survival data:
<<jomo_surv, eval = F>>=
library(jomo)
jomo_surv <- jomo.coxph(formula = Surv(Time, event) ~ x1 + x2 + x3,
                        data = survdat)
@

<<jomo_surv_run, echo = F, eval = F>>=
library(jomo)
set.seed(2018)
jomo_survMCMC <- jomo.coxph.MCMCchain(formula = Surv(Time, event) ~ x1 + x2 + x3,
                                      data = survdat)
# matplot(t(test$collectbeta[1, c(2,3), ]), type = 'l')
# matplot(t(test$collectomega[1, , ]), type = 'l')

jomo_surv <- jomo.coxph(formula = Surv(Time, event) ~ x1 + x2 + x3,
                        data = survdat)
save(jomo_surv, jomo_survMCMC, file = "Slides/workspaces/jomo_surv.RData")
@

<<jomo_surv_get, echo = F, include = F>>=
library(jomo)
load("workspaces/jomo_surv.RData")
impobj_jomo_surv <- datalist2mids(split(jomo_surv, jomo_surv$Imputation)[-1])
models_jomo_surv <- with(impobj_jomo_surv, coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_jomo_surv <- summary(pool(models_jomo_surv))
@
Note that the convergence of the procedure should be checked using
\Rfct{jomo.coxph.MCMCchain} (analogous to the previous examples using \textbf{jomo}).

\bigskip

To analyze \& pool the imputed data the steps are analogous to the other examples:
<<eval = F>>=
impobj_jomo_surv <- datalist2mids(split(jomo_surv, jomo_surv$Imputation)[-1])
models_jomo_surv <- with(impobj_jomo_surv,
                         coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_jomo_surv <- summary(pool(models_jomo_surv))
@
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 6, fig.height = 2.5>>=
mod_surv <- with(survdat_orig, coxph(Surv(Time, event) ~ x1 + x2 + x3))

res_surv <- list(mice_naive = rescox01,
                 mice = as.data.frame(res_mice_surv)[, c("est", "lo 95", "hi 95")],
                 smcfcs = as.data.frame(res_smcfcs_surv)[, c("est", "lo 95", "hi 95")],
                 jomo = as.data.frame(res_jomo_surv)[, c("est", "lo 95", "hi 95")]
)

res_surv <- lapply(res_surv, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  # x$var <- gsub("x22", "x2", rownames(x))
  x
})

plot_surv <- reshape2::melt(res_surv, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_surv) + .5)[c(1,2,2,1)],
                             length(mod_surv$coef)),
                     y = c(apply(log(summary(mod_surv)$conf.int[, 3:4]), 1, rep,
                           each = 2)),
                     var = rep(names(coef(mod_surv)), each = 4)
)

ggplot(plot_surv, aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.5) +
  geom_hline(data = data.frame(betas = coef(mod_surv),
                               var = names(coef(mod_surv))),
             aes(yintercept = betas), lty = 2) +
  xlab("imputation method") +
  ylab("coefficient") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_naive", "mice", "smcfcs", "jomo"),
                   labels = c("mice\nnaive", "mice", "smcfcs", "jomo"))
@

The naive mice approach, and mice using the Nelson-Aalen estimator give very
biased results for the effects of $x1$ and $x2$, but performed acceptable
for $x3$.

\bigskip

Note that the true effects (log HR) of $x1$ and $x2$ are very large
(-2 and 2.5, respectively),
and represent the setting where the approximation by the Nelson-Aalen estimate
is expected to be biased.
\end{frame}

\section{Some general notes}
\begin{frame}
The packags are young and research is ongoing. There may be problems, errors, etc.

\end{frame}

