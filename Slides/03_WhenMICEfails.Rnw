\begin{frame}[allowframebreaks=0.75]{Outline of Part III}
\tableofcontents[part=3, sections={12-14}]
\framebreak
\tableofcontents[part=3, sections={15-16}]
\framebreak
\tableofcontents[part=3, sections={17-18}]
\end{frame}

<<packages part3, echo = F>>=
library(knitr)
library(kableExtra)
library(plyr)
library(RColorBrewer)
library(magrittr)
library(kableExtra)
library(ggplot2)
library(splines)
library(dplyr)
library(mice)
library(miceadds)
library(lme4)
library(knitr)

source(file.path(projdir, "Slides", "Rfcts/make_exampledata.R"))
source(file.path(projdir, "Slides", "Rfcts/myfcts.R"))
@

\section{Settings where MICE may have problems}
\subsection{Example: Quadratic effect}
<<example_quadratic_bias, echo = F>>=
# sim data quadratic -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
y <- -1 - 0.6 * x + 0.5 * x^2 + rnorm(N, 0, 0.2)

DFexqdr <- data.frame(y = y, x = x)
DFexqdr$xmis <- DFexqdr$x
DFexqdr$xmis[sample(1:length(x), size = N/2, prob = plogis(5 * DFexqdr$y))] <- NA

impmod <- lm(xmis ~ y, DFexqdr)
imps <- predict(impmod, newdata = DFexqdr[is.na(DFexqdr$xmis), ]) +
  rnorm(sum(is.na(DFexqdr$xmis)), 0, summary(impmod)$sigma)

DFexqdr$ximp <- DFexqdr$xmis
DFexqdr$ximp[is.na(DFexqdr$xmis)] <- imps

lm0 <- lm(y ~ x + I(x^2), DFexqdr)
lm_imp <- lm(y ~ ximp + I(ximp^2), DFexqdr)
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Consider the case where the \blue{analysis model} (which we assume to be true)
is
$$y = \beta_0 + \beta_1 x + {\color{darkred}\bmath{\beta_2 x^2}} + \ldots,$$
i.e., $y$ has a \blue{quadratic relationship} with $x$, and $x$ is incomplete.

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr1, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 <- ggplot(DFexqdr, aes(x = x, y = y,
                               color = is.na(xmis),
                               shape = is.na(xmis))) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.1, 0.15),
        legend.background = element_rect(fill = 'transparent'),
        legend.text = element_text(size = 13),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        axis.ticks = element_blank())

pexqdr1 +
  scale_color_manual(name = "",
                     limits = c(F, T),
                     values = c("black", "black"),
                     labels = c("observed", "missing")) +
  scale_shape_manual(name = "",
                     limits = c(F, T),
                     values = c(19, 1),
                     labels = c("observed", "missing"))

@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The original data show a curved pattern.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to \blue{impute $x$} when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \ldots,$$
i.e., a \blue{linear relation} between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr2, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 + geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
                     aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "darkgrey", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed"))
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The imputed values \blue{distort the curved pattern} of the original data.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
% Analysis and imputation model contradict each other.
%
% No joint distribution exists that has the conditional distributions resulting
% from these models as its conditional distributions.
%
% \blue{\ding{225}} The imputation model for $x_1$ is \blue{uncongenial}.\\
% \blue{\ding{225}} Analysis of the imputed data leads to biased results.

The model fitted on the imputed data gives \blue{severely biased results}; the
non-linear shape of the curve has almost completely disappeared.

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_qdr3, echo = F, fig.width = 6, fig.height = 4>>=
pexqdr1 +
  geom_point(data = DFexqdr[is.na(DFexqdr$xmis), ],
             aes(x = ximp, y = y, shape = 'shapeimp', color = 'colimp')) +
  geom_smooth(aes(group = "1", linetype = "ltycompl"), color = 'darkred',
              method = "lm", formula = y~x + I(x^2), se = F, lwd = 1.5) +
  geom_smooth(data = DFexqdr, aes(x = ximp, y = y, group = '1',
                                  linetype = "ltyimp"),
              color = 'darkred', se = F, lwd = 1.5,
              method = "lm", formula = y~x + I(x^2)) +
  scale_color_manual(name = "",
                     limits = c(F, T, 'colimp'),
                     values = c("black", "black", "black"),
                     labels = c("observed", "missing", "imputed")) +
  scale_shape_manual(name = "",
                     limits = c(F, T, 'shapeimp'),
                     values = c(19, 1, 8),
                     labels = c("observed", "missing", "imputed")) +
  scale_linetype_manual(name = "",
                        limits = c('ltycompl', 'ltyimp'),
                        values = c(1, 2),
                        labels = c("fit on complete", "fit on imputed")) +
  theme(legend.key.width = unit(1.5,"cm"),
        legend.title = element_blank(),
        legend.position = c(0.17, 0.20),
        legend.spacing.y = unit(-0.3, "lines")
  ) +
  expand_limits(y = -2)
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<restab_qdr, echo = F, size = 'scriptsize'>>=
tabexqdr <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'x2'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  3, "Imputed" = 3))# %>%

tabexqdr %>%
  gsub("x2", "$x^2$", .) %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Example: Interaction effect}
<<example_interact_bias, echo = F>>=
# sim data interact -----------------------------------------------------------
set.seed(2)
N <- 200
x <- runif(N, -1, 1)
z <- rbinom(N, size = 1, prob = 0.5)
y <- -1 - 0.6 * x + 0.5 * z + x*z + rnorm(N, 0, 0.2)

DFexint <- data.frame(y = y, x = x, z = z)
DFexint$xmis <- DFexint$x
DFexint$xmis[sample(1:length(x), size = N/2, prob = plogis(2 * DFexint$y))] <- NA

impmod <- lm(xmis ~ y + z, DFexint)
impmod2 <- lm(xmis ~ y*z, DFexint)

impresid <- rnorm(sum(is.na(DFexint$xmis)), 0, summary(impmod)$sigma)

imps <- predict(impmod, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid
imps2 <- predict(impmod2, newdata = DFexint[is.na(DFexint$xmis), ]) + impresid

DFexint$ximp <- DFexint$ximp2 <- DFexint$xmis
DFexint$ximp[is.na(DFexint$xmis)] <- imps
DFexint$ximp2[is.na(DFexint$xmis)] <- imps2

lm0 <- lm(y ~ x*z, DFexint)
lm_imp <- lm(y ~ ximp*z, DFexint)
lm_imp2 <- lm(y ~ ximp2*z, DFexint)
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another example occurs when the analysis model (again, assumed to be true)
is
$$y = \beta_0 + \beta_x x + \beta_z z + {\color{darkred}\bmath{\beta_{xz} xz}} + \ldots,$$
i.e., $y$ has a \blue{non-linear relationship} with $x$ due to the
\blue{interaction term}.


\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int1, echo = F, fig.width = 6, fig.height = 4.5>>=
plotexint <- reshape2::melt(DFexint, id.vars = c("y", "z", "ximp2", "xmis"))
plotexint$combi <- paste0(plotexint$variable, "_",
                          ifelse(is.na(plotexint$xmis), "mis", "obs"), plotexint$z)

ggplot(plotexint[plotexint$variable == "x", ], aes(x = value, y = y,
                                                   color = combi,
                                                   shape = combi)) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.15, 0.16),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 13),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  xlab("x") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c(1, 1, 19, 19),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1", "x_obs0", "x_obs1"),
                     values = c("blue", "chartreuse4", "blue", "chartreuse4"),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)"))
@
\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The original data shows a ``$<$'' shaped pattern.
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The model used to impute $x$ when using MICE (naively) is
$$x = \theta_{10} + \theta_{11} y + \theta_{12} z + \ldots,$$
i.e., a linear relation between $x$ and $y$ is assumed.
\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}

<<plot_int2, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi,
           alpha = combi)) +
  geom_point(size = 2) +
  theme_light() +
  theme(legend.position = c(0.15, 0.20),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 13),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal") +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 2, 2),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "chartreuse4"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_alpha_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(0.5, 0.5, 1, 1, 1, 1),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  expand_limits(y = -2) +
  xlab("x")
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
The ``$<$'' shaped pattern of the true data is \blue{distorted by the imputed values}.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
And the analysis on these naively imputed values leads to \blue{severely biased estimates}.

\vfill

\begin{columns}
\begin{column}{0.6\linewidth}
\begin{center}
<<plot_int3, echo = F, fig.width = 6, fig.height = 4.5>>=
ggplot(plotexint[plotexint$variable == "x" | is.na(plotexint$xmis), ],
       aes(x = value, y = y,
           color = combi,
           shape = combi)) +
  geom_point(size = 2, alpha = 0.3) +
  geom_smooth(data = plotexint[plotexint$z == "0", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'blue') +
  geom_smooth(data = plotexint[plotexint$z == "1", ], method = "lm", se = F,
              aes(x = value, y = y, linetype = variable,
                  group = variable), color = 'chartreuse4') +
  theme_light() +
  theme(legend.position = c(0.25, 0.20),
        legend.background = element_rect(fill = 'transparent'),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_text(size = 15),
        legend.text = element_text(size = 13),
        legend.spacing.x = unit(-0.5,  "lines"),
        legend.spacing.y = unit(-1.5, "lines"),
        legend.box = "horizontal",
        legend.key.width = unit(1,"cm")
        ) +
  scale_shape_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = c(1, 1, 19, 19, 8, 8),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_color_manual(name = "",
                     limits = c("x_mis0", "x_mis1",
                                "x_obs0", "x_obs1",
                                "ximp_mis0", "ximp_mis1"),
                     values = rep(c("blue", "chartreuse4"), 3),
                     labels = c("missing (z = 0)", "missing (z = 1)",
                                "observed (z = 0)", "observed (z = 1)",
                                "imputed (z = 0)", "imputed (z = 1)")) +
  scale_linetype_manual(name = "",
                        limits = c("x", "ximp"),
                        values = c(1, 2),
                        labels = c(" true",  " imputed")) +
  expand_limits(y = -2, x = -1.8) +
  xlab("x")
@

\end{center}
\end{column}
\begin{column}{0.4\linewidth}
<<echo = F, size = 'scriptsize'>>=
restab_interact <- confint(lm0) %>%
  rbind(confint(lm_imp)) %>%
  apply(1, sprintf, fmt = "%.2f") %>%
  apply(2, paste0, collapse = ", ") %>%
  paste0("[", ., "]") %>%
  cbind("beta" = round(c(lm0$coef, lm_imp$coef), 2) %>%
          `names<-`(rep(c("Intercept", "x", 'z', 'x:z'), 2)),
        "95% CI" = .) %>%
  kable('latex', booktabs = T, align = 'r') %>%
  group_rows(index = c("Original" =  4, "Imputed" = 4))

restab_interact %>%
  gsub("beta", "$\\beta$", ., fixed = T)
@
\end{column}
\end{columns}
\end{frame}



\subsection{Example: Longitudinal outcome}
<<simlong data, echo = F, fig.with = 6, fig.height = 4>>=
IDs <- c(5, 6, 7, 8, 18)
subIDs <- IDs[IDs != 7]
subDFexlong <- DFexlong[DFexlong$id %in% IDs, ]

DFexlongwide <- reshape(DFexlong, direction = 'wide', v.names = c("y", "time"), idvar = "id",
                  timevar = 'ti', drop = "tp")
subDFexlongwide <- DFexlongwide[DFexlongwide$id %in% subIDs, ]


coefDFexlong <- as.data.frame(t(sapply(lapply(split(subDFexlong, subDFexlong$id),
                                        lm, formula = y ~ time), coef)))
coefDFexlong$ID <- IDs


ltDFexlong <- subDFexlong[subDFexlong$id != 7,
                          c("id", "y", paste0("x", 1:4), "time")]
ltDFexlong$time <- sprintf(ltDFexlong$time, fmt = "%.2f")
ltDFexlong$y <- "\\checkmark"
ltDFexlong$x1 <- "\\checkmark"
ltDFexlong$x2 <- as.character(ltDFexlong$x2)
ltDFexlong$x2[!is.na(ltDFexlong$x2)] <- "\\checkmark"
ltDFexlong$x3 <- as.character(ltDFexlong$x3)
ltDFexlong$x3[!is.na(ltDFexlong$x3)] <- "\\checkmark"
ltDFexlong$x4[!is.na(ltDFexlong$x4)] <- "\\checkmark"

ltDFexlong <- rbind(ltDFexlong, rep("\\vdots", 7))


colvec <- brewer.pal(length(IDs), "Dark2")
@



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Another setting where imputation with MICE is not straightforward is when
the \blue{outcome variable is longitudinal}.
\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
<<trajectories, echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_0 <- ggplot(subDFexlong, aes(x = time, y = y, color = factor(id))) +
  theme(legend.position = "none",
        axis.title = element_text(size = 18),
        axis.text = element_text(size = 12)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL,
                     minor_breaks = seq(from = 4, to = 6, by = 0.02))

plong1_1 <- plong1_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong1_1
@
\end{column}
\begin{column}{0.45\linewidth}
<<ex_datatable, echo = F, size = 'scriptsize', warning = F>>=
lsp <- rep("", nrow(ltDFexlong))
lsp[cumsum(table(subDFexlong$id[subDFexlong$id %in% ltDFexlong$id]))] <- "\\hdashline"

longdatatab <- ltDFexlong %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000"))),
         id = cell_spec(id, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  kable(format = 'latex', escape = F, booktabs = T,
        linesep = lsp,
        align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F)

longdatatab <- gsub("\\\\\n\\bottomrule", "", longdatatab, fixe = T)
longdatatab
@
\end{column}
\end{columns}
Here, $x_1, \ldots, x_4$ are baseline covariates, i.e., not measured repeatedly.
% You can think of them as "age at baseline", "gender", "education level", \ldots
\end{frame}


<<fake_imp, echo = F>>=
impexlong <- mice(DFexlong, seed = 123)
impDFexlong <- complete(impexlong, 3)
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
If we use MICE in the data in this (long) format,
each row would be regarded as independent,
which may cause bias and \blue{inconsistent imputations}.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\linewidth}
Imputed values of baseline covariates are imputed with different values,
creating data that could not have been observed.
\end{column}
\begin{column}{0.45\linewidth}
<<imptablong, echo = F, size = 'scriptsize'>>=
imptablong <- rbind(impDFexlong[impDFexlong$id %in% subIDs, names(ltDFexlong)],
                    rep(NA, ncol(ltDFexlong)))
imptablong[sapply(imptablong, is.numeric)] <-
  round(imptablong[sapply(imptablong, is.numeric)], 2)

ltDFexlong2 <- ltDFexlong
ltDFexlong2[is.na(ltDFexlong2)] <- imptablong[is.na(ltDFexlong2)]

ltDFexlong2 <- ltDFexlong2 %>%
  mutate(time = cell_spec(time, 'latex', escape = F,
                          color = factor(id, c(IDs, "\\vdots"),
                                         c(brewer.pal(length(IDs),
                                                      name = "Dark2"),
                                           "#000000")))) %>%
  mutate(x2 = cell_spec(x2, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x2),
                                       brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                       '#FFFFFF'))) %>%
  mutate(x3 = cell_spec(x3, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x3),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  mutate(x4 = cell_spec(x4, "latex", escape = F,
                        background = ifelse(is.na(ltDFexlong$x4),
                                            brewer.pal(length(IDs), "Dark2")[match(id, unique(IDs))],
                                            '#FFFFFF'))) %>%
  mutate(id = cell_spec(id, 'latex', escape = F,
                        color = factor(id, c(IDs, "\\vdots"),
                                       c(brewer.pal(length(IDs),
                                                    name = "Dark2"),
                                         "#000000")))) %>%
  kable(format = 'latex', escape = F, booktabs = T, linesep = lsp, align = 'c',
        col.names = c("ID", "y", "$x_1$", "$x_2$", "$x_3$", "$x_4$", "time"),
        row.names = F, digits = 2)

for (k in 1:8) {
  ltDFexlong2 <- gsub(paste0("\\cellcolor[HTML]{",
                             gsub("#", "", brewer.pal(8, "Dark2")[k])),
               paste0("\\cellcolor{Dark2", k, "!30"), ltDFexlong2, fixed = T)
}

gsub("\\\\\n\\bottomrule", "", ltDFexlong2, fixe = T)
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}[onlytextwidth]
\begin{column}{0.7\linewidth}
<<res example LMM, echo = F, message = F, fig.height = 4, fig.width = 5>>=
lme0 <- lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
               (time|id), data = DFexlong_orig)

lme_imp <- with(impexlong, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) +
                                (time|id)))

res0 <- as.data.frame(cbind(fixef(lme0),
                            confint(lme0, parm = names(fixef(lme0)),
                                    method = "Wald")))
resimp <- as.data.frame(summary(pool(lme_imp))[, c("est", "lo 95", "hi 95")])

res0$mod <- "orig"
resimp$mod <- "imp"
names(res0) <- names(resimp) <- c("est", "lo", "hi", "mod")

res <- rbind(res0, resimp)
res$var <- rep(rownames(res0), 2)

ggplot(res[!res$var %in% grep("time", res$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2girl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3low" = "x3 (low)",
                                      "x3mid" = "x3 (mid)",
                                      "x4" = "x4"))) +
  # geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp"),
                   labels = c("original", "imputed")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.25\linewidth}
Estimates can be severely biased.
\end{column}
\end{columns}
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In some settings \blue{imputation in wide format} may be possible.

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.54\linewidth}
\only<1>{
<<impwideplot1a, echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_1
@
}
\only<2>{
<<impwideplotab, echo = F, fig.with = 6, fig.height = 4.5>>=
plong1_1 +
 geom_vline(xintercept = seq(1, 9, 2), lty = 2) +
  scale_x_continuous(breaks = seq(1, 9, 2))
@
}
\end{column}
\begin{column}{0.45\linewidth}
<<impwidedat, echo = F, size = 'scriptsize', warning = F>>=
longdatatab
@
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

<<impwidedat2, size = 'scriptsize', echo = F>>=
subDFexlongwide[c("id",
            paste0("y.", c(1,3,5,7,9)),
            paste0("time.", c(1,3,5,7,9)))] %>%
  round(2) %>%
  rbind(., rep("\\vdots", 11)) %>%
  cbind(., '\\ldots' = c(rep("\\ldots", 4), "$\\ddots$")) %>%
  kable(format = 'latex', row.names = F, booktabs = T, escape = F)
@

\bigskip

In this \blue{wide format data} frame, missing values in outcome and measurement times
need to be imputed (to be able to use them as predictors to impute covariates),
even though we would not need to impute them for the analysis
(mixed model valid when outcome measurements are M(C)AR).
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, cache = T>>=
impwide <- mice(DFexlongwide, printFlag = F, maxit = 10)
@

<<fig.height = 4, fig.width = 5, echo = F, message = F>>=
implist <- mice::complete(impwide, 'long') %>% split(., .$.imp)

longList <- lapply(implist, reshape, direction = 'long',
                   varying = list(y = paste0("y.", seq(1, 9, 2)),
                                  time = paste0("time.", seq(1, 9, 2))),
                   v.names = c("y", "time"),
                   timevar = 'tp', drop = ".imp")

midsobj <- miceadds::datalist2mids(longList)

lme_impwide <- with(midsobj, lmer(y ~ x1 + x2 + x3 + x4 + ns(time, df = 3) + (time|id)))
reswide <- as.data.frame(summary(pool(lme_impwide)))[, c("est", "lo 95", "hi 95")]
reswide$mod <- "impwide"
names(reswide) <- names(resimp)
reswide$var <- rownames(res0)

res2 <- rbind(res, reswide)#, coefJointAI)

ggplot(res2[!res2$var %in% grep("time", res2$var, value = T), ],
       aes(x = mod, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = lo, max = hi), width = 0.2) +
  facet_wrap("var", scales = 'free',
             labeller = as_labeller(c("x2girl" = "x2",
                                      "(Intercept)" = "Intercept",
                                      "x1" = "x1",
                                      "x3low" = "x3 (low)",
                                      "x3mid" = "x3 (mid)",
                                      "x4" = "x4"))) +
  geom_hline(yintercept = 0, lty = 2) +
  scale_x_discrete(limits = c("orig", "imp", "impwide"),#, "JointAI"),
                   labels = c("orig.", "imp.\nlong", "imp.\nwide")) +#, "JointAI")) +
  xlab("") +
  ylab("estimate & 95% CI")

@
\end{column}
\begin{column}{0.3\linewidth}
Better, but very large confidence intervals.
\end{column}
\end{columns}
\end{frame}


<<simlong2 data, echo = F, fig.with = 6, fig.height = 4>>=
coefDFexlong2 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ time), coef)))

coefDFexlong22 <- as.data.frame(t(sapply(lapply(split(DFexlong2, DFexlong2$id),
                                        lm, formula = y ~ time + I(time^2)), coef)))
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}


\begin{columns}
\begin{column}{0.7\linewidth}
<<echo = F, fig.width = 6, fig.height = 4>>=
plong2_0 <- ggplot(DFexlong2_sub, aes(x = time, y = y, color = factor(id))) +
  theme_light() +
  theme(legend.position = "none",
        axis.title = element_text(size = 14)) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_continuous(breaks = NULL) +
                     # minor_breaks = seq(from = 4, to = 6, by = 0.02)) +
  scale_x_continuous(breaks = NULL) +
  xlab("time")

plong2_1 <- plong2_0 +
  geom_line(lwd = 1) +
  geom_point(lwd = 2)
plong2_1
@
\end{column}
\begin{column}{0.3\linewidth}
When the data is very \blue{unbalanced}, i.e., there are no clear cut-offs in
time, transformation to wide format is not possible.

\bigskip

(Or at least transformation to wide format leads to variables with high proportions
of missing values.)
% When the measurement time-points do not follow a regular pattern, transformation
% to wide format is not possible.
\end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, label = naivelong]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.6\linewidth}
<<trajectories_ignore, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_1 +
  geom_line(data = data.frame(x = c(min(DFexlong2_sub$time), max(DFexlong2_sub$time),
                                    min(DFexlong2_sub$time), max(DFexlong2_sub$time)),
                              y = c(min(DFexlong2_sub$y), max(DFexlong2_sub$y),
                                    max(DFexlong2_sub$y), min(DFexlong2_sub$y)),
                              id = c(1, 1, 2, 2)),
            aes(x = x, y = y, group = factor(id)), color = "red", lwd = 2) +
  theme(axis.title = element_text(size = 16))
@
\onslide<2->{
<<trajectories_first, echo = F, fig.with = 6, fig.height = 3.5>>=
plong2_0 +
  geom_point(data = DFexlong2_sub[DFexlong2_sub$ti == 1, ],
             aes(x = time, y = y, fill = factor(id)),
             size = 8, shape = 21, alpha = 0.5) +
  geom_line(lwd = 1) +
  geom_point(lwd = 2) +
  scale_fill_brewer(palette = "Dark2") +
  theme(axis.title = element_text(size = 16))
@
}
\end{column}
\begin{column}{0.4\linewidth}
Naive approaches that are sometimes used are to
\begin{itemize}
\item \blue{ignore the outcome} in the imputation\onslide<2->{, or to}
\item<2-> use only the \blue{first/baseline outcome}
\end{itemize}

\bigskip

\onslide<3>{However, \blue{important information may be lost},
resulting in invalid imputations and biased results.}

\end{column}
\end{columns}
\end{frame}



\subsection{Example: Survival data}
<<simSurv, echo = F>>=
library(MASS)
library(splines)
n <- 500 # number of subjects

# parameters for the survival model
phi <- 1.6458 # shape for the Weibull baseline hazard
mean.Cens <- 12 # mean of the exponential distribution for the censoring mechanism

################################################
gammas <- c("(Intercept)" = -5.7296, "x2" = 2.4092, "x1" = -2, x3 = 0.2) # coefficients for baseline covariates

x2 <- rep(0:1, each = n/2) # group indicator, i.e., '0' placebo, '1' active treatment
x1 <- rnorm(n)
x3 <- rnorm(n)

# design matrix for the survival model
W <- cbind("(Intercept)" = 1,
           "x2" = x2,
           "x1" = x1,
           "x3" = x3)

################################################

# simulate event times
eta.t <- as.vector(W %*% gammas)
invS <- function(t, u, i) {
    h <- function(s) {
        x20 <- 1 - x2[i]
        x21 <- x2[i]
        exp(log(phi) + (phi - 1) * log(s) + eta.t[i])
    }
    integrate(h, lower = 0, upper = t)$value + log(u)
}
u <- runif(n)
trueTimes <- numeric(n)
for (i in 1:n) {
    Up <- 50
    tries <- 5
    Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    while (inherits(Root, "try-error") && tries > 0) {
        tries <- tries - 1
        Up <- Up + 200
        Root <- try(uniroot(invS, interval = c(1e-05, Up), u = u[i], i = i)$root, TRUE)
    }
    trueTimes[i] <- if (!inherits(Root, "try-error")) Root else NA
}
na.ind <- !is.na(trueTimes)
trueTimes <- trueTimes[na.ind]
W <- W[na.ind, , drop = FALSE]

n <- length(trueTimes)

# simulate censoring times from an exponential distribution,
# and calculate the observed event times, i.e., min(true event times, censoring times)
Ctimes <- runif(n, 0, 2 * mean.Cens)
Time <- pmin(trueTimes, Ctimes)
event <- as.numeric(trueTimes <= Ctimes) # event indicator

survdat_orig <- data.frame(Time = Time,
                           event = event,
                           x2 = x2[na.ind],
                           x1 = x1[na.ind],
                           x3 = x3[na.ind])

@


<<echo = F>>=
library(survival)
library(mice)

survdat <- survdat_orig
N = n
survdat$x1[sample(1:N, N*0.3)] <- NA
survdat$x3[sample(1:N, N*0.3)] <- NA
survdat$x2[sample(1:N, N*0.3)] <- NA
survdat$x2 <- factor(survdat$x2)
survdat_orig$x2 <- factor(survdat_orig$x2 + 1)


imp00 <- mice(survdat, maxit = 0)

meth01 <- imp00$method
meth01[c("x1")] <- "norm"
meth01[c("x3")] <- "norm"

impsurv_01 <- mice(survdat, maxit = 10, method = meth01)

cox <- with(survdat_orig, coxph(Surv(Time, as.numeric(event)) ~ x1 + x2 + x3))
cox01 <- with(impsurv_01, coxph(Surv(Time, as.numeric(event)) ~ x1 + x2 + x3))

rescox01 <- as.data.frame(summary(pool(cox01))[, c("est", "lo 95", "hi 95")])
rescox <- as.data.frame(cbind(cox$coef, confint(cox)))

rescox01$meth <- "norm"
rescox$meth <- "orig"

rescox$var = rownames(rescox)
rescox01$var = rownames(rescox)

names(rescox) <- names(rescox01)
plotcox <- rbind(rescox, rescox01)
@

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In \blue{survival analysis}, the aim is to estimate the effect of covariates on
the \blue{time until an event} of interest happens.

\bigskip

\pause
In the commonly used method: \blue{Cox proportional hazards model}

$$h(t) = h_0(t) \exp(x \beta_x + z\beta_z),$$

\begin{itemize}
\item $h(t)$: hazard = the instantaneous risk of an event at time $t$,
      given that the event has not occurred until time $t$
\item $h_0(t)$: unspecified baseline hazard
\item \blue{$x$} and \blue{$z$}: \blue{incomplete} and \blue{complete}
covariates, respectively
\end{itemize}

\bigskip

\pause
\blue{Survival outcomes} are usually represented by the \blue{observed event
time $T$} and the \blue{event indicator $D$} ($D = 1$: event, $D = 0$: censored).
\end{frame}

\begin{frame}[fragile, label=survivalmice]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Naive use of MICE} treats the columns in the data set containing $T$ and $D$
just like any other variable, and the resulting imputation model for $X$ would have the form
$$p(x \mid T, D, \mathbf z) = \theta_0 + \theta_1 T + \theta_2 D + \theta_3 z + \ldots.$$

\bigskip

\pause
The correct conditional distribution of $x$ given the other variables is, however,
\begin{multline}
\log p(x\mid T, D, z) = \log p(x\mid z) + D(\beta_x x + \beta_z z) - \\
H_0(T)\exp(\beta_x x+\beta_z z) + const.,\nonumber
\end{multline}
where $H_0(T)$ is the cumulative baseline hazard.\cite{White2009}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using the naively assumed imputation model can lead to \blue{severe bias}:

<<plot surv example, echo = F, fig.width = 7, fig.height = 3, out.width = "90%">>=
library(ggplot2)
ggplot(plotcox, aes(x = meth, y = est)) +
  geom_point() +
  geom_errorbar(aes(min = `lo 95`, max = `hi 95`), width = 0.2) +
  theme(axis.text = element_text(size = 12),
        strip.text = element_text(size = 12)) +
  facet_wrap("var", scales = 'free',
             labeller = labeller(var = c("x22" = "x2 (binary)",
                                         "x1" = "x1 (continuous)",
                                         "x3" = "x3 (continuous)"))) +
  scale_x_discrete(limits = c("orig", "norm"),
                   labels = c("original", "naive\nimputation")) +
  xlab("") +
  ylab("estimate & 95% confidence interval")
@
(Results from MICE imputation with two incomplete normal and one incomplete binary covariate.)
\end{frame}



\section{Requirements for MICE to work (well)}
\subsection{Joint and conditional distributions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Recall:} The MICE algorithm is based on the idea of Gibbs sampling.

\bigskip

Gibbs sampling exploits the fact that a joint distribution is fully determined
by its full conditional distributions.

\begin{center}
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white} joint\\distribution}
}
\quad
\parbox[c]{3cm}{
\tikzfancyarrow[3cm]{\scriptsize \textbf{Gibbs}}\\
\onslide<2>{\tikzfancyarrow[3cm, shape border rotate = 180]{\scriptsize \textbf{MICE}}}
}
\quad
\tcbox[nobeforeafter, box align=base, colback = EMCdark, colframe=EMCdark, boxsep = 1ex]{
   \parbox{2.5cm}{\centering\color{white}full\\conditionals}
}
\end{center}

\onslide<2>{In MICE, the full conditionals are not derived from the joint distribution:\\
we directly specify the full conditionals and hope a joint distribution exists.}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The \blue{uncertainty about whether a joint distribution exists} for the specified
set of imputation models is often considered to be mainly a theoretical problem.

\bigskip

In practice, violations only have little impact on results in many applications.

\bigskip

However, as we have seen in the examples on the previous slides,
there are \blue{settings where the direct specification} of the full
conditionals/imputation models \blue{may lead to problems}, causing biased results.

\end{frame}


\subsection{Some conditions and definitions}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two important definitions:

\bigskip


\blue{Compatibility:}
\begin{quote}
A joint distribution exists, that has the full conditionals (imputation models)
as its conditional distributions.
\end{quote}

\blue{Congeniality:}
\begin{quote}
The imputation model is compatible with the analysis model.
\end{quote}

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Important requirements} for MICE to work well include:
\begin{itemize}
\item Compatibility
\item Congeniality
\item MAR or MCAR (in the standard implementations)
\item \blue{all relevant variables} need to be included (omission might result in MNAR)
\item \textbf{\textcolor{red}{The outcome needs to be included}} as predictor variable\\
      (but we usually do not impute missing outcome values)
\item the imputation models (and analysis model) need to be \blue{correctly specified}
      (which is a requirement in any standard analysis)
\end{itemize}
\end{frame}


\subsection{Why imputation with MICE can go wrong}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\blue{What went wrong in our previous examples?}

\bigskip

When incomplete variables have \blue{non-linear associations} with the outcome,
or with each other, the requirement(s) of \blue{\textit{compatibility} and/or
\textit{congeniality} are violated}.

\bigskip

\blue{Omission, or inadequate inclusion, of the outcome} may result in \blue{MNAR} missing
mechanisms. The same is the case when other relevant predictor variables
are not used as predictor variables in the imputation.
\bigskip

Furthermore, \blue{omission of variables} may lead to \blue{mis-specified models},
however, models may also be mis-specified when all relevant covariates are included,
but \blue{distributional assumptions} or the specified \blue{form of associations}
are incorrect.
\end{frame}



\section{Alternatives to MICE}
\subsection{Joint model imputation}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To \blue{avoid incompatible and uncongenial imputation models}, we need to
\begin{itemize}
\item specify the joint distribution
\item and derive full conditionals / imputation models from this joint distribution
\end{itemize}
instead of specifying them directly.

\bigskip

\pause
\blue{Problem:}\\
Especially in settings with several \blue{variables of mixed type}, the joint
distribution is usually not of any known form:

\begin{eqnarray*}
\begin{array}{c}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim N(\mu_2, \sigma_2^2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim N\left(
                \left[
                  \begin{array}{c}
                  \mu_1\\ \mu_2
                  \end{array}
                \right], \left[
                            \begin{array}{cc}
                            \sigma_1^2 & \sigma_{12}\\
                            \sigma_{12} & \sigma_2^2
                            \end{array}
                          \right]
              \right)\\[2ex]
\text{\blue{but}\quad}
\begin{array}{l}
x_1 \sim N(\mu_1, \sigma_1^2)\\
x_2 \sim Bin(\mu_2)\\
\end{array}
& \Rightarrow &
\left(
  \begin{array}{c}
  x_1\\ x_2
  \end{array}
\right) \sim ???
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Approach 1: Multivariate Normal Model}\\
Approximate the joint distribution by a known multivariate distribution
\mode<presentation>{
(usually the normal distribution; this is the approach mentioned in Part I
on slide~\ref{jointmodelimp})
}
\mode<article>{
(usually the normal distribution; this is the approach mentioned in Part I
in Section~\ref{subsec:multivarmissing})
}

\bigskip

\blue{Approach 2: Sequential Factorization}\\
Factorize the joint distribution into a (sequence of) conditional and a marginal
distributions
\end{frame}

\subsection{Multivariate Normal Model}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{Assumption:}\\
The outcome and incomplete variables follow a \blue{joint multivariate normal
distribution}, conditional on the completely observed covariates $\mathbf X_c$,
parameters $\bmath\theta$ and, possibly, random effects, $\bmath b$:
$$ p(\bmath y, \bmath x_1,\ldots, \bmath x_p \mid \mathbf X_c, \bmath\theta,
     \bmath b) \sim N(\bmath \mu, \bmath \Sigma)$$

\bigskip

\onslide<2>{
\textbf{How do we get that multivariate normal distribution?}
\begin{enumerate}
\item Assume \blue{all} incomplete variables and the outcome are \blue{(latent) normal}.
\item Specify linear (mixed) \blue{models based on observed covariates}.
\item \blue{Connect} using multivariate normal for \blue{random effects \& error terms}.
\end{enumerate}
}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{1. Latent normal assumption:}\vspace*{-3ex}
$$\text{e.g.: } \bmath x_k \text{ binary }
  \rightarrow \text{ latent } \bmath{\hat x}_k \text{ is standard normal: }
  \left\{\begin{array}{c} \bmath x_k = 1\\ \bmath x_k = 0\end{array}\right.
  \text{ if } \begin{array}{c} \bmath{\hat x_k}\geq 0\\ \bmath{\hat x_k} < 0\end{array}
$$

<<echo = F, fig.width = 6, fig.height = 3, out.width = "70%">>=
par(mar = c(3.5, 4.4, 0.5, 0.5), mgp = c(2.5, 0.6, 0))
plot(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)), type = "l", cex.lab = 1.5,
     xlab = expression(hat(x)[k]), ylab = expression(density~of~hat(x)[k]))
polygon(x = c(seq(-4, 0, 0.1), 0),
        y = c(dnorm(seq(-4, 0, 0.1)), 0), col = grey(0.9), border = 'transparent')
polygon(x = c(seq(4, 0, -0.1), 0),
        y = c(dnorm(seq(4, 0, -0.1)), 0), col = grey(0.7), border = 'transparent')
abline(v = 0, lty = 2)
lines(seq(-4, 4, 0.1), dnorm(seq(-4, 4, 0.1)))
text(x = -1, y = 0.05, label = bquote(x[k] == 0), cex = 1.5)
text(x = 1, y = 0.05, label = bquote(x[k] == 1), cex = 1.5)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<1>{\textbf{2. Specify models:}\\}
\only<2>{\textbf{2. Specify models / 3. Connect random effects \& error terms:}\\}
\begin{picture}(200, 120)
\onslide<1->{
\put(0, 60){
    $\addtolength\arraycolsep{-.8ex}\def\arraystretch{1.5}
    \begin{array}{rclclcl}
    \bmath y   &=& \bmath X_c \bmath{\beta}_y     &+& \bmath{ Z_y} \;\bmath{ b_y} &+& \bmath{ \varepsilon_y}\\
    \textcolor{black!30}{\bmath w} &=& \textcolor{black!30}{\bmath X_c \bmath{\beta}_w}
                                   &+& \textcolor{black!30}{\bmath{ Z_w} \,\bmath{ b_w}}
                                   &+& \textcolor{black!30}{\bmath{ \varepsilon_w}}\\
    \bmath{\hat x}_1 &=& \bmath X_c \bmath{\beta}_{x_1} &+& \phantom{\bmath Z_w\,} \bmath{ \varepsilon_{x_1}}      &&\\[-1ex]
               & \vdots&                                & & \phantom{\bmath Z_w\;} \vdots                                &&\\[-1ex]
    \bmath{\hat x}_p &=& \bmath X_c \bmath{\beta}_{x_p} &+& \phantom{\bmath Z_w\,} \bmath{ \varepsilon_{x_p}}      &&
    \end{array}
    $
    }
}
\thicklines
\onslide<2>{
\put(124, 87){\color{red} \oval(15, 35)}
\put(96, 62.5){\color{red} \oval(18, 93)}
\put(97, 15){\line(0,-1){12}}
\put(97, 3){\vector(1, 0){10}}
\put(110, 0.5){multivariate normal}
%
\put(125, 67){\line(0,-1){17}}
\put(125, 50){\vector(1, 0){10}}
\put(137.5, 47.5){multivariate normal (optional, but suggested)}
}
\end{picture}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}[T,onlytextwidth]
\begin{column}{0.5\linewidth}
\blue{Advantages:}
\begin{itemize}
\item Easy to specify
\item Relatively easy to implement
\item Relatively easy to sample from
\item Works for longitudinal outcomes
\end{itemize}
\end{column}
\begin{column}{0.5\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item Assumes linear associations
\end{itemize}
\end{column}
\end{columns}

\bigskip

\begin{center}
\parbox{0.6\linewidth}{Imputation with \blue{non-linear associations} or \blue{survival data} is
possible with \blue{extensions} of the multivariate normal approach.
}\end{center}
\end{frame}

\subsection{Sequential Factorization}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\onslide<1->{
The \blue{joint distribution} of two variables $y$ and $x$ can be written
as the product of a conditional and a marginal distribution:
$$p(y,x) = p(y\mid x)\;p(x)$$
(or alternatively $p(y,x) = p(x\mid y)\;p(y)$)
}

\vfill

\onslide<2->{
This can easily be \blue{extended for more variables}:
$$p(y,x_1,\ldots,x_p, X_c) = \underset{\text{analysis model}}{
                             \underbrace{p(y\mid x_1,\ldots,x_p, X_c)}}\;
p(x_1\mid x_2,\ldots,x_p, X_c)\;
\ldots\; p(x_p\mid X_c)$$%

where $x_1, \ldots, x_p$ denote incomplete covariates and $X_c$ contains all
completely observed covariates.
}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
That the analysis model is part of the specification of the joint distribution has
several advantages:
\begin{itemize}
\item<1-> The outcome is \blue{automatically included in the imputation} procedure.
\item<1-> The outcome does not appear in any of the predictors of the imputation
      models:
      \begin{itemize}
      \item \blue{no need to approximate} complex outcomes,
      \item \blue{no need to summarize} complex outcomes.
      \end{itemize}
\item<2-> The parameters of interest are obtained directly\\
      \blue{\ding{225}}
      imputation and analysis in one step
\item<3-> \blue{Non-linear associations} or interactions involving incomplete covariates
      are specified in the analysis model and thereby
      \blue{automatically taken into account}
\end{itemize}


\bigskip

\onslide<4>{Since the joint distribution usually does not have a known form, Gibbs sampling
is used to estimate parameters and sample imputed values.}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\begin{columns}
\begin{column}{0.55\linewidth}
\blue{Advantages:}
\begin{itemize}
\item \blue{flexible} with regards to outcome type
\item univariate conditional distributions of incomplete covariates can be chosen
according to \blue{type of variable}
\item \blue{non-linear associations} and interactions can be taken into account
\item assures \blue{congeniality and compatible imputation models}
\end{itemize}
\end{column}
\begin{column}{0.45\linewidth}
\blue{Disadvantages:}
\begin{itemize}
\item separate models need to be specified per incomplete variable: \blue{takes more time
and consideration}
\item the joint distribution is of unknown form and sampling may be more \blue{computationally intensive}
\end{itemize}
\end{column}
\end{columns}
\end{frame}


\section{Imputation with non-linear functional forms}
\begin{frame}[fragile]{\thesection. \insertsection}

In the following we will not only consider the \textsf{R} package \blue{mice},
but also three additional packages, \blue{JointAI}, \blue{smcfcs} and \blue{jomo},
that provide alternatives to \textbf{mice}.

\vfill

These three packages use \blue{Bayesian methodology} to impute values, but once imputed
datasets are obtained, standard complete data methods can be used.

\bigskip

\blue{jomo} and \blue{smcfcs} perform \blue{multiple imputation} and create imputed
datasets that can then be analysed the same way data imputed by \textbf{mice}
would be analysed.

\bigskip

\blue{JointAI} works \blue{fully Bayesian} and performs the analysis and imputation
simultaneously, so that the results from the analysis model of interest are
obtained directly.
\end{frame}


\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
There is no strategy for MICE that can guarantee valid imputations when
non-linear functional forms and/or interactions are involved,
but some settings in \textbf{mice} may help to reduce bias in the resulting estimates.

\bigskip

For imputation of variables that have non-linear associations
\begin{itemize}
\item \Rstring{pmm} often works better than \Rstring{norm},
\item Just Another Variable approach can reduce bias in interactions,
\item \Rstring{quadratic} can help to impute variables with quadratic association.
% \item inclusion of interaction terms in the imputation model may help.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In the \blue{Just Another Variable (JAV)} approach the non-linear form (or interaction term)
is calculated in the incomplete data, added as a column to the dataset and
imputed as if it was just another variable.

\bigskip

\Rstring{quadratic} provides imputation of covariates that have a
quadratic association with the outcome, using the ``polynomial combination''
method.\cite[pp. 139--141]{Buuren2012}, \cite{Vink2013}.

\bigskip

This is to ensure the imputed values for $x$ and $x^2$ are consistent,
and to reduce bias in the subsequent analysis that uses $x$ and $x^2$.

\bigskip

In my experience, using \Rstring{quadratic} can lead to numerical problems.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To demonstrate the approaches, we use a simulated example dataset \Robj{DFnonlin}, with
\begin{itemize}
\item continuous outcome $y$
\item continuous (normal) covariate $x$ (50\% missing values MCAR)
\item quadratic effect of $x$ on $y$
\item binary covariate $z$ (complete)
\item interaction between $x$ and $z$
\end{itemize}

<<echo = F>>=
# simulate data
set.seed(2018)
N <- 200
x <- rnorm(N)
z <- rbinom(N, size = 1, prob = plogis(x))
y <- x + x^2 + z + x*z + rnorm(N, 0, 0.5)

DF_nonlin <- data.frame(y = y, x = x, z = z)

# model on complete data
mod_nonlin <- lm(y ~ x + I(x^2) + z + x:z, data = DF_nonlin)

# create missing values
DF_nonlin$x[sample(1:length(x), size = N/2)] <- NA
@

\bigskip

\pause
In the naive approach, we leave all settings to the defaults.
<<size = 'small'>>=
# naive imputation, using only y, x, z
impnaive <- mice(DF_nonlin, printFlag = F)
@

\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We use two different JAV approaches:\\[2ex]
\blue{JAV:} calculating the quadratic and interaction term before imputation
<<size = 'small'>>=
# add quadratic term and interaction to data
DF2 <- DF_nonlin
DF2$xx <- DF2$x^2
DF2$xz <- DF2$x * DF2$z

# JAV imputation
impJAV <- mice(DF2, printFlag = F, maxit = 20)
@
\blue{JAV2:} additionally using an interaction between $z$ and $y$
<<size = 'small'>>=
# add interaction between y and z to data
DF3 <- DF2
DF3$yz <- DF3$y * DF3$z

# JAV imputation with additional interaction
impJAV2 <- mice(DF3, printFlag = F, maxit = 20)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
We also try using imputation method \Rarg{quadratic}.
<<warning = F, size = 'small'>>=
# adapt the imputation method for quadratic imputation
methqdr <- impJAV$meth
methqdr[c("x", "xx", "xz")] <- c("quadratic", "~I(x^2)", "~I(x*z)")

# adapt the predictor matrix
predqdr <- impJAV$pred
predqdr[, "xx"] <- 0

impqdr <- mice(DF2, meth = methqdr, pred = predqdr,
               printFlag = F, maxit = 10)
@
Note: there were warning messages about numerical issues for this approach.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 6, fig.height = 3.5>>=
res_impnaive <- with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary
res_JAV <- with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_JAV2 <- with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary
res_qdr <- with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

resqdr <- rbind(
  with(impnaive, lm(y ~ x + I(x^2) + z + x:z)) %>% pool %>% summary,
  with(impJAV, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impJAV2, lm(y ~ x + xx + z + xz)) %>% pool %>% summary,
  with(impqdr, lm(y ~ x + xx + z + x:z)) %>% pool %>% summary

)[, c("est", 'lo 95', 'hi 95')] %>%
  `row.names<-`(1:(4*5)) %>%
  as.data.frame() %>%
  mutate(meth = rep(c("naive", "JAV", "JAV2", "qdr"), each = 5),
         var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), 4),
         beta = rep(coef(mod_nonlin), 4)
  )

polyDF_nonlin <- data.frame(x = rep(c(0, 5, 5, 0), 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"),
                               each = 4)
)

ggplot(resqdr, aes(x = meth, y = est)) +
  geom_polygon(data = polyDF_nonlin,
               aes(x = x, y = y), fill = 'blue', alpha = 0.2) +
  geom_point() +
  geom_errorbar(aes(ymin = `lo 95`, ymax = `hi 95`)) +
  facet_wrap("var", scales = 'free') +
  geom_hline(aes(yintercept = beta), lty = 2) +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr")) +
  ylab("estimate & 95% confidence interval")
@
For this example, \blue{none of the approaches provided satisfying results}.
\end{frame}


\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

The package \href{https://cran.r-project.org/web/packages/JointAI/index.html}%
{\blue{JointAI}} uses the \blue{sequential factorization approach} to perform
simultaneous analysis and imputation.\cite{Erler2016, Erler2017}

\bigskip

\textbf{JointAI} (version 0.1.0) can handle

\begin{itemize}
\item linear regression
\item generalized linear regression
\item linear mixed models
\end{itemize}

while assuring compatibility between analysis model and imputation models
when non-linear functions or interactions are included.

\bigskip

The necessary Gibbs sampling is performed using \textsf{JAGS} (an external program),
which is free, but needs to be
installed from \url{https://sourceforge.net/projects/mcmc-jags/files/}.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\blue{JointAI} can be installed from CRAN
<<eval = F, size = 'small'>>=
install.packages("JointAI")
@

The development version (containing bug fixes and other improvements)
can be installed from \href{https://github.com/nerler/JointAI}{GitHub}
<<eval = F, size = 'small'>>=
install.packages("devtools")
devtools::install_github("NErler/JointAI")
@

A detailed explanation of the functionality is given in the help files of the
package, and a vignette with an in-depth example analysis will be available soon.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The syntax we use to analyse and impute the current example using \blue{JointAI} is
similar to the specification of a standard linear model using \Rfct{lm}.

<<JointAI_nonlin, eval = F, size = 'small'>>=
library(JointAI)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF_nonlin,
                         n.iter = 2500)
@

\pause
Convergence of the Gibbs sampler can be checked using a traceplot.
<<JointAI_nonlin02, eval = F, size = 'small'>>=
traceplot(JointAI_nonlin)
@

<<runJointAI_nonlin, eval = F, echo = F>>=
library(JointAI)
set.seed(1234)
JointAI_nonlin <- lm_imp(y ~ x*z + I(x^2), data = DF_nonlin, n.iter = 2500)
save(JointAI_nonlin, file =  "workspaces/JointAI_nonlin.RData")
@

<<getJointAI_nonlin, echo = F>>=
load("workspaces/JointAI_nonlin.RData")
@

Results (no separate analysis \& pooling is necessary) can be obtained with
the \Rfct{summary} function:
<<size = 'small'>>=
res_JointAI_nonlin <- summary(JointAI_nonlin)
@
\end{frame}



\subsection{R package smcfcs}
\begin{frame}{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The package
\href{https://cran.r-project.org/web/packages/smcfcs/index.html}{\blue{smcfcs}}
performs multiple imputation using
\textit{substantive model compatible fully conditional specification}, a \blue{hybrid
approach between FCS and sequential factorization}.\cite{Bartlett2015}

\bigskip
\textbf{smcfcs} (version 1.3.0) can handle
\begin{itemize}
\item linear regression,
\item logistic regression,
\item poisson regression,
\item Cox proportional hazard models, and
\item competing risk survival models,
\end{itemize}

while ensuring compatibility between analysis model and imputation models.

\bigskip

For more information see the help files and the
\href{https://cran.r-project.org/web/packages/smcfcs/vignettes/smcfcs-vignette.html}%
{vignette}.
\end{frame}


\begin{frame}[fragile, label=smcfcsnonlin]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The syntax to impute the data in the current example using the package \blue{smcfcs}
is:
<<smcfcs_nonlin01, eval = F, size = 'small'>>=
library(smcfcs)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)
@

The convergence of the procedure should be checked, for example with the
following syntax:
<<smcfcs_nonlin02, eval = F, size = 'small'>>=
par(mfrow = c(2,3), mar = c(2, 2, 0.5, 0.5), mgp = c(2, 0.6, 0))
for(i in 1:dim(smcfcs_nonlin$smCoefIter)[2]) {
  matplot(t(smcfcs_nonlin$smCoefIter[, i, ]), type = 'l', ylab = '')
}
@

<<smcfcs_nonlin_run, eval = F, echo = F>>=
library(smcfcs)
set.seed(2018)
smcfcs_nonlin <- smcfcs(originaldata = DF_nonlin, smtype = "lm",
                        smformula = "y~x*z + I(x^2)",
                        method = c("", "norm", ""),
                        rjlimit = 3000, numit = 20)
save(smcfcs_nonlin, file = 'workspaces/smcfcs_nonlin.RData')
@

<<smcfcs_nonlin_get, echo = F, include = F>>=
library(smcfcs)
library(miceadds)
load("workspaces/smcfcs_nonlin.RData")
impobj_smcfcs_nonlin <- datalist2mids(smcfcs_nonlin$impDatasets)
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- summary(pool(models_smcfcs_nonlin))
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
To be able to use the convenient pooling function from the \textbf{mice} package
we first need to convert the imputed data (which is a list)
to a \Robj{mids} object.

\bigskip

This can be done with the function \Rfct{datalist2mids} from the \textbf{miceadds}
package.
<<smcfcs_nonlin_pool1, eval = F, size = 'small'>>=
library(miceadds)
impobj_smcfcs_nonlin <- datalist2mids(smcfcs_nonlin$impDatasets)
@

The \Robj{mids} object can then be pooled and summarized as we have seen before
with \texttt{mids} objects created by \Rfct{mice}.
<<smcfcs_nonlin_pool2, eval = F, size = 'small'>>=
models_smcfcs_nonlin <- with(impobj_smcfcs_nonlin, lm(y ~ x*z + I(x^2)))
res_smcfcs_nonlin <- summary(pool(models_smcfcs_nonlin))
@
\end{frame}




\subsection{R package jomo}
\begin{frame}{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The package
\href{https://cran.r-project.org/web/packages/jomo/index.html}{\blue{jomo}}
performs \blue{joint model imputation} using the multivariate normal approach,
with \blue{extensions to assure compatibility} between analysis and imputation models.\cite{Carpenter2012}

\bigskip

\textbf{jomo} (version 2.6-2) can handle
\begin{itemize}
\item linear regression,
\item generalized linear regression,
\item linear mixed models,
\item generalized linear mixed models, and
\item Cox proportional hazards models.
\end{itemize}
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using \blue{jomo} we can impute the data in the current example as follows:
<<jomo_nonlin, eval = F, size = 'small'>>=
library(jomo)
jomo_nonlin <- jomo.lm(y ~ x*z + I(x^2), data = DF_nonlin)
@

<<jomo_nonlin_run, echo = F, eval = F>>=
library(jomo)
set.seed(2018)
jomo_nonlinMCMC <- jomo.lm.MCMCchainC(y ~ x*z + I(x^2), data = DF_nonlin)
jomo_nonlin <- jomo.lmC(y ~ x*z + I(x^2), data = DF_nonlin)
save(jomo_nonlin, jomo_nonlinMCMC, file = "workspaces/jomo_nonlin.RData")
@

<<jomo_nonlin_get, echo = F, include = F>>=
library(jomo)
library(miceadds)
load("workspaces/jomo_nonlin.RData")
impobj_jomo_nonlin <- datalist2mids(split(jomo_nonlin,
                                          jomo_nonlin$Imputation)[-1])
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(pool(models_jomo_nonlin))
@

\pause
To check the convergence of the model, the corresponding function with
ending \Rfct{.MCMCchain} has to be used.
<<jomo_nonlin2, eval = F, size = 'small'>>=
jomo_nonlinMCMC <- jomo.lm.MCMCchain(y ~ x*z + I(x^2), data = DF_nonlin)

par(mfcol = c(2, 3), mar = c(3, 2.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
apply(jomo_nonlinMCMC$collectbeta[1, ,], 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
for (k in 1:dim(jomo_nonlinMCMC$collectomega)[1]) {
  apply(jomo_nonlinMCMC$collectomega[k, , ], 1, plot, type = "l",
        xlab = 'iteration', ylab = '')
}

apply(jomo_nonlinMCMC$collectbetaY[1, ,], 1, plot, type = "l",
      xlab = 'iteration', ylab = '')
plot(jomo_nonlinMCMC$collectvarY, type = 'l')
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

Again, we need to convert the output to a \Robj{mids} object using
\Rfct{datalist2mids}. However, \Rfct{jomo.lm} returns a data frame, in which
the original data and all imputed datasets are stacked onto each other.

\bigskip

\Rfct{split} splits the dataset by imputation number into a list of datasets,
from which we need to exclude the first element (the original/incomplete data).

<<eval = F, size = 'small'>>=
impobj_jomo_nonlin <- datalist2mids(split(jomo_nonlin,
                                          jomo_nonlin$Imputation)[-1])
@

With the resulting \Robj{mids} object, analysis of the imputed data and
pooling of the results works as in the above examples.
<<eval = F, size = 'small'>>=
models_jomo_nonlin <- with(impobj_jomo_nonlin, lm(y ~ x*z + I(x^2)))
res_jomo_nonlin <- summary(pool(models_jomo_nonlin))
@
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, figwidth = 6, fig.height = 4.5>>=
res_nonlin <- list(naive = as.data.frame(res_impnaive[, c("est", "lo 95", "hi 95")]),
                   JAV = as.data.frame(res_JAV[, c("est", "lo 95", "hi 95")]),
                   JAV2 = as.data.frame(res_JAV2[, c("est", "lo 95", "hi 95")]),
                   qdr = as.data.frame(res_qdr[, c("est", "lo 95", "hi 95")]),
                   JointAI = as.data.frame(res_JointAI_nonlin$stat[, c(1,3,4)]),
                   smcfcs = as.data.frame(res_smcfcs_nonlin[, c("est", "lo 95", "hi 95")]),
                   jomo = as.data.frame(res_jomo_nonlin[, c("est", "lo 95", "hi 95")])
)

res_nonlin <- lapply(res_nonlin, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- gsub("xx", "I(x^2)", rownames(x)) %>%
    gsub("xz", "x:z", .)
  x
})

plot_nonlin <- reshape2::melt(res_nonlin, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_nonlin) + .5)[c(1,2,2,1)], 5),
                     y = c(apply(confint(mod_nonlin), 1, rep, each = 2)),
                     var = rep(c("(Intercept)", "x", "I(x^2)", "z", "x:z"), each = 4)
)

ggplot(plot_nonlin, aes(x = L1, y = coef)) +
  geom_point() +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.2) +
  geom_hline(data = data.frame(betas = coef(mod_nonlin),
                               var = names(coef(mod_nonlin))),
             aes(yintercept = betas), lty = 2) +
  ylab("coefficient") +
  xlab("") +
  scale_x_discrete(limits = c("naive", "JAV", "JAV2", "qdr",
                              "JointAI", "smcfcs", "jomo")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
\end{frame}

\begin{frame}
\begin{beamercolorbox}[sep=8pt,center,wd=\textwidth]{part title}
\usebeamerfont{part title}
Practical
\end{beamercolorbox}

\vfill

To practice imputation with non-linear forms or interaction terms, go to
\begin{block}{}
\centering\url{https://emcbiostatistics.shinyapps.io/MICourse_MIadvanced}
\end{block}
or download the instructions and data for the practical from Canvas\\
(Files $>$ Principal documents $>$ Multiple Imputation $>$ Practical MIadvanced).

\vfill

\end{frame}

\section{Imputation of longitudinal data}
\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

\textbf{mice} has functions to allow imputation of longitudinal (2-level) data.
\begin{itemize}
\item \blue{Level 1:}\\
repeated measurements (within subjects) or subjects (within classes)
\item \blue{Level 2:}\\
time-constant/baseline covariates, between subjects effects, variables on the group level
\end{itemize}

\bigskip

\begin{columns}[onlytextwidth]
\begin{column}{0.5\textwidth}
Imputation methods for \blue{level-1} variables:
\begin{itemize}
\item \Rstring{2l.pan}
\item \Rstring{2l.norm}
\item \Rstring{2l.lmer}
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
Imputation methods for \blue{level-2} variables:
\begin{itemize}
\item \Rstring{2lonly.norm}
\item \Rstring{2lonly.pmm}
\item \Rstring{2lonly.mean}
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.pan} uses a linear two-level model with \blue{homogeneous
within group variances} using Gibbs sampling \cite{Schafer2002}.
It needs the package \textbf{pan} to be installed.

\bigskip

\Rstring{2l.pan} allows for different roles of predictor variables, that
can be specified as different values in the \Rarg{predictorMatrix}:
\begin{itemize}
\item grouping/ID variable: -2
\item random effects (also included as fixed effects): 2
\item fixed effects of group means: 3
\item fixed effects of group means \& random effects: 4
\end{itemize}

<<micelong_ex1_cont3_, eval = F, size = 'small'>>=
# random effects of x in model for y
pred["y","x"] <- 2
# fixed effects of x and group mean of x
pred["y","x"] <- 3
# random effects of x and group mean of x
pred["y","x"] <- 4
@
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2l.norm} implements a (Bayesian) linear two-level model with
\blue{heterogenous} group variances.

In the current implementation all predictors should be specified as random
effects (set to 2 in the \Rarg{predictorMatrix}, because the algorithm does not
handle predictors that are specified as fixed effects).

\bigskip

\pause
\Rstring{2l.lmer} imputes univariate systematically and sporadically
missing data using a two-level normal model using \Rfct{lmer} from package
\textbf{lme4} (developed in the context of individual patient meta analysis.
\cite{Jolani2015, Jolani2018})

\bigskip

\pause
\Rstring{2lonly.norm} and \Rstring{2lonly.pmm} can be used
to impute level-2 variables (in combination with \Rstring{2l.pan} for
level-1 variables).

\bigskip

In all case, the group identifier ("id" variable") needs to be set to -2 in
the \Rarg{predictorMatrix}.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\Rstring{2lonly.mean} imputes values with the mean of the observed values per
class. This method should only be used to fill in values that are known to be
constant per class and have some values observed in each class.

\bigskip

\textbf{Example:}
In a multi-center trial the type of some medical equipment is known to be
the same for all patients treated in the same hospital, but not filled in for
some patients.
\end{frame}



\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As an example, we will impute the second (unbalanced) longitudinal
data example from above. The data contain
\begin{itemize}
\item $x1$ (complete)
\item $x2$ (binary, 30\% missing values)
\item $x3$ (3 categories, 30\% missing values)
\item $x4$ (continuous/normal, 30\% missing values)
\item $y$ (longitudinal outcome)
\item $time$ (time variable with quadratic effect)
\item $id$ (id variable)
\end{itemize}

\bigskip

Since there is no 2-level method for categorical data, we use \Rstring{2lonly.pmm}
to impute $x2$ and $x3$.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
As usual, we start with the setup run of \Rfct{mice}
<<miceimp_DFexlong2, size = 'small'>>=
imp0 <- mice(DFexlong2, maxit = 0)
meth <- imp0$method
pred <- imp0$predictorMatrix
@

and adjust the imputation \Rarg{method} and \Rarg{predictorMatrix}
<<miceimp_DFexlong2_02, size = 'small'>>=
meth[c("x2", "x3")] <- "2lonly.pmm"
meth[c("x4")] <- "2lonly.norm"

pred[, "id"] <- -2  # identify id variable
pred[, "ti"] <- 0 # don't use time-point indicator
@

We can then perform the imputation.
<<miceimp_DFexlong2_03, size = 'small'>>=
imp <- mice(DFexlong2, maxit = 10, method = meth,
            predictorMatrix = pred, printFlag = F)
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
The imputed data can be analysed using either \Rfct{lmer} from the package
\textbf{lme4}, or \Rfct{lme} from \textbf{nlme}. Here we use the former.
<<miceimp_DFexlong2_04, size = 'small'>>=
library(lme4)
models <- with(imp, lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) +
                           (time|id)))
mice_longimp <- summary(pool(models))
@
\end{frame}


<<miceimp_DFexlong2_naive, echo = F>>=
pred[, c("id", "ti")] <- 0
impnaive <- mice(DFexlong2, predictorMatrix = pred, maxit = 10)
models2 <- with(impnaive,
                lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id)))

mice_longimp_naive <- summary(pool(models2))
@


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Currently, there is only limited documentation and examples available that show how to
use these functions in \textbf{mice}.

Technical details can be obtained from the methodological references given in the
help files of the R functions.

\bigskip

A
\href{https://gerkovink.github.io/miceVignettes/Multi_level/Multi_level_data.html}{vignette}
on multi-level imputation with \textbf{mice} is available.
It gives a more elaborate example of how to analyse such data.
%\textcolor{red}{[which did not run when I tried on march 29, 2018]}
\end{frame}



\subsection{R package JointAI}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Linear mixed models with incomplete covariates can also be
analysed using the package \textbf{JointAI}.

\bigskip

The syntax is analogous the syntax used in \Rfct{lme} of the package \textbf{nlme}.

<<JointAI_long, eval = F, size = 'small'>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2 + x4 + time + I(time^2),
                        random = ~time|id, data = DFexlong2,
                        n.iter = 5000)
@

Again, convergence of the Gibbs sampler should be checked using a traceplot,
<<JointAI_long_02, eval = F, size = 'small'>>=
traceplot(JointAI_long)
@
before obtaining the results:
<<JointAI_long_03, eval = F, size = 'small'>>=
res_JointAI_long <- summary(JointAI_long)
@

<<JointAI_long_run, eval = F, echo = F, size = 'small'>>=
library(JointAI)
JointAI_long <- lme_imp(y ~ x1 + x3 + x2 + x4 + time + I(time^2),
                        random = ~time|id, data = DFexlong2,
                        n.iter = 5000)

save(JointAI_long, file = "Slides/workspaces/JointAI_long.RData")
@

<<JointAI_long_get, echo = F, fig.width = 8, fig.height = 4, message = F, size = 'small'>>=
load("workspaces/JointAI_long.RData")
res_JointAI_long <- summary(JointAI_long)
@


Contrary to the two-level imputation of \textbf{mice}, non-linear associations
are appropriately handled.
\end{frame}



\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In \blue{jomo}, the functions \Rfct{jomo.lmer} and \Rfct{jomo.glmer}
can be used to impute longitudinal data with normal or non-normal outcomes.

\bigskip

In the multi-level setting, the \blue{level of each variable} needs to be specified
(1: repeated measurements, 2: baseline covariates), and \blue{ordered the same way}
the variables occur in the data frame.
<<jomo_long, eval = F, size = 'small'>>=
library(jomo)
# specify the level of each variable
lvl <- c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2, x4 = 2, time = 1)

jomo_long <- jomo.lmer(formula = y ~ x1 + x2 + x3 + x4 +
                         time + I(time^2) + (1 + time|id),
                       data = DFexlong2[, names(lvl)], level = lvl)
@


<<jomo_long_run, eval = F, echo = F, size = 'small'>>=
library(jomo)
lvl <- c("id" = 1, y = 1, x1 = 2, x2 = 2, x3 = 2, x4 = 2, time = 1)

jomo_long <- jomo.lmer(formula = y ~ x1 + x2 + x3 + x4 +
                         time + I(time^2) + (time|id),
                       data = DFexlong2[, names(lvl)], level = lvl)

jomo_longMCMC <- jomo.lmer.MCMCchain(formula = y ~ x1 + x2 + x3 + x4 +
                                       time + I(time^2) + (1 + time|id),
                                     data = DFexlong2[, names(lvl)],
                                     level = lvl, nburn = 3000)

plot(jomo_longMCMC$collectbeta[1, 1, ], type = 'l')
plot(jomo_longMCMC$collectomega[1, 1, ], type = 'l')

par(mfrow = c(5, 5), mar = c(2.5, 2.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
for (i in 1:dim(jomo_longMCMC$collectcovu)[1]) {
  for (j in 1:i) {
    plot(jomo_longMCMC$collectcovu[i, j, ], type = 'l')
  }
}

for (i in 1:dim(jomo_longMCMC$collectbetaY)[2]) {
  plot(jomo_longMCMC$collectbetaY[1, i, ], type = 'l')
}

plot(jomo_longMCMC$collectvarY, type = "l")

par(mfrow = c(2, 2), mar = c(2.5, 2.5, 0.5, 0.5), mgp = c(2, 0.6, 0))
for (i in 1:dim(jomo_longMCMC$collectcovuY)[1]) {
  for (j in 1:i) {
    plot(jomo_longMCMC$collectcovuY[i, j, ], type = 'l')
  }
}


save(jomo_long, jomo_longMCMC, file = 'Slides/workspaces/jomo_long.RData')
@

<<jomo_long_get, echo = F, size = 'small'>>=
load('workspaces/jomo_long.RData')
@

Like in the example with non-linear effects, convergence of the imputation
needs to be checked.
\end{frame}


\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Again, the stacked dataframe returned by \Rfct{jomo.lmer} needs to be split
by imputation number and the original data excluded, before fitting the model
and pooling the results.
<<size = 'small'>>=
library(miceadds)
impobj_jomo_long <- datalist2mids(split(jomo_long,
                                        jomo_long$Imputation)[-1])
models_jomo_long <- with(impobj_jomo_long,
                         lmer(y ~ x1 + x3 + x2 + x4 + time + I(time^2) +
                                (time|clus)))

res_jomo_long <- summary(pool(models_jomo_long))
@
(Note: \Rfct{jomo.lmer} re-names the grouping variable to \Rstring{clus}).

\bigskip

As in the examples for non-linear functional forms, congeniality of imputation
models is maintained.
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
\only<1>{
<<echo = F, figwidth = 6, fig.height = 4.5, size = 'small'>>=
mod_long2 <- with(DFexlong2_orig,
                  lmer(y ~ x1 + x2 + x3 + x4 + time + I(time^2) + (time|id)))

res_long2 <- list(JointAI = as.data.frame(res_JointAI_long$stat[, c(1,3,4)]),
                  jomo = as.data.frame(res_jomo_long)[, c("est", "lo 95", "hi 95")],
                  mice_long = as.data.frame(mice_longimp)[, c("est", "lo 95", "hi 95")],
                  mice_naive = as.data.frame(mice_longimp_naive)[, c("est", "lo 95", "hi 95")]
                  # mice_wide = as.data.frame(mice_wideimp)[, c("est", "lo 95", "hi 95")]
)

res_long2 <- lapply(res_long2, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  x$var <- gsub("x22", "x21", rownames(x))
  x
})

plot_long <- reshape2::melt(res_long2, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_long2) + .5)[c(1,2,2,1)], 8),
                     y = c(apply(confint(mod_long2,
                                         method = "Wald",
                           parm = names(fixef(mod_long2))), 1, rep,
                           each = 2)),
                     var = rep(names(fixef(mod_long2)), each = 4)
)

ggplot(plot_long[plot_long$L1 != "mice_naive", ], aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free', ncol = 4) +
  geom_polygon(data = polyDF, aes(x = pmin(x, 3.5), y = y), fill = 'blue', alpha = 0.2) +
  geom_hline(data = data.frame(betas = fixef(mod_long2),
                               var = names(fixef(mod_long2))),
             aes(yintercept = betas), lty = 2) +
  ylab("coefficient") +
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_long", "JointAI", "jomo"),
                   labels = c("mice", "JointAI", "jomo"))
@
}
\only<2>{
<<echo = F, figwidth = 6, fig.height = 4.5, size = 'small'>>=
ggplot(plot_long, aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free', ncol = 4) +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.2) +
  geom_hline(data = data.frame(betas = fixef(mod_long2),
                               var = names(fixef(mod_long2))),
             aes(yintercept = betas), lty = 2) +
  xlab("") +
  ylab("coefficient") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_long", "JointAI", "jomo", "mice_naive"),
                   labels = c("mice", "JointAI", "jomo", "mice\nnaive"))
@
}
\end{frame}


\begin{frame}
\begin{beamercolorbox}[sep=8pt,center,wd=\textwidth]{part title}
\usebeamerfont{part title}
Practical
\end{beamercolorbox}

\vfill

To practice imputation with longitudinal data, continue with the practical at
\begin{block}{}
\centering\url{https://emcbiostatistics.shinyapps.io/MICourse_MIadvanced}
\end{block}
or the offline version that can be downloaded from Canvas\\
(Files $>$ Principal documents $>$ Multiple Imputation $>$ Practical MIadvanced).

\vfill

\end{frame}


\section{Imputation of survival data}
\subsection{Results from literature}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
On slide~\ref{survivalmice} we have seen the rather complex formula for imputation of
an incomplete covariate in survival data.

\bigskip

White et al. \cite{White2009} derived versions of this model for different
settings (binary or continuous incomplete covariate $X$, and
continuous, categorical or no complete covariate $Z$) and investigated how to best
approximate it.

\bigskip

They found that when \blue{covariate effects and cumulative incidences are rather small},
using \blue{$Z$, $D$ and $H_0(T)$}, and possibly an interaction term, as
predictor variables in the imputation for $X$ in MICE may work satisfactorily.

\bigskip

However, in practice $H_0(T)$ is unspecified.
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Two main ideas:
\begin{itemize}
\item If covariate effects $\beta_x$ and $\beta_z$ are small, \blue{$H_0(t)\approx H(t)$},
      which can be approximated by the \blue{Nelson-Aalen estimator}.
\item \blue{Estimate $H_0(T)$ in an additional step} inside the MICE procedure
      by fitting a Cox model on the imputed data.
\end{itemize}
Neither of these approaches takes into account uncertainty about $H_0(t)$
(but the impact is likely to be small).

\bigskip

\pause
Based on results from their simulation study, White et al. conclude that
\blue{using $Z$, $D$ and the Nelson-Aalen estimator $\hat H(T)$} as predictors
for the imputation of $X$ worked best.

\bigskip

However, some \blue{bias towards the null} should be expected when covariates have large
effects.
\end{frame}


\subsection{R package mice}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}

In \textbf{mice}, \Rfct{nelsonaalen} can be used to
\blue{calculate the Nelson-Aalen estimator}, to use it as covariate in the
imputation.

<<mice_surv01, size = 'small'>>=
survdat$H0 <- nelsonaalen(survdat, timevar = Time, statusvar = event)
@

Then, we can prepare the imputation using the same steps as in previous examples:
<<mice_surv02, size = 'small'>>=
# setup run
imp0 <- mice(survdat, maxit = 0)
meth <- imp0$method
pred <- imp0$predictorMatrix

# specify normal imputation for continuous covariates
meth[c("x1", "x3")] <- "norm"

# remove event time from predictor (high correlation with H0)
pred[, "Time"] <- 0
@
\end{frame}

\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
With the modified arguments \Rarg{method} and \Rarg{predictorMatrix} we run
the imputation:
<<mice_surv03, size = 'small'>>=
survimp <- mice(survdat, maxit = 10, method = meth,
                predictorMatrix = pred, printFlag = F)
@


To obtain the pooled results, we first fit the model of interest
<<mice_surv2, size = 'small'>>=
cox_mice <- with(survimp, coxph(Surv(Time, event) ~ x1 + x2 + x3))
@

and pool and summarize the results.
<<size = 'small'>>=
res_mice_surv <- summary(pool(cox_mice))
@
The warning message refers to the way the degrees of freedom for the formulas
we saw in Part I (slide \ref{poolingdf}) are calculated and can be ignored.
\end{frame}


\subsection{R package smcfcs}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
Using the package \blue{smcfcs}, the same data can be imputed with the following
syntax:

<<smcfcs_surv, eval = F, size = 'small'>>=
library(smcfcs)
smcfcs_surv <- smcfcs(originaldata = survdat, smtype = "coxph",
                      smformula = "Surv(Time, event) ~ x1 + x2 + x3",
                      method = c("", "", "logreg", "norm", "norm", ""),
                      numit = 20, rjlimit = 1500)
@
Convergence of the procedure should be checked, analogously to the previous
example (see slide~\ref{smcfcsnonlin}).

\bigskip

After the resulting object is converted to a \Robj{mids} object, fitting the
model and pooling the results is identical to what was done with the data imputed
by \textbf{mice}.

<<smcfcs_surv02, eval = F, size = 'small'>>=
impobj_smcfcs_surv <- datalist2mids(smcfcs_surv$impDatasets)
models_smcfcs_surv <- with(impobj_smcfcs_surv,
                           coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_smcfcs_surv <- summary(pool(models_smcfcs_surv))
@

<<smcfcs_surv_run, echo = F, eval = F, size = 'small'>>=
library(smcfcs)
smcfcs_surv <- smcfcs(originaldata = survdat, smtype = "coxph",
                      smformula = "Surv(Time, event) ~ x1 + x2 + x3",
                      method = c("", "", "logreg", "norm", "norm", ""),
                      numit = 20, rjlimit = 1500)

save(smcfcs_surv, file = "Slides/workspaces/smcfcs_surv.Rdata")
@

<<smcfcs_surv_load, echo = F, warning = F, size = 'small'>>=
load("workspaces/smcfcs_surv.Rdata")
impobj_smcfcs_surv <- datalist2mids(smcfcs_surv$impDatasets)
models_smcfcs_surv <- with(impobj_smcfcs_surv,
                           coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_smcfcs_surv <- summary(pool(models_smcfcs_surv))
@
\end{frame}


\subsection{R package jomo}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
In the package \blue{jomo}, the function \Rfct{jomo.coxph} can be used to
impute our example survival data:
<<jomo_surv, eval = F, size = 'small'>>=
library(jomo)
jomo_surv <- jomo.coxph(formula = Surv(Time, event) ~ x1 + x2 + x3,
                        data = survdat)
@

<<jomo_surv_run, echo = F, eval = F, size = 'small'>>=
library(jomo)
set.seed(2018)
jomo_survMCMC <- jomo.coxph.MCMCchain(formula = Surv(Time, event) ~ x1 + x2 + x3,
                                      data = survdat)
matplot(t(jomo_survMCMC$collectbeta[1, c(2,3), ]), type = 'l')
matplot(t(jomo_survMCMC$collectomega[1, , ]), type = 'l')

jomo_surv <- jomo.coxph(formula = Surv(Time, event) ~ x1 + x2 + x3,
                        data = survdat)
save(jomo_surv, jomo_survMCMC, file = "Slides/workspaces/jomo_surv.RData")
@

<<jomo_surv_get, echo = F, include = F, size = 'small'>>=
library(jomo)
load("workspaces/jomo_surv.RData")
impobj_jomo_surv <- datalist2mids(split(jomo_surv, jomo_surv$Imputation)[-1])
models_jomo_surv <- with(impobj_jomo_surv, coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_jomo_surv <- summary(pool(models_jomo_surv))
@
Note that the convergence of the procedure should be checked using
\Rfct{jomo.coxph.MCMCchain} (see the previous examples using \textbf{jomo}).

\bigskip

To analyse \& pool the imputed data the steps are identical to the other examples:
<<eval = F, size = 'small'>>=
impobj_jomo_surv <- datalist2mids(split(jomo_surv,
                                        jomo_surv$Imputation)[-1])
models_jomo_surv <- with(impobj_jomo_surv,
                         coxph(Surv(Time, event) ~ x1 + x2 + x3))
res_jomo_surv <- summary(pool(models_jomo_surv))
@
\end{frame}


\subsection{Comparison of results}
\begin{frame}[fragile]{\thesection. \insertsection}
\framesubtitle{\thesection.\thesubsection. \insertsubsection}
<<echo = F, fig.width = 6, fig.height = 2.5, size = 'small'>>=
mod_surv <- with(survdat_orig, coxph(Surv(Time, event) ~ x1 + x2 + x3))

res_surv <- list(mice_naive = rescox01,
                 mice = as.data.frame(res_mice_surv)[, c("est", "lo 95", "hi 95")],
                 smcfcs = as.data.frame(res_smcfcs_surv)[, c("est", "lo 95", "hi 95")],
                 jomo = as.data.frame(res_jomo_surv)[, c("est", "lo 95", "hi 95")]
)

res_surv <- lapply(res_surv, function(x) {
  colnames(x) <- c("coef", "lo", "up")
  x$var <- rownames(x)
  x
})

plot_surv <- reshape2::melt(res_surv, id.vars = c("coef", "lo", "up", "var"))

polyDF <- data.frame(x = rep(c(0.5, length(res_surv) + .5)[c(1,2,2,1)],
                             length(mod_surv$coef)),
                     y = c(apply(log(summary(mod_surv)$conf.int[, 3:4]), 1, rep,
                           each = 2)),
                     var = rep(names(coef(mod_surv)), each = 4)
)

ggplot(plot_surv, aes(x = L1, y = coef)) +
  geom_point(na.rm = T) +
  geom_errorbar(aes(ymin = lo, ymax = up), width = 0.3, na.rm = T) +
  facet_wrap("var", scales = 'free') +
  geom_polygon(data = polyDF, aes(x = x, y = y), fill = 'blue', alpha = 0.2) +
  geom_hline(data = data.frame(betas = coef(mod_surv),
                               var = names(coef(mod_surv))),
             aes(yintercept = betas), lty = 2) +
  ylab("coefficient") +
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(limits = c("mice_naive", "mice", "smcfcs", "jomo"),
                   labels = c("mice\nnaive", "mice", "smcfcs", "jomo"))
@

The naive mice approach, and mice using the Nelson-Aalen estimator give very
biased results for the effects of $x1$ and $x2$, but performed acceptably well
for $x3$.

\bigskip

Note that the \blue{true effects} (log HR) of $x1$ and $x2$ are \blue{very large}
(-2 and 2.5, respectively),
and represent the setting where the approximation by the Nelson-Aalen estimate
is \blue{expected to be biased}.
\end{frame}

\begin{frame}
\begin{beamercolorbox}[sep=8pt,center,wd=\textwidth]{part title}
\usebeamerfont{part title}
Practical
\end{beamercolorbox}

\vfill

To practice imputation with survival data, continue with the practical at
\begin{block}{}
\centering\url{https://emcbiostatistics.shinyapps.io/MICourse_MIadvanced}
\end{block}
or the offline version that can be downloaded from Canvas\\
(Files $>$ Principal documents $>$ Multiple Imputation $>$ Practical MIadvanced).

\vfill

\end{frame}


\mode<article>{
\section*{Summary \& Conclusion of Part III}
}
\begin{frame}[allowframebreaks]{Summary \& Conclusion of Part III}
\begin{itemize}
\item MICE requires \blue{congenial \& compatible imputation models} to work well.
\item When this is not the case, (naive) use of MICE can lead to \blue{biased results}.
\item Common settings that require special attention are
      \begin{itemize}
      \item \blue{non-linear functional forms \& interaction terms}
      \item \blue{longitudinal data}
      \item \blue{survival data}
      \end{itemize}
\framebreak
\item When using the package \textbf{mice}, there are choices that can \blue{reduce bias}
      \begin{itemize}
      \item \Rarg{pmm} tends to be less biased than \Rarg{norm} for interactions or non-linear associations
      \item JAV approach reduces bias in settings with interactions or non-linear associations
      \item \blue{special 2-level imputation methods} are available for longitudinal data
      \item The \blue{Nelson-Aalen estimator} can be used instead of the time variable
            for imputing survival data when effects are not too large.
      \end{itemize}
\item Generally, \blue{problems} are more severe when
      \begin{itemize}
      \item \blue{proportions of missing values are large},
      \item effect sizes are large,
      \item little other \blue{covariate information} is available.
      \end{itemize}
      (Note that in the examples we had all of the above.)
\framebreak
\item In settings where MICE may not provide valid imputations,
      \blue{alternative approaches} are available and should be considered.
\item R packages that provide such alternative approaches are for example:
      \begin{itemize}
      \item \blue{JointAI} (non-linear \& longitudinal)
      \item \blue{smcfcs} (non-linear \& survival)
      \item \blue{jomo} (non-linear, longitudinal \& survival)
      \end{itemize}
\item These packages are very young.
      \begin{itemize}
      \item Hence, they may still have some problems.\\
            \blue{\ding{225}} \blue{Use them carefully!} (and email the maintainer about problems)
      \item They are under \blue{active development}, so resolutions of bugs and
      features are frequently added.
      \end{itemize}
\end{itemize}
\end{frame}

